{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMHyndLKDrtTHK9gO5/1PGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Audio_AI/blob/main/Trascribe_You_tube_video_using_Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=6gHE4TdexnU"
      ],
      "metadata": {
        "id": "BlZ6YNWACcGd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_jTRXpqCNNN",
        "outputId": "82808a84-b5cf-4052-fe0f-83531aeeec47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-dkergeyk\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py): started\n",
            "  Building wheel for whisper (setup.py): finished with status 'done'\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175324 sha256=c9ed25e7f0d5d0dbeae49265bb44119823267eb0807a36a773f16e883681bb40\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w08s9jzv/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1 whisper-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "Installing collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-dkergeyk\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install git+https://github.com/openai/whisper.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXDR-TH-DGvf",
        "outputId": "70b259ce-d3eb-48bf-de7e-423a66cffb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.8/dist-packages (12.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first we import whisper and pytube modules\n",
        "import whisper\n",
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "gDXC0oUiDOGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJOtPZ4rDVxg",
        "outputId": "177fef76-65b1-4064-d477-59c309eea6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:26<00:00, 118MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link = 'https://www.youtube.com/watch?v=6gHE4TdexnU'\n",
        "yt = YouTube(link)\n",
        "path = yt.streams.filter(only_audio=True)[0].download(filename=\"audio.mp4\")\n"
      ],
      "metadata": {
        "id": "XSXb4uZXDhSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options = whisper.DecodingOptions(without_timestamps=True)\n",
        "# transcribe the downloaded youtube video using whisper\n",
        "results = model.transcribe(path)"
      ],
      "metadata": {
        "id": "GlwQCpkODrQf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4QWo8P5SDm6",
        "outputId": "edbc6edc-f77d-40f9-ca37-fa4d47e9e8e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \" So here, the intention of this application is me to predict the software quality. So here we are going to consider one data set, which is having related to the software and everything. So here we are having 10 data sets, one is related to Spring Framework, another one is related to JUnit, another one is related to Kafka trunk, another one is related to Blue Sea and Drop Wizard, Textile, Hadoop, Selenium, Skywalking and Signal Android Mast. So these are the data sets which we are working. So among these data sets, we can choose any one data set. So when you observe any data set, it is having the information related to the software. So for example, here we are using qualified name. So what are the things they are observing and then the name. So here we are having qualified name and the name, then complexity, then coupling, size, lack of cohesion, CBO, RFC. These are all the different parameters that are considering in software quality and everything. So every quality is having its own values. So based on the thing, it may have between 1 to 100 or 0 to 1 like that or 1 or 0. So like that, we are having different data sets. Regarding JUnit also we are having. So any data set we can use it. So it's also having the same parameters. So and like that, we are having totally 10 data sets. Among these 10 data sets, we can choose anything. So whichever data set you want, you can test it. So here, when you are going to discuss regarding the abstract, they are saying that the software quality estimation is an activity needed at various stages of software development. So when people are going to develop any software, so mainly they will concentrate on quality and everything. So already we know that one problem can be solved with the help of different things. For example, when you consider one example like to find out whether the number is a right number or not, or else whether you want to find out whether the number is a strong number or not, or want to reverse the number, or there's some exergence. So if you assume some problem, for that problem, you can find different solutions. So everything is correct. When you execute n number of programs, for example, n users are there, and n users, they will give n programs. All n programs will get the same output, but they will consider some applications only. They will not consider all n programs to implement it. Why? Because they may need some time complexity and space complexity also. So the program should execute as early as possible in a good time manner and should use very less memory. These are the main constraints. So when you consider these constraints, then some programs will be assured and some programs only will work. So that will decide based on the situation. Next slide, please. Sorry. So here the thing is, when we people are working with programming styles, so all programmers write their own program, but we don't consider all the programs. The programming which is giving best performance, then only we'll consider. So when you're planning some performance, they may have different factors. So among these factors, they will check it. But here in the part of machine learning, so what we are going to discuss is, so which one is best, which one is better. So for that, we are using SVM and neural network algorithms. So they will find the accuracy, which is having high accuracy, which is having low accuracy, and everything will be mentioned in machine learning algorithm. So these are the total documentation which we are having. So when it comes to execution part, so in the folder, software quality folder is there, there just click on run. When you click on run, automatically your application will start execution. So it is having PPT also. And generally, the machine learning algorithms will process these things. So whatever the data set we are having, first they will apply cleaning and pre-processing, then they will find the data set and they will select the future. So futures in the sense here in machine learning, so table fields, we call it as a future setting. So if you consider any table, it may have a number of fields, columns are there. So that columns will be mentioned as a future. So they will select the futures and then they will do the input and they will apply the machine learning algorithms. But then they will get the predictions. So for execution it will take some time. We need to wait. So this is the table. So first you're supposed to upload the data set. So in data set, we're having different types of data sets. Among these things, whichever data set you want, you can choose it. You need to consider one data set. These are different software's data which we have collected. Yeah, which is already recorded. And if you have your own data set, you can also add here. So whatever it may be. So here they gave some data sets which is related to different different software's. And they recorded yearly wise. So just you need to choose upload data set. So we are having different different data sets. So I'm using some Hadoop trunk. So it is having only 2020. We can choose that one. So once you uploaded the data set, then pre-processing is going to work. So we're having the data sets information. Some are there. Totally 4,000, sorry, 41,667 records are there and 40 features are there. So 41,667 rows and 40 columns. Here columns in the sense we call it as features. And we are giving some graphical representation also. Of different different columns, SRFC, DIT, all the columns are there. So it is giving information. And if you want to save this image, you can save it, but not required. Just I'm closing this one. So this is data which I uploaded. Once you uploaded the data set, then you're supposed to pre-process the given data set. Pre-processing in the sense it is going to check any null values are there or else any difficulties is there. Everything will think. And if any null values or anything is there, then they will remove the data set. They will remove the rows and which contains the null values. Just we're supposed to be pre-processed data set. It is having the qualified name, resolve things and which is giving the maximum value which is having maximum value. So once it is pre-processed, here I'm getting some data which is ready to pre-processing. And then feature selection algorithms. So we need to select the features. When you click on here, so it is going to give the information. This is a cross matrix. So we may have a number of features, 40 features are there. That's why that overlapping is happening. So, but here graphically, not only graphically textual in text wise, we can see here. So total features are found in the data set before applying the feature selection. 39 is there. So total features found in the data set after applying the feature selection algorithm. So among 39, we are choosing 30 only. And the total records found is so 41067. But among these, some null data will be there. Some null data will be there. OK, that we can remove. The total records used for trying the machine learning algorithm is 33,333. And the total records used to test machine learning algorithm is 8,334. So here, when you observe the data set, so we are having single data set. When you people are applying any machine learning algorithm, so the data set is supposed to divide into two parts. One is called trying data set, another is called test data set. And some problems may find a different for training and testing also. OK, so in some applications, you may find two data sets. One is for training, another is for testing. In some applications, you may get only one data set. In that case, if you are having only one data set, in that case, it is your responsibility to divide the data set into two parts, training and test. So how we are going to divide in the sense, so we may consider 70-30 percentages only. So some programs may consider 70% of data set will be training and 30% will be testing. In some applications, they may go with 80-20 also. In some applications, they may go with 60-40 also. OK, so in our application. So here in our application, we are using 80-20 percent. Here, the test size is equal to 0.2, means 20%. So 80% will be for training data and 20% is for testing data. How we are going to select like that means based on the data which we have in a week. OK, so for example, you can calculate. So total we are having 41,067 into 0.20. So 8334. So that is the value which we are having. OK, 8334 means 8334 it is taking and remaining the cost will be training cost. So 70-30 means if you are having huge amount of data, thousands of records, then go with 80-20. If you are having some medium, means some 5000, 6000 like that, go with 70-30. So if you are having very less, like hundreds, then go with 60-40. Why? Because for training or testing, both should be having some meaningful of records. OK, if you are having very less records for testing, then in that case, so your machine learning algorithms will not work properly. So here I'm having 41,667. That's why I choose 80-20%. So 20% of data will be for testing purpose and 80% of data will be for training purpose. So among these records, so it is taking randomly. Randomly it is going to divide into two parts. So that is feature selection algorithm. Then I'm running machine learning algorithms. Just I'm clicking machine learning algorithm. Run. So it will take some time. So for machine learning algorithms execution, you take a lot of time. We need to wait for some time. So this 8334 records, it will pick randomly or it will pick sequentially? Randomly. Randomly machine itself is taking. OK, among these, so it is going to design data frames. So for 80% of records, it is going to design one data frame and 30% of records, it is going to design one data frame and it is not sequence. So randomly, it will choose. A single data set which we have pointed, it will split into two now? Yeah. OK. Whatever the data set you selected, so that will be split into two parts. 80-20%. Is it compulsory 80-20 means? No. Some people may go with 70-30 also. Some people may go with 60-40 also. Based on our requirement. But 70-30 is the average maximum people will use. But here we are using 80-20 because we have plenty of records. Why they opt to choose for this splitting? Is there any logic? For example, if you say that I prepared for exam. I prepared for exam. So I prepared some math exam. So in my notes, I'm having some problems. So I prepared very well. Can we expect in exam the same 10 problems or same questions in examination? Can you expect the same questions in external examination? No, we cannot expect. But you should, when you said that I prepared for exam, then you're supposed to do same type of questions that may arise. Same, not same problem, same type of questions that will arise. In that situation, you're supposed to write answer that questions also. For that here we are using training and testing. Training in the data set. So mission is going to train the algorithm with the help of these 33,333 records. Randomly they choose them. And then to check whether the mission is working properly or not, whether the algorithm is working properly or not, we are using testing data set. So for testing data set also supposed to take same performance. For that we are dividing training and testing. Training in the sense that training, we are giving training to algorithm and to test whether it is working properly or not, we are using testing data set. All the fields in the data set, how we are capturing like there are 30 columns. 40 fields are there. So in programming part we are thinking just a minute I will show that program. The fields which is recorded by application, some application is there so that we are not discussing. So every fields will be gathered through application. So someone is giving that data set to us to go with the software quality prediction. How much, how quality is there if I'm using Hadoop. So whether the accuracy, how much accuracy is there, whether can we proceed with Hadoop or not. If I give some net bills, how much accuracy is there. So Java, how much accuracy is there, like that. They will give the fields and every data set. For that we are going to process the thing. So here feature selection will be there. So some columns may be having non-values in that case, we'll remove that one. Some rows will be having non-values in that case, we'll remove that row also, like that. And if we're having less non-values, then we go with standard deviation. But for that particular column, we're going to calculate standard deviation and the value will be represented with standard deviation value. Non-value will be represented with standard deviation value. For example, I will show you. Some empty values are there here, just of the empty values are there. In that case, if like that, if it is having more number of records, then they will try to remove. So, but if it is having very less, then these values will be replaced with standard deviation. So RFC, standard deviation of RFC they will find and these values will be replaced. So standard deviation of SRFC will find, processing will take care. So that is taken care by machine learning algorithm. One second, can you open that? So data set you are required to open. So these are the non-values and it doesn't have any value. So it is also having, doesn't have any value. Some values are there, some values are empty. So these empty values. All the columns, is it given by some third party members? Third party, third party, third party. So the person who gave the problem to us, they will provide. Okay. So. Is there any definitions? Yeah. Definitions available for all these columns because it is listed in short form. Yeah. RFC, SRFC, DAT. Yeah. I will check it. I will check it and if possible, I will share with you. Okay. Supposed to be given that. So we don't have. Can I check in online for this? Yeah, you can find it online. You can find it online. Okay. Anyhow, if possible, myself also, I will share with you. Okay, here we have. So, matrix is there. Just we need to close this one. Okay. So, first you're supposed to upload the data set. Then we process the data set. And then we select the algorithm. So here we are having 36,000, 928. Same 20, 80%. And machine learning algorithm. So, yeah, it executed different algorithms. So, the rolling average accuracy 90% is there. We supposed to take accuracy and they should be accuracy 97% 4.8. Random forest 97.83. Logistic regression is 85. Among these, which algorithm is providing more accuracy that algorithm will prefer. So here, random forest is having 97.83. They can choose either random forest or Dation tree. These two algorithms they can find. Okay, why because it's having high accuracy value. And then next we will go with Bernoulli Naive Bayes. And last we will go with logistic regression. So, they will consider. So accuracy. Okay, so precision, they call FMF measure, but accuracy, they will consider. So, when you executed for this data set, these two algorithms can prefer. Okay, so 97.48 is there, 97.83 is there. Okay, and then run CNN algorithm. We're executing CNN algorithm also. So, it is taking some time. So, background, it is running. Final result we'll get. It is running. It is taking some time. So, total output will be come here itself. Model sequential, layer depth dense one, look output shape, params, how much params it is taking, everything is there. So, just we are executing CNN algorithm. So, total params it is having 281606, paranormal params 281606, non-paranormal params are 0. Just executing like this. And then we can compare the graph. So, which is having highest. Already in text only we can find it. But in graph, we are executing only. So, patient tree. So, among these, we can find this color blue is having accuracy, reference score, precision, recall. So, here we are suggesting. So, patient tree is one and random forest is another one. So, this is about the project execution. And the values will be changed based on the data set which we choose. So, for this we can prefer this. So, have any doubts? If you run CNN algorithm, it won't be displayed in this window. It will be displayed in command window only. Yeah, it doesn't work. Why? Because actually it will work in background process only. It will work background only. And up to, this CNN is in the future selection only. So, up to this one only is the final. Okay, this is the future selection process. And CNN algorithms will work background only. It doesn't work in front, we can't show you. Okay. So, first you're supposed to upload the data set, then pre-process it, then future selection process, and then machine learning execution process. So, in this comparison graph, is there any option available like how to check that? Which one? Comparison graph. Comparison graph, just whatever the data which we received here, whatever the data which we received here. So, yeah, CNN accuracy also it came here. CNN accuracy 86.5150. Okay, CNN precision, CNN recall and CNN reference. It will be received here also. So, CNN algorithm is also having very less, 86.5151. So, just we are giving comparison graph means the text what we received here, the text what we received here, just we are showing graphical monad, nothing is there. Okay. All the data we have, same thing we are representing here. This different algorithms, values? Yeah, values. Just different algorithm values only there. So, what we received in here. Okay, so for checking purpose only we are using graph. But here only we can say that. When you compare accuracy, here only we can say that. And CNN is also. So, bagging glass for accuracy 85 is there. So, gradient boosting accuracy 99.71 is there, sorry. Gradient boosting is having 99.71. And CNN accuracy is 86. So, this is having best one. Scroll the text. So, 97 decision tree and 7.48 and random forest 97.83. So, when it comes to gradient boosting accuracy algorithm, gradient boosting accuracy 99.71. So, only CNN algorithm has been extended. CNN algorithm is extended. CNN, LSTM, and other extension algorithms are not there. That's why we executed it separately. So, it came out finally, it extended algorithm. We also have CNN and Joplin. Any doubts? No.\",\n",
              " 'segments': [{'id': 0,\n",
              "   'seek': 0,\n",
              "   'start': 0.0,\n",
              "   'end': 14.88,\n",
              "   'text': ' So here, the intention of this application is me to predict the software quality.',\n",
              "   'tokens': [407,\n",
              "    510,\n",
              "    11,\n",
              "    264,\n",
              "    7789,\n",
              "    295,\n",
              "    341,\n",
              "    3861,\n",
              "    307,\n",
              "    385,\n",
              "    281,\n",
              "    6069,\n",
              "    264,\n",
              "    4722,\n",
              "    3125,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5242671966552734,\n",
              "   'compression_ratio': 1.4488188976377954,\n",
              "   'no_speech_prob': 0.24179895222187042},\n",
              "  {'id': 1,\n",
              "   'seek': 0,\n",
              "   'start': 14.88,\n",
              "   'end': 22.84,\n",
              "   'text': ' So here we are going to consider one data set, which is having related to the software',\n",
              "   'tokens': [407,\n",
              "    510,\n",
              "    321,\n",
              "    366,\n",
              "    516,\n",
              "    281,\n",
              "    1949,\n",
              "    472,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    597,\n",
              "    307,\n",
              "    1419,\n",
              "    4077,\n",
              "    281,\n",
              "    264,\n",
              "    4722],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5242671966552734,\n",
              "   'compression_ratio': 1.4488188976377954,\n",
              "   'no_speech_prob': 0.24179895222187042},\n",
              "  {'id': 2,\n",
              "   'seek': 0,\n",
              "   'start': 22.84,\n",
              "   'end': 24.16,\n",
              "   'text': ' and everything.',\n",
              "   'tokens': [293, 1203, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5242671966552734,\n",
              "   'compression_ratio': 1.4488188976377954,\n",
              "   'no_speech_prob': 0.24179895222187042},\n",
              "  {'id': 3,\n",
              "   'seek': 2416,\n",
              "   'start': 24.16,\n",
              "   'end': 30.08,\n",
              "   'text': ' So here we are having 10 data sets, one is related to Spring Framework, another one is',\n",
              "   'tokens': [407,\n",
              "    510,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    1266,\n",
              "    1412,\n",
              "    6352,\n",
              "    11,\n",
              "    472,\n",
              "    307,\n",
              "    4077,\n",
              "    281,\n",
              "    14013,\n",
              "    31628,\n",
              "    1902,\n",
              "    11,\n",
              "    1071,\n",
              "    472,\n",
              "    307],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3862768061020795,\n",
              "   'compression_ratio': 1.7718446601941749,\n",
              "   'no_speech_prob': 0.0009263393585570157},\n",
              "  {'id': 4,\n",
              "   'seek': 2416,\n",
              "   'start': 30.08,\n",
              "   'end': 35.76,\n",
              "   'text': ' related to JUnit, another one is related to Kafka trunk, another one is related to Blue',\n",
              "   'tokens': [4077,\n",
              "    281,\n",
              "    508,\n",
              "    12405,\n",
              "    270,\n",
              "    11,\n",
              "    1071,\n",
              "    472,\n",
              "    307,\n",
              "    4077,\n",
              "    281,\n",
              "    47064,\n",
              "    19849,\n",
              "    11,\n",
              "    1071,\n",
              "    472,\n",
              "    307,\n",
              "    4077,\n",
              "    281,\n",
              "    8510],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3862768061020795,\n",
              "   'compression_ratio': 1.7718446601941749,\n",
              "   'no_speech_prob': 0.0009263393585570157},\n",
              "  {'id': 5,\n",
              "   'seek': 2416,\n",
              "   'start': 35.76,\n",
              "   'end': 45.480000000000004,\n",
              "   'text': ' Sea and Drop Wizard, Textile, Hadoop, Selenium, Skywalking and Signal Android Mast.',\n",
              "   'tokens': [11352,\n",
              "    293,\n",
              "    17675,\n",
              "    37449,\n",
              "    11,\n",
              "    18643,\n",
              "    794,\n",
              "    11,\n",
              "    389,\n",
              "    1573,\n",
              "    404,\n",
              "    11,\n",
              "    10736,\n",
              "    268,\n",
              "    2197,\n",
              "    11,\n",
              "    9879,\n",
              "    12490,\n",
              "    278,\n",
              "    293,\n",
              "    43414,\n",
              "    8853,\n",
              "    376,\n",
              "    525,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3862768061020795,\n",
              "   'compression_ratio': 1.7718446601941749,\n",
              "   'no_speech_prob': 0.0009263393585570157},\n",
              "  {'id': 6,\n",
              "   'seek': 2416,\n",
              "   'start': 45.480000000000004,\n",
              "   'end': 49.16,\n",
              "   'text': ' So these are the data sets which we are working.',\n",
              "   'tokens': [407, 613, 366, 264, 1412, 6352, 597, 321, 366, 1364, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3862768061020795,\n",
              "   'compression_ratio': 1.7718446601941749,\n",
              "   'no_speech_prob': 0.0009263393585570157},\n",
              "  {'id': 7,\n",
              "   'seek': 2416,\n",
              "   'start': 49.16,\n",
              "   'end': 52.879999999999995,\n",
              "   'text': ' So among these data sets, we can choose any one data set.',\n",
              "   'tokens': [407,\n",
              "    3654,\n",
              "    613,\n",
              "    1412,\n",
              "    6352,\n",
              "    11,\n",
              "    321,\n",
              "    393,\n",
              "    2826,\n",
              "    604,\n",
              "    472,\n",
              "    1412,\n",
              "    992,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3862768061020795,\n",
              "   'compression_ratio': 1.7718446601941749,\n",
              "   'no_speech_prob': 0.0009263393585570157},\n",
              "  {'id': 8,\n",
              "   'seek': 5288,\n",
              "   'start': 52.88,\n",
              "   'end': 59.72,\n",
              "   'text': ' So when you observe any data set, it is having the information related to the software.',\n",
              "   'tokens': [407,\n",
              "    562,\n",
              "    291,\n",
              "    11441,\n",
              "    604,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    309,\n",
              "    307,\n",
              "    1419,\n",
              "    264,\n",
              "    1589,\n",
              "    4077,\n",
              "    281,\n",
              "    264,\n",
              "    4722,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35523994445800783,\n",
              "   'compression_ratio': 1.4776119402985075,\n",
              "   'no_speech_prob': 0.0005695950239896774},\n",
              "  {'id': 9,\n",
              "   'seek': 5288,\n",
              "   'start': 59.72,\n",
              "   'end': 65.88,\n",
              "   'text': ' So for example, here we are using qualified name.',\n",
              "   'tokens': [407, 337, 1365, 11, 510, 321, 366, 1228, 15904, 1315, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35523994445800783,\n",
              "   'compression_ratio': 1.4776119402985075,\n",
              "   'no_speech_prob': 0.0005695950239896774},\n",
              "  {'id': 10,\n",
              "   'seek': 5288,\n",
              "   'start': 65.88,\n",
              "   'end': 77.62,\n",
              "   'text': ' So what are the things they are observing and then the name.',\n",
              "   'tokens': [407,\n",
              "    437,\n",
              "    366,\n",
              "    264,\n",
              "    721,\n",
              "    436,\n",
              "    366,\n",
              "    22107,\n",
              "    293,\n",
              "    550,\n",
              "    264,\n",
              "    1315,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35523994445800783,\n",
              "   'compression_ratio': 1.4776119402985075,\n",
              "   'no_speech_prob': 0.0005695950239896774},\n",
              "  {'id': 11,\n",
              "   'seek': 7762,\n",
              "   'start': 77.62,\n",
              "   'end': 93.28,\n",
              "   'text': ' So here we are having qualified name and the name, then complexity, then coupling, size,',\n",
              "   'tokens': [407,\n",
              "    510,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    15904,\n",
              "    1315,\n",
              "    293,\n",
              "    264,\n",
              "    1315,\n",
              "    11,\n",
              "    550,\n",
              "    14024,\n",
              "    11,\n",
              "    550,\n",
              "    37447,\n",
              "    11,\n",
              "    2744,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48714936454341096,\n",
              "   'compression_ratio': 1.3856209150326797,\n",
              "   'no_speech_prob': 0.00029306754004210234},\n",
              "  {'id': 12,\n",
              "   'seek': 7762,\n",
              "   'start': 93.28,\n",
              "   'end': 95.84,\n",
              "   'text': ' lack of cohesion, CBO, RFC.',\n",
              "   'tokens': [5011, 295, 598, 38571, 11, 383, 15893, 11, 497, 18671, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48714936454341096,\n",
              "   'compression_ratio': 1.3856209150326797,\n",
              "   'no_speech_prob': 0.00029306754004210234},\n",
              "  {'id': 13,\n",
              "   'seek': 7762,\n",
              "   'start': 95.84,\n",
              "   'end': 103.04,\n",
              "   'text': ' These are all the different parameters that are considering in software quality and everything.',\n",
              "   'tokens': [1981,\n",
              "    366,\n",
              "    439,\n",
              "    264,\n",
              "    819,\n",
              "    9834,\n",
              "    300,\n",
              "    366,\n",
              "    8079,\n",
              "    294,\n",
              "    4722,\n",
              "    3125,\n",
              "    293,\n",
              "    1203,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48714936454341096,\n",
              "   'compression_ratio': 1.3856209150326797,\n",
              "   'no_speech_prob': 0.00029306754004210234},\n",
              "  {'id': 14,\n",
              "   'seek': 10304,\n",
              "   'start': 103.04,\n",
              "   'end': 110.28,\n",
              "   'text': ' So every quality is having its own values.',\n",
              "   'tokens': [407, 633, 3125, 307, 1419, 1080, 1065, 4190, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3935184736509581,\n",
              "   'compression_ratio': 1.5649350649350648,\n",
              "   'no_speech_prob': 0.000113840818812605},\n",
              "  {'id': 15,\n",
              "   'seek': 10304,\n",
              "   'start': 110.28,\n",
              "   'end': 117.92,\n",
              "   'text': ' So based on the thing, it may have between 1 to 100 or 0 to 1 like that or 1 or 0.',\n",
              "   'tokens': [407,\n",
              "    2361,\n",
              "    322,\n",
              "    264,\n",
              "    551,\n",
              "    11,\n",
              "    309,\n",
              "    815,\n",
              "    362,\n",
              "    1296,\n",
              "    502,\n",
              "    281,\n",
              "    2319,\n",
              "    420,\n",
              "    1958,\n",
              "    281,\n",
              "    502,\n",
              "    411,\n",
              "    300,\n",
              "    420,\n",
              "    502,\n",
              "    420,\n",
              "    1958,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3935184736509581,\n",
              "   'compression_ratio': 1.5649350649350648,\n",
              "   'no_speech_prob': 0.000113840818812605},\n",
              "  {'id': 16,\n",
              "   'seek': 10304,\n",
              "   'start': 117.92,\n",
              "   'end': 123.92,\n",
              "   'text': ' So like that, we are having different data sets.',\n",
              "   'tokens': [407, 411, 300, 11, 321, 366, 1419, 819, 1412, 6352, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3935184736509581,\n",
              "   'compression_ratio': 1.5649350649350648,\n",
              "   'no_speech_prob': 0.000113840818812605},\n",
              "  {'id': 17,\n",
              "   'seek': 10304,\n",
              "   'start': 123.92,\n",
              "   'end': 126.92,\n",
              "   'text': ' Regarding JUnit also we are having.',\n",
              "   'tokens': [35523, 508, 12405, 270, 611, 321, 366, 1419, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3935184736509581,\n",
              "   'compression_ratio': 1.5649350649350648,\n",
              "   'no_speech_prob': 0.000113840818812605},\n",
              "  {'id': 18,\n",
              "   'seek': 10304,\n",
              "   'start': 126.92,\n",
              "   'end': 131.06,\n",
              "   'text': ' So any data set we can use it.',\n",
              "   'tokens': [407, 604, 1412, 992, 321, 393, 764, 309, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3935184736509581,\n",
              "   'compression_ratio': 1.5649350649350648,\n",
              "   'no_speech_prob': 0.000113840818812605},\n",
              "  {'id': 19,\n",
              "   'seek': 13106,\n",
              "   'start': 131.06,\n",
              "   'end': 135.08,\n",
              "   'text': \" So it's also having the same parameters.\",\n",
              "   'tokens': [407, 309, 311, 611, 1419, 264, 912, 9834, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3504677069814582,\n",
              "   'compression_ratio': 1.6201117318435754,\n",
              "   'no_speech_prob': 5.10077879880555e-05},\n",
              "  {'id': 20,\n",
              "   'seek': 13106,\n",
              "   'start': 135.08,\n",
              "   'end': 142.4,\n",
              "   'text': ' So and like that, we are having totally 10 data sets.',\n",
              "   'tokens': [407,\n",
              "    293,\n",
              "    411,\n",
              "    300,\n",
              "    11,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    3879,\n",
              "    1266,\n",
              "    1412,\n",
              "    6352,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3504677069814582,\n",
              "   'compression_ratio': 1.6201117318435754,\n",
              "   'no_speech_prob': 5.10077879880555e-05},\n",
              "  {'id': 21,\n",
              "   'seek': 13106,\n",
              "   'start': 142.4,\n",
              "   'end': 146.28,\n",
              "   'text': ' Among these 10 data sets, we can choose anything.',\n",
              "   'tokens': [16119, 613, 1266, 1412, 6352, 11, 321, 393, 2826, 1340, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3504677069814582,\n",
              "   'compression_ratio': 1.6201117318435754,\n",
              "   'no_speech_prob': 5.10077879880555e-05},\n",
              "  {'id': 22,\n",
              "   'seek': 13106,\n",
              "   'start': 146.28,\n",
              "   'end': 150.32,\n",
              "   'text': ' So whichever data set you want, you can test it.',\n",
              "   'tokens': [407, 24123, 1412, 992, 291, 528, 11, 291, 393, 1500, 309, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3504677069814582,\n",
              "   'compression_ratio': 1.6201117318435754,\n",
              "   'no_speech_prob': 5.10077879880555e-05},\n",
              "  {'id': 23,\n",
              "   'seek': 13106,\n",
              "   'start': 150.32,\n",
              "   'end': 155.72,\n",
              "   'text': ' So here, when you are going to discuss regarding the abstract, they are saying that the software',\n",
              "   'tokens': [407,\n",
              "    510,\n",
              "    11,\n",
              "    562,\n",
              "    291,\n",
              "    366,\n",
              "    516,\n",
              "    281,\n",
              "    2248,\n",
              "    8595,\n",
              "    264,\n",
              "    12649,\n",
              "    11,\n",
              "    436,\n",
              "    366,\n",
              "    1566,\n",
              "    300,\n",
              "    264,\n",
              "    4722],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3504677069814582,\n",
              "   'compression_ratio': 1.6201117318435754,\n",
              "   'no_speech_prob': 5.10077879880555e-05},\n",
              "  {'id': 24,\n",
              "   'seek': 15572,\n",
              "   'start': 155.72,\n",
              "   'end': 162.28,\n",
              "   'text': ' quality estimation is an activity needed at various stages of software development.',\n",
              "   'tokens': [3125,\n",
              "    35701,\n",
              "    307,\n",
              "    364,\n",
              "    5191,\n",
              "    2978,\n",
              "    412,\n",
              "    3683,\n",
              "    10232,\n",
              "    295,\n",
              "    4722,\n",
              "    3250,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42330207824707033,\n",
              "   'compression_ratio': 1.6026200873362446,\n",
              "   'no_speech_prob': 0.0001651749189477414},\n",
              "  {'id': 25,\n",
              "   'seek': 15572,\n",
              "   'start': 162.28,\n",
              "   'end': 168.28,\n",
              "   'text': ' So when people are going to develop any software, so mainly they will concentrate on quality',\n",
              "   'tokens': [407,\n",
              "    562,\n",
              "    561,\n",
              "    366,\n",
              "    516,\n",
              "    281,\n",
              "    1499,\n",
              "    604,\n",
              "    4722,\n",
              "    11,\n",
              "    370,\n",
              "    8704,\n",
              "    436,\n",
              "    486,\n",
              "    18089,\n",
              "    322,\n",
              "    3125],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42330207824707033,\n",
              "   'compression_ratio': 1.6026200873362446,\n",
              "   'no_speech_prob': 0.0001651749189477414},\n",
              "  {'id': 26,\n",
              "   'seek': 15572,\n",
              "   'start': 168.28,\n",
              "   'end': 169.44,\n",
              "   'text': ' and everything.',\n",
              "   'tokens': [293, 1203, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42330207824707033,\n",
              "   'compression_ratio': 1.6026200873362446,\n",
              "   'no_speech_prob': 0.0001651749189477414},\n",
              "  {'id': 27,\n",
              "   'seek': 15572,\n",
              "   'start': 169.44,\n",
              "   'end': 175.72,\n",
              "   'text': ' So already we know that one problem can be solved with the help of different things.',\n",
              "   'tokens': [407,\n",
              "    1217,\n",
              "    321,\n",
              "    458,\n",
              "    300,\n",
              "    472,\n",
              "    1154,\n",
              "    393,\n",
              "    312,\n",
              "    13041,\n",
              "    365,\n",
              "    264,\n",
              "    854,\n",
              "    295,\n",
              "    819,\n",
              "    721,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42330207824707033,\n",
              "   'compression_ratio': 1.6026200873362446,\n",
              "   'no_speech_prob': 0.0001651749189477414},\n",
              "  {'id': 28,\n",
              "   'seek': 15572,\n",
              "   'start': 175.72,\n",
              "   'end': 183.68,\n",
              "   'text': ' For example, when you consider one example like to find out whether the number is a right',\n",
              "   'tokens': [1171,\n",
              "    1365,\n",
              "    11,\n",
              "    562,\n",
              "    291,\n",
              "    1949,\n",
              "    472,\n",
              "    1365,\n",
              "    411,\n",
              "    281,\n",
              "    915,\n",
              "    484,\n",
              "    1968,\n",
              "    264,\n",
              "    1230,\n",
              "    307,\n",
              "    257,\n",
              "    558],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42330207824707033,\n",
              "   'compression_ratio': 1.6026200873362446,\n",
              "   'no_speech_prob': 0.0001651749189477414},\n",
              "  {'id': 29,\n",
              "   'seek': 18368,\n",
              "   'start': 183.68,\n",
              "   'end': 188.96,\n",
              "   'text': ' number or not, or else whether you want to find out whether the number is a strong number',\n",
              "   'tokens': [1230,\n",
              "    420,\n",
              "    406,\n",
              "    11,\n",
              "    420,\n",
              "    1646,\n",
              "    1968,\n",
              "    291,\n",
              "    528,\n",
              "    281,\n",
              "    915,\n",
              "    484,\n",
              "    1968,\n",
              "    264,\n",
              "    1230,\n",
              "    307,\n",
              "    257,\n",
              "    2068,\n",
              "    1230],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4367446517944336,\n",
              "   'compression_ratio': 1.7857142857142858,\n",
              "   'no_speech_prob': 8.188093488570303e-05},\n",
              "  {'id': 30,\n",
              "   'seek': 18368,\n",
              "   'start': 188.96,\n",
              "   'end': 193.52,\n",
              "   'text': \" or not, or want to reverse the number, or there's some exergence.\",\n",
              "   'tokens': [420,\n",
              "    406,\n",
              "    11,\n",
              "    420,\n",
              "    528,\n",
              "    281,\n",
              "    9943,\n",
              "    264,\n",
              "    1230,\n",
              "    11,\n",
              "    420,\n",
              "    456,\n",
              "    311,\n",
              "    512,\n",
              "    454,\n",
              "    260,\n",
              "    1766,\n",
              "    384,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4367446517944336,\n",
              "   'compression_ratio': 1.7857142857142858,\n",
              "   'no_speech_prob': 8.188093488570303e-05},\n",
              "  {'id': 31,\n",
              "   'seek': 18368,\n",
              "   'start': 193.52,\n",
              "   'end': 201.96,\n",
              "   'text': ' So if you assume some problem, for that problem, you can find different solutions.',\n",
              "   'tokens': [407,\n",
              "    498,\n",
              "    291,\n",
              "    6552,\n",
              "    512,\n",
              "    1154,\n",
              "    11,\n",
              "    337,\n",
              "    300,\n",
              "    1154,\n",
              "    11,\n",
              "    291,\n",
              "    393,\n",
              "    915,\n",
              "    819,\n",
              "    6547,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4367446517944336,\n",
              "   'compression_ratio': 1.7857142857142858,\n",
              "   'no_speech_prob': 8.188093488570303e-05},\n",
              "  {'id': 32,\n",
              "   'seek': 18368,\n",
              "   'start': 201.96,\n",
              "   'end': 203.68,\n",
              "   'text': ' So everything is correct.',\n",
              "   'tokens': [407, 1203, 307, 3006, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4367446517944336,\n",
              "   'compression_ratio': 1.7857142857142858,\n",
              "   'no_speech_prob': 8.188093488570303e-05},\n",
              "  {'id': 33,\n",
              "   'seek': 18368,\n",
              "   'start': 203.68,\n",
              "   'end': 210.20000000000002,\n",
              "   'text': ' When you execute n number of programs, for example, n users are there, and n users, they',\n",
              "   'tokens': [1133,\n",
              "    291,\n",
              "    14483,\n",
              "    297,\n",
              "    1230,\n",
              "    295,\n",
              "    4268,\n",
              "    11,\n",
              "    337,\n",
              "    1365,\n",
              "    11,\n",
              "    297,\n",
              "    5022,\n",
              "    366,\n",
              "    456,\n",
              "    11,\n",
              "    293,\n",
              "    297,\n",
              "    5022,\n",
              "    11,\n",
              "    436],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4367446517944336,\n",
              "   'compression_ratio': 1.7857142857142858,\n",
              "   'no_speech_prob': 8.188093488570303e-05},\n",
              "  {'id': 34,\n",
              "   'seek': 18368,\n",
              "   'start': 210.20000000000002,\n",
              "   'end': 211.20000000000002,\n",
              "   'text': ' will give n programs.',\n",
              "   'tokens': [486, 976, 297, 4268, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4367446517944336,\n",
              "   'compression_ratio': 1.7857142857142858,\n",
              "   'no_speech_prob': 8.188093488570303e-05},\n",
              "  {'id': 35,\n",
              "   'seek': 21120,\n",
              "   'start': 211.2,\n",
              "   'end': 219.83999999999997,\n",
              "   'text': ' All n programs will get the same output, but they will consider some applications only.',\n",
              "   'tokens': [1057,\n",
              "    297,\n",
              "    4268,\n",
              "    486,\n",
              "    483,\n",
              "    264,\n",
              "    912,\n",
              "    5598,\n",
              "    11,\n",
              "    457,\n",
              "    436,\n",
              "    486,\n",
              "    1949,\n",
              "    512,\n",
              "    5821,\n",
              "    787,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4030245163861443,\n",
              "   'compression_ratio': 1.7067307692307692,\n",
              "   'no_speech_prob': 8.811596489977092e-05},\n",
              "  {'id': 36,\n",
              "   'seek': 21120,\n",
              "   'start': 219.83999999999997,\n",
              "   'end': 224.04,\n",
              "   'text': ' They will not consider all n programs to implement it.',\n",
              "   'tokens': [814, 486, 406, 1949, 439, 297, 4268, 281, 4445, 309, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4030245163861443,\n",
              "   'compression_ratio': 1.7067307692307692,\n",
              "   'no_speech_prob': 8.811596489977092e-05},\n",
              "  {'id': 37,\n",
              "   'seek': 21120,\n",
              "   'start': 224.04,\n",
              "   'end': 225.04,\n",
              "   'text': ' Why?',\n",
              "   'tokens': [1545, 30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4030245163861443,\n",
              "   'compression_ratio': 1.7067307692307692,\n",
              "   'no_speech_prob': 8.811596489977092e-05},\n",
              "  {'id': 38,\n",
              "   'seek': 21120,\n",
              "   'start': 225.04,\n",
              "   'end': 229.76,\n",
              "   'text': ' Because they may need some time complexity and space complexity also.',\n",
              "   'tokens': [1436, 436, 815, 643, 512, 565, 14024, 293, 1901, 14024, 611, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4030245163861443,\n",
              "   'compression_ratio': 1.7067307692307692,\n",
              "   'no_speech_prob': 8.811596489977092e-05},\n",
              "  {'id': 39,\n",
              "   'seek': 21120,\n",
              "   'start': 229.76,\n",
              "   'end': 235.76,\n",
              "   'text': ' So the program should execute as early as possible in a good time manner and should',\n",
              "   'tokens': [407,\n",
              "    264,\n",
              "    1461,\n",
              "    820,\n",
              "    14483,\n",
              "    382,\n",
              "    2440,\n",
              "    382,\n",
              "    1944,\n",
              "    294,\n",
              "    257,\n",
              "    665,\n",
              "    565,\n",
              "    9060,\n",
              "    293,\n",
              "    820],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4030245163861443,\n",
              "   'compression_ratio': 1.7067307692307692,\n",
              "   'no_speech_prob': 8.811596489977092e-05},\n",
              "  {'id': 40,\n",
              "   'seek': 21120,\n",
              "   'start': 235.76,\n",
              "   'end': 237.76,\n",
              "   'text': ' use very less memory.',\n",
              "   'tokens': [764, 588, 1570, 4675, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4030245163861443,\n",
              "   'compression_ratio': 1.7067307692307692,\n",
              "   'no_speech_prob': 8.811596489977092e-05},\n",
              "  {'id': 41,\n",
              "   'seek': 21120,\n",
              "   'start': 237.76,\n",
              "   'end': 240.76,\n",
              "   'text': ' These are the main constraints.',\n",
              "   'tokens': [1981, 366, 264, 2135, 18491, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4030245163861443,\n",
              "   'compression_ratio': 1.7067307692307692,\n",
              "   'no_speech_prob': 8.811596489977092e-05},\n",
              "  {'id': 42,\n",
              "   'seek': 24076,\n",
              "   'start': 240.76,\n",
              "   'end': 246.0,\n",
              "   'text': ' So when you consider these constraints, then some programs will be assured and some programs',\n",
              "   'tokens': [407,\n",
              "    562,\n",
              "    291,\n",
              "    1949,\n",
              "    613,\n",
              "    18491,\n",
              "    11,\n",
              "    550,\n",
              "    512,\n",
              "    4268,\n",
              "    486,\n",
              "    312,\n",
              "    23426,\n",
              "    293,\n",
              "    512,\n",
              "    4268],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5157272020975748,\n",
              "   'compression_ratio': 1.3944954128440368,\n",
              "   'no_speech_prob': 0.0003703366674017161},\n",
              "  {'id': 43,\n",
              "   'seek': 24076,\n",
              "   'start': 246.0,\n",
              "   'end': 248.44,\n",
              "   'text': ' only will work.',\n",
              "   'tokens': [787, 486, 589, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5157272020975748,\n",
              "   'compression_ratio': 1.3944954128440368,\n",
              "   'no_speech_prob': 0.0003703366674017161},\n",
              "  {'id': 44,\n",
              "   'seek': 24844,\n",
              "   'start': 248.44,\n",
              "   'end': 275.52,\n",
              "   'text': ' So that will decide based on the situation.',\n",
              "   'tokens': [407, 300, 486, 4536, 2361, 322, 264, 2590, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6058704669658954,\n",
              "   'compression_ratio': 0.86,\n",
              "   'no_speech_prob': 0.00015555397840216756},\n",
              "  {'id': 45,\n",
              "   'seek': 27552,\n",
              "   'start': 275.52,\n",
              "   'end': 300.47999999999996,\n",
              "   'text': ' Next slide, please.',\n",
              "   'tokens': [3087, 4137, 11, 1767, 13],\n",
              "   'temperature': 1.0,\n",
              "   'avg_logprob': -1.235526402791341,\n",
              "   'compression_ratio': 0.7037037037037037,\n",
              "   'no_speech_prob': 2.7354964913683943e-05},\n",
              "  {'id': 46,\n",
              "   'seek': 42048,\n",
              "   'start': 420.48,\n",
              "   'end': 435.48,\n",
              "   'text': ' Sorry. So here the thing is, when we people are working with programming styles, so all',\n",
              "   'tokens': [4919,\n",
              "    13,\n",
              "    407,\n",
              "    510,\n",
              "    264,\n",
              "    551,\n",
              "    307,\n",
              "    11,\n",
              "    562,\n",
              "    321,\n",
              "    561,\n",
              "    366,\n",
              "    1364,\n",
              "    365,\n",
              "    9410,\n",
              "    13273,\n",
              "    11,\n",
              "    370,\n",
              "    439],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4911676837551978,\n",
              "   'compression_ratio': 1.5917159763313609,\n",
              "   'no_speech_prob': 0.6759941577911377},\n",
              "  {'id': 47,\n",
              "   'seek': 42048,\n",
              "   'start': 435.48,\n",
              "   'end': 441.32,\n",
              "   'text': \" programmers write their own program, but we don't consider all the programs. The programming\",\n",
              "   'tokens': [41504,\n",
              "    2464,\n",
              "    641,\n",
              "    1065,\n",
              "    1461,\n",
              "    11,\n",
              "    457,\n",
              "    321,\n",
              "    500,\n",
              "    380,\n",
              "    1949,\n",
              "    439,\n",
              "    264,\n",
              "    4268,\n",
              "    13,\n",
              "    440,\n",
              "    9410],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4911676837551978,\n",
              "   'compression_ratio': 1.5917159763313609,\n",
              "   'no_speech_prob': 0.6759941577911377},\n",
              "  {'id': 48,\n",
              "   'seek': 42048,\n",
              "   'start': 441.32,\n",
              "   'end': 447.56,\n",
              "   'text': \" which is giving best performance, then only we'll consider. So when you're planning some\",\n",
              "   'tokens': [597,\n",
              "    307,\n",
              "    2902,\n",
              "    1151,\n",
              "    3389,\n",
              "    11,\n",
              "    550,\n",
              "    787,\n",
              "    321,\n",
              "    603,\n",
              "    1949,\n",
              "    13,\n",
              "    407,\n",
              "    562,\n",
              "    291,\n",
              "    434,\n",
              "    5038,\n",
              "    512],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4911676837551978,\n",
              "   'compression_ratio': 1.5917159763313609,\n",
              "   'no_speech_prob': 0.6759941577911377},\n",
              "  {'id': 49,\n",
              "   'seek': 44756,\n",
              "   'start': 447.56,\n",
              "   'end': 454.96,\n",
              "   'text': ' performance, they may have different factors. So among these factors, they will check it.',\n",
              "   'tokens': [3389,\n",
              "    11,\n",
              "    436,\n",
              "    815,\n",
              "    362,\n",
              "    819,\n",
              "    6771,\n",
              "    13,\n",
              "    407,\n",
              "    3654,\n",
              "    613,\n",
              "    6771,\n",
              "    11,\n",
              "    436,\n",
              "    486,\n",
              "    1520,\n",
              "    309,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.33558701409233943,\n",
              "   'compression_ratio': 1.775609756097561,\n",
              "   'no_speech_prob': 0.001504693878814578},\n",
              "  {'id': 50,\n",
              "   'seek': 44756,\n",
              "   'start': 454.96,\n",
              "   'end': 459.84000000000003,\n",
              "   'text': ' But here in the part of machine learning, so what we are going to discuss is, so which',\n",
              "   'tokens': [583,\n",
              "    510,\n",
              "    294,\n",
              "    264,\n",
              "    644,\n",
              "    295,\n",
              "    3479,\n",
              "    2539,\n",
              "    11,\n",
              "    370,\n",
              "    437,\n",
              "    321,\n",
              "    366,\n",
              "    516,\n",
              "    281,\n",
              "    2248,\n",
              "    307,\n",
              "    11,\n",
              "    370,\n",
              "    597],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.33558701409233943,\n",
              "   'compression_ratio': 1.775609756097561,\n",
              "   'no_speech_prob': 0.001504693878814578},\n",
              "  {'id': 51,\n",
              "   'seek': 44756,\n",
              "   'start': 459.84000000000003,\n",
              "   'end': 468.0,\n",
              "   'text': ' one is best, which one is better. So for that, we are using SVM and neural network algorithms.',\n",
              "   'tokens': [472,\n",
              "    307,\n",
              "    1151,\n",
              "    11,\n",
              "    597,\n",
              "    472,\n",
              "    307,\n",
              "    1101,\n",
              "    13,\n",
              "    407,\n",
              "    337,\n",
              "    300,\n",
              "    11,\n",
              "    321,\n",
              "    366,\n",
              "    1228,\n",
              "    31910,\n",
              "    44,\n",
              "    293,\n",
              "    18161,\n",
              "    3209,\n",
              "    14642,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.33558701409233943,\n",
              "   'compression_ratio': 1.775609756097561,\n",
              "   'no_speech_prob': 0.001504693878814578},\n",
              "  {'id': 52,\n",
              "   'seek': 44756,\n",
              "   'start': 468.0,\n",
              "   'end': 473.0,\n",
              "   'text': ' So they will find the accuracy, which is having high accuracy, which is having low accuracy,',\n",
              "   'tokens': [407,\n",
              "    436,\n",
              "    486,\n",
              "    915,\n",
              "    264,\n",
              "    14170,\n",
              "    11,\n",
              "    597,\n",
              "    307,\n",
              "    1419,\n",
              "    1090,\n",
              "    14170,\n",
              "    11,\n",
              "    597,\n",
              "    307,\n",
              "    1419,\n",
              "    2295,\n",
              "    14170,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.33558701409233943,\n",
              "   'compression_ratio': 1.775609756097561,\n",
              "   'no_speech_prob': 0.001504693878814578},\n",
              "  {'id': 53,\n",
              "   'seek': 47300,\n",
              "   'start': 473.0,\n",
              "   'end': 480.0,\n",
              "   'text': ' and everything will be mentioned in machine learning algorithm. So these are the total',\n",
              "   'tokens': [293,\n",
              "    1203,\n",
              "    486,\n",
              "    312,\n",
              "    2835,\n",
              "    294,\n",
              "    3479,\n",
              "    2539,\n",
              "    9284,\n",
              "    13,\n",
              "    407,\n",
              "    613,\n",
              "    366,\n",
              "    264,\n",
              "    3217],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.45928404761142416,\n",
              "   'compression_ratio': 1.5574712643678161,\n",
              "   'no_speech_prob': 0.0011109801707789302},\n",
              "  {'id': 54,\n",
              "   'seek': 47300,\n",
              "   'start': 480.0,\n",
              "   'end': 496.36,\n",
              "   'text': ' documentation which we are having. So when it comes to execution part, so in the folder,',\n",
              "   'tokens': [14333,\n",
              "    597,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    13,\n",
              "    407,\n",
              "    562,\n",
              "    309,\n",
              "    1487,\n",
              "    281,\n",
              "    15058,\n",
              "    644,\n",
              "    11,\n",
              "    370,\n",
              "    294,\n",
              "    264,\n",
              "    10820,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.45928404761142416,\n",
              "   'compression_ratio': 1.5574712643678161,\n",
              "   'no_speech_prob': 0.0011109801707789302},\n",
              "  {'id': 55,\n",
              "   'seek': 47300,\n",
              "   'start': 496.36,\n",
              "   'end': 502.88,\n",
              "   'text': ' software quality folder is there, there just click on run. When you click on run, automatically',\n",
              "   'tokens': [4722,\n",
              "    3125,\n",
              "    10820,\n",
              "    307,\n",
              "    456,\n",
              "    11,\n",
              "    456,\n",
              "    445,\n",
              "    2052,\n",
              "    322,\n",
              "    1190,\n",
              "    13,\n",
              "    1133,\n",
              "    291,\n",
              "    2052,\n",
              "    322,\n",
              "    1190,\n",
              "    11,\n",
              "    6772],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.45928404761142416,\n",
              "   'compression_ratio': 1.5574712643678161,\n",
              "   'no_speech_prob': 0.0011109801707789302},\n",
              "  {'id': 56,\n",
              "   'seek': 50288,\n",
              "   'start': 502.88,\n",
              "   'end': 526.52,\n",
              "   'text': ' your application will start execution.',\n",
              "   'tokens': [428, 3861, 486, 722, 15058, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26715502738952634,\n",
              "   'compression_ratio': 0.8636363636363636,\n",
              "   'no_speech_prob': 0.0035284082405269146},\n",
              "  {'id': 57,\n",
              "   'seek': 52652,\n",
              "   'start': 526.52,\n",
              "   'end': 540.52,\n",
              "   'text': ' So it is having PPT also. And generally, the machine learning algorithms will process these',\n",
              "   'tokens': [407,\n",
              "    309,\n",
              "    307,\n",
              "    1419,\n",
              "    37369,\n",
              "    51,\n",
              "    611,\n",
              "    13,\n",
              "    400,\n",
              "    5101,\n",
              "    11,\n",
              "    264,\n",
              "    3479,\n",
              "    2539,\n",
              "    14642,\n",
              "    486,\n",
              "    1399,\n",
              "    613],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43810116160999646,\n",
              "   'compression_ratio': 1.6506024096385543,\n",
              "   'no_speech_prob': 0.00031353969825431705},\n",
              "  {'id': 58,\n",
              "   'seek': 52652,\n",
              "   'start': 540.52,\n",
              "   'end': 548.56,\n",
              "   'text': ' things. So whatever the data set we are having, first they will apply cleaning and pre-processing,',\n",
              "   'tokens': [721,\n",
              "    13,\n",
              "    407,\n",
              "    2035,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    11,\n",
              "    700,\n",
              "    436,\n",
              "    486,\n",
              "    3079,\n",
              "    8924,\n",
              "    293,\n",
              "    659,\n",
              "    12,\n",
              "    41075,\n",
              "    278,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43810116160999646,\n",
              "   'compression_ratio': 1.6506024096385543,\n",
              "   'no_speech_prob': 0.00031353969825431705},\n",
              "  {'id': 59,\n",
              "   'seek': 52652,\n",
              "   'start': 548.56,\n",
              "   'end': 553.28,\n",
              "   'text': ' then they will find the data set and they will select the future. So futures in the',\n",
              "   'tokens': [550,\n",
              "    436,\n",
              "    486,\n",
              "    915,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    293,\n",
              "    436,\n",
              "    486,\n",
              "    3048,\n",
              "    264,\n",
              "    2027,\n",
              "    13,\n",
              "    407,\n",
              "    26071,\n",
              "    294,\n",
              "    264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43810116160999646,\n",
              "   'compression_ratio': 1.6506024096385543,\n",
              "   'no_speech_prob': 0.00031353969825431705},\n",
              "  {'id': 60,\n",
              "   'seek': 55328,\n",
              "   'start': 553.28,\n",
              "   'end': 559.28,\n",
              "   'text': ' sense here in machine learning, so table fields, we call it as a future setting. So if you',\n",
              "   'tokens': [2020,\n",
              "    510,\n",
              "    294,\n",
              "    3479,\n",
              "    2539,\n",
              "    11,\n",
              "    370,\n",
              "    3199,\n",
              "    7909,\n",
              "    11,\n",
              "    321,\n",
              "    818,\n",
              "    309,\n",
              "    382,\n",
              "    257,\n",
              "    2027,\n",
              "    3287,\n",
              "    13,\n",
              "    407,\n",
              "    498,\n",
              "    291],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3974951820812006,\n",
              "   'compression_ratio': 1.8434343434343434,\n",
              "   'no_speech_prob': 0.00020224352192599326},\n",
              "  {'id': 61,\n",
              "   'seek': 55328,\n",
              "   'start': 559.28,\n",
              "   'end': 564.28,\n",
              "   'text': ' consider any table, it may have a number of fields, columns are there. So that columns',\n",
              "   'tokens': [1949,\n",
              "    604,\n",
              "    3199,\n",
              "    11,\n",
              "    309,\n",
              "    815,\n",
              "    362,\n",
              "    257,\n",
              "    1230,\n",
              "    295,\n",
              "    7909,\n",
              "    11,\n",
              "    13766,\n",
              "    366,\n",
              "    456,\n",
              "    13,\n",
              "    407,\n",
              "    300,\n",
              "    13766],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3974951820812006,\n",
              "   'compression_ratio': 1.8434343434343434,\n",
              "   'no_speech_prob': 0.00020224352192599326},\n",
              "  {'id': 62,\n",
              "   'seek': 55328,\n",
              "   'start': 564.28,\n",
              "   'end': 570.1999999999999,\n",
              "   'text': ' will be mentioned as a future. So they will select the futures and then they will do the',\n",
              "   'tokens': [486,\n",
              "    312,\n",
              "    2835,\n",
              "    382,\n",
              "    257,\n",
              "    2027,\n",
              "    13,\n",
              "    407,\n",
              "    436,\n",
              "    486,\n",
              "    3048,\n",
              "    264,\n",
              "    26071,\n",
              "    293,\n",
              "    550,\n",
              "    436,\n",
              "    486,\n",
              "    360,\n",
              "    264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3974951820812006,\n",
              "   'compression_ratio': 1.8434343434343434,\n",
              "   'no_speech_prob': 0.00020224352192599326},\n",
              "  {'id': 63,\n",
              "   'seek': 55328,\n",
              "   'start': 570.1999999999999,\n",
              "   'end': 580.16,\n",
              "   'text': ' input and they will apply the machine learning algorithms. But then they will get the predictions.',\n",
              "   'tokens': [4846,\n",
              "    293,\n",
              "    436,\n",
              "    486,\n",
              "    3079,\n",
              "    264,\n",
              "    3479,\n",
              "    2539,\n",
              "    14642,\n",
              "    13,\n",
              "    583,\n",
              "    550,\n",
              "    436,\n",
              "    486,\n",
              "    483,\n",
              "    264,\n",
              "    21264,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3974951820812006,\n",
              "   'compression_ratio': 1.8434343434343434,\n",
              "   'no_speech_prob': 0.00020224352192599326},\n",
              "  {'id': 64,\n",
              "   'seek': 58016,\n",
              "   'start': 580.16,\n",
              "   'end': 595.48,\n",
              "   'text': ' So for execution it will take some time. We need to wait. So this is the table. So first',\n",
              "   'tokens': [407,\n",
              "    337,\n",
              "    15058,\n",
              "    309,\n",
              "    486,\n",
              "    747,\n",
              "    512,\n",
              "    565,\n",
              "    13,\n",
              "    492,\n",
              "    643,\n",
              "    281,\n",
              "    1699,\n",
              "    13,\n",
              "    407,\n",
              "    341,\n",
              "    307,\n",
              "    264,\n",
              "    3199,\n",
              "    13,\n",
              "    407,\n",
              "    700],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3938234301580899,\n",
              "   'compression_ratio': 1.4971098265895955,\n",
              "   'no_speech_prob': 0.0005566795007325709},\n",
              "  {'id': 65,\n",
              "   'seek': 58016,\n",
              "   'start': 595.48,\n",
              "   'end': 603.16,\n",
              "   'text': \" you're supposed to upload the data set. So in data set, we're having different types\",\n",
              "   'tokens': [291,\n",
              "    434,\n",
              "    3442,\n",
              "    281,\n",
              "    6580,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    407,\n",
              "    294,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    321,\n",
              "    434,\n",
              "    1419,\n",
              "    819,\n",
              "    3467],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3938234301580899,\n",
              "   'compression_ratio': 1.4971098265895955,\n",
              "   'no_speech_prob': 0.0005566795007325709},\n",
              "  {'id': 66,\n",
              "   'seek': 58016,\n",
              "   'start': 603.16,\n",
              "   'end': 608.56,\n",
              "   'text': ' of data sets. Among these things, whichever data set you want, you can choose it. You',\n",
              "   'tokens': [295,\n",
              "    1412,\n",
              "    6352,\n",
              "    13,\n",
              "    16119,\n",
              "    613,\n",
              "    721,\n",
              "    11,\n",
              "    24123,\n",
              "    1412,\n",
              "    992,\n",
              "    291,\n",
              "    528,\n",
              "    11,\n",
              "    291,\n",
              "    393,\n",
              "    2826,\n",
              "    309,\n",
              "    13,\n",
              "    509],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3938234301580899,\n",
              "   'compression_ratio': 1.4971098265895955,\n",
              "   'no_speech_prob': 0.0005566795007325709},\n",
              "  {'id': 67,\n",
              "   'seek': 60856,\n",
              "   'start': 608.56,\n",
              "   'end': 610.56,\n",
              "   'text': ' need to consider one data set.',\n",
              "   'tokens': [643, 281, 1949, 472, 1412, 992, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4626265539639238,\n",
              "   'compression_ratio': 1.6352941176470588,\n",
              "   'no_speech_prob': 0.0004305488255340606},\n",
              "  {'id': 68,\n",
              "   'seek': 60856,\n",
              "   'start': 610.56,\n",
              "   'end': 615.56,\n",
              "   'text': \" These are different software's data which we have collected.\",\n",
              "   'tokens': [1981, 366, 819, 4722, 311, 1412, 597, 321, 362, 11087, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4626265539639238,\n",
              "   'compression_ratio': 1.6352941176470588,\n",
              "   'no_speech_prob': 0.0004305488255340606},\n",
              "  {'id': 69,\n",
              "   'seek': 60856,\n",
              "   'start': 615.56,\n",
              "   'end': 624.52,\n",
              "   'text': ' Yeah, which is already recorded. And if you have your own data set, you can also add here.',\n",
              "   'tokens': [865,\n",
              "    11,\n",
              "    597,\n",
              "    307,\n",
              "    1217,\n",
              "    8287,\n",
              "    13,\n",
              "    400,\n",
              "    498,\n",
              "    291,\n",
              "    362,\n",
              "    428,\n",
              "    1065,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    291,\n",
              "    393,\n",
              "    611,\n",
              "    909,\n",
              "    510,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4626265539639238,\n",
              "   'compression_ratio': 1.6352941176470588,\n",
              "   'no_speech_prob': 0.0004305488255340606},\n",
              "  {'id': 70,\n",
              "   'seek': 60856,\n",
              "   'start': 624.52,\n",
              "   'end': 629.4399999999999,\n",
              "   'text': ' So whatever it may be. So here they gave some data sets which is related to different different',\n",
              "   'tokens': [407,\n",
              "    2035,\n",
              "    309,\n",
              "    815,\n",
              "    312,\n",
              "    13,\n",
              "    407,\n",
              "    510,\n",
              "    436,\n",
              "    2729,\n",
              "    512,\n",
              "    1412,\n",
              "    6352,\n",
              "    597,\n",
              "    307,\n",
              "    4077,\n",
              "    281,\n",
              "    819,\n",
              "    819],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4626265539639238,\n",
              "   'compression_ratio': 1.6352941176470588,\n",
              "   'no_speech_prob': 0.0004305488255340606},\n",
              "  {'id': 71,\n",
              "   'seek': 62944,\n",
              "   'start': 629.44,\n",
              "   'end': 643.96,\n",
              "   'text': \" software's. And they recorded yearly wise. So just you need to choose upload data set.\",\n",
              "   'tokens': [4722,\n",
              "    311,\n",
              "    13,\n",
              "    400,\n",
              "    436,\n",
              "    8287,\n",
              "    39102,\n",
              "    10829,\n",
              "    13,\n",
              "    407,\n",
              "    445,\n",
              "    291,\n",
              "    643,\n",
              "    281,\n",
              "    2826,\n",
              "    6580,\n",
              "    1412,\n",
              "    992,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3716896375020345,\n",
              "   'compression_ratio': 1.536723163841808,\n",
              "   'no_speech_prob': 0.00018536450807005167},\n",
              "  {'id': 72,\n",
              "   'seek': 62944,\n",
              "   'start': 643.96,\n",
              "   'end': 649.2,\n",
              "   'text': \" So we are having different different data sets. So I'm using some Hadoop trunk. So it\",\n",
              "   'tokens': [407,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    819,\n",
              "    819,\n",
              "    1412,\n",
              "    6352,\n",
              "    13,\n",
              "    407,\n",
              "    286,\n",
              "    478,\n",
              "    1228,\n",
              "    512,\n",
              "    389,\n",
              "    1573,\n",
              "    404,\n",
              "    19849,\n",
              "    13,\n",
              "    407,\n",
              "    309],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3716896375020345,\n",
              "   'compression_ratio': 1.536723163841808,\n",
              "   'no_speech_prob': 0.00018536450807005167},\n",
              "  {'id': 73,\n",
              "   'seek': 62944,\n",
              "   'start': 649.2,\n",
              "   'end': 658.12,\n",
              "   'text': ' is having only 2020. We can choose that one. So once you uploaded the data set, then pre-processing',\n",
              "   'tokens': [307,\n",
              "    1419,\n",
              "    787,\n",
              "    4808,\n",
              "    13,\n",
              "    492,\n",
              "    393,\n",
              "    2826,\n",
              "    300,\n",
              "    472,\n",
              "    13,\n",
              "    407,\n",
              "    1564,\n",
              "    291,\n",
              "    17135,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    550,\n",
              "    659,\n",
              "    12,\n",
              "    41075,\n",
              "    278],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3716896375020345,\n",
              "   'compression_ratio': 1.536723163841808,\n",
              "   'no_speech_prob': 0.00018536450807005167},\n",
              "  {'id': 74,\n",
              "   'seek': 65812,\n",
              "   'start': 658.12,\n",
              "   'end': 667.5600000000001,\n",
              "   'text': \" is going to work. So we're having the data sets information. Some are there. Totally\",\n",
              "   'tokens': [307,\n",
              "    516,\n",
              "    281,\n",
              "    589,\n",
              "    13,\n",
              "    407,\n",
              "    321,\n",
              "    434,\n",
              "    1419,\n",
              "    264,\n",
              "    1412,\n",
              "    6352,\n",
              "    1589,\n",
              "    13,\n",
              "    2188,\n",
              "    366,\n",
              "    456,\n",
              "    13,\n",
              "    22837],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.524785969355335,\n",
              "   'compression_ratio': 1.543859649122807,\n",
              "   'no_speech_prob': 0.000265524402493611},\n",
              "  {'id': 75,\n",
              "   'seek': 65812,\n",
              "   'start': 667.5600000000001,\n",
              "   'end': 679.92,\n",
              "   'text': ' 4,000, sorry, 41,667 records are there and 40 features are there. So 41,667 rows and',\n",
              "   'tokens': [1017,\n",
              "    11,\n",
              "    1360,\n",
              "    11,\n",
              "    2597,\n",
              "    11,\n",
              "    18173,\n",
              "    11,\n",
              "    15237,\n",
              "    22,\n",
              "    7724,\n",
              "    366,\n",
              "    456,\n",
              "    293,\n",
              "    3356,\n",
              "    4122,\n",
              "    366,\n",
              "    456,\n",
              "    13,\n",
              "    407,\n",
              "    18173,\n",
              "    11,\n",
              "    15237,\n",
              "    22,\n",
              "    13241,\n",
              "    293],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.524785969355335,\n",
              "   'compression_ratio': 1.543859649122807,\n",
              "   'no_speech_prob': 0.000265524402493611},\n",
              "  {'id': 76,\n",
              "   'seek': 65812,\n",
              "   'start': 679.92,\n",
              "   'end': 686.6,\n",
              "   'text': ' 40 columns. Here columns in the sense we call it as features. And we are giving some graphical',\n",
              "   'tokens': [3356,\n",
              "    13766,\n",
              "    13,\n",
              "    1692,\n",
              "    13766,\n",
              "    294,\n",
              "    264,\n",
              "    2020,\n",
              "    321,\n",
              "    818,\n",
              "    309,\n",
              "    382,\n",
              "    4122,\n",
              "    13,\n",
              "    400,\n",
              "    321,\n",
              "    366,\n",
              "    2902,\n",
              "    512,\n",
              "    35942],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.524785969355335,\n",
              "   'compression_ratio': 1.543859649122807,\n",
              "   'no_speech_prob': 0.000265524402493611},\n",
              "  {'id': 77,\n",
              "   'seek': 68660,\n",
              "   'start': 686.6,\n",
              "   'end': 694.96,\n",
              "   'text': ' representation also. Of different different columns, SRFC, DIT, all the columns are there.',\n",
              "   'tokens': [10290,\n",
              "    611,\n",
              "    13,\n",
              "    2720,\n",
              "    819,\n",
              "    819,\n",
              "    13766,\n",
              "    11,\n",
              "    20840,\n",
              "    18671,\n",
              "    11,\n",
              "    413,\n",
              "    3927,\n",
              "    11,\n",
              "    439,\n",
              "    264,\n",
              "    13766,\n",
              "    366,\n",
              "    456,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3426537363152755,\n",
              "   'compression_ratio': 1.6188340807174888,\n",
              "   'no_speech_prob': 9.287449938710779e-05},\n",
              "  {'id': 78,\n",
              "   'seek': 68660,\n",
              "   'start': 694.96,\n",
              "   'end': 702.76,\n",
              "   'text': ' So it is giving information. And if you want to save this image, you can save it, but not',\n",
              "   'tokens': [407,\n",
              "    309,\n",
              "    307,\n",
              "    2902,\n",
              "    1589,\n",
              "    13,\n",
              "    400,\n",
              "    498,\n",
              "    291,\n",
              "    528,\n",
              "    281,\n",
              "    3155,\n",
              "    341,\n",
              "    3256,\n",
              "    11,\n",
              "    291,\n",
              "    393,\n",
              "    3155,\n",
              "    309,\n",
              "    11,\n",
              "    457,\n",
              "    406],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3426537363152755,\n",
              "   'compression_ratio': 1.6188340807174888,\n",
              "   'no_speech_prob': 9.287449938710779e-05},\n",
              "  {'id': 79,\n",
              "   'seek': 68660,\n",
              "   'start': 702.76,\n",
              "   'end': 710.08,\n",
              "   'text': \" required. Just I'm closing this one. So this is data which I uploaded. Once you uploaded\",\n",
              "   'tokens': [4739,\n",
              "    13,\n",
              "    1449,\n",
              "    286,\n",
              "    478,\n",
              "    10377,\n",
              "    341,\n",
              "    472,\n",
              "    13,\n",
              "    407,\n",
              "    341,\n",
              "    307,\n",
              "    1412,\n",
              "    597,\n",
              "    286,\n",
              "    17135,\n",
              "    13,\n",
              "    3443,\n",
              "    291,\n",
              "    17135],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3426537363152755,\n",
              "   'compression_ratio': 1.6188340807174888,\n",
              "   'no_speech_prob': 9.287449938710779e-05},\n",
              "  {'id': 80,\n",
              "   'seek': 68660,\n",
              "   'start': 710.08,\n",
              "   'end': 715.52,\n",
              "   'text': \" the data set, then you're supposed to pre-process the given data set. Pre-processing in the\",\n",
              "   'tokens': [264,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    550,\n",
              "    291,\n",
              "    434,\n",
              "    3442,\n",
              "    281,\n",
              "    659,\n",
              "    12,\n",
              "    41075,\n",
              "    264,\n",
              "    2212,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    6001,\n",
              "    12,\n",
              "    41075,\n",
              "    278,\n",
              "    294,\n",
              "    264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3426537363152755,\n",
              "   'compression_ratio': 1.6188340807174888,\n",
              "   'no_speech_prob': 9.287449938710779e-05},\n",
              "  {'id': 81,\n",
              "   'seek': 71552,\n",
              "   'start': 715.52,\n",
              "   'end': 721.64,\n",
              "   'text': ' sense it is going to check any null values are there or else any difficulties is there.',\n",
              "   'tokens': [2020,\n",
              "    309,\n",
              "    307,\n",
              "    516,\n",
              "    281,\n",
              "    1520,\n",
              "    604,\n",
              "    18184,\n",
              "    4190,\n",
              "    366,\n",
              "    456,\n",
              "    420,\n",
              "    1646,\n",
              "    604,\n",
              "    14399,\n",
              "    307,\n",
              "    456,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5011387325468517,\n",
              "   'compression_ratio': 1.6875,\n",
              "   'no_speech_prob': 0.00020622546435333788},\n",
              "  {'id': 82,\n",
              "   'seek': 71552,\n",
              "   'start': 721.64,\n",
              "   'end': 726.8,\n",
              "   'text': ' Everything will think. And if any null values or anything is there, then they will remove',\n",
              "   'tokens': [5471,\n",
              "    486,\n",
              "    519,\n",
              "    13,\n",
              "    400,\n",
              "    498,\n",
              "    604,\n",
              "    18184,\n",
              "    4190,\n",
              "    420,\n",
              "    1340,\n",
              "    307,\n",
              "    456,\n",
              "    11,\n",
              "    550,\n",
              "    436,\n",
              "    486,\n",
              "    4159],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5011387325468517,\n",
              "   'compression_ratio': 1.6875,\n",
              "   'no_speech_prob': 0.00020622546435333788},\n",
              "  {'id': 83,\n",
              "   'seek': 71552,\n",
              "   'start': 726.8,\n",
              "   'end': 731.4,\n",
              "   'text': \" the data set. They will remove the rows and which contains the null values. Just we're\",\n",
              "   'tokens': [264,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    814,\n",
              "    486,\n",
              "    4159,\n",
              "    264,\n",
              "    13241,\n",
              "    293,\n",
              "    597,\n",
              "    8306,\n",
              "    264,\n",
              "    18184,\n",
              "    4190,\n",
              "    13,\n",
              "    1449,\n",
              "    321,\n",
              "    434],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5011387325468517,\n",
              "   'compression_ratio': 1.6875,\n",
              "   'no_speech_prob': 0.00020622546435333788},\n",
              "  {'id': 84,\n",
              "   'seek': 71552,\n",
              "   'start': 731.4,\n",
              "   'end': 743.8,\n",
              "   'text': ' supposed to be pre-processed data set. It is having the qualified name, resolve things',\n",
              "   'tokens': [3442,\n",
              "    281,\n",
              "    312,\n",
              "    659,\n",
              "    12,\n",
              "    41075,\n",
              "    292,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    467,\n",
              "    307,\n",
              "    1419,\n",
              "    264,\n",
              "    15904,\n",
              "    1315,\n",
              "    11,\n",
              "    14151,\n",
              "    721],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5011387325468517,\n",
              "   'compression_ratio': 1.6875,\n",
              "   'no_speech_prob': 0.00020622546435333788},\n",
              "  {'id': 85,\n",
              "   'seek': 74380,\n",
              "   'start': 743.8,\n",
              "   'end': 752.92,\n",
              "   'text': ' and which is giving the maximum value which is having maximum value. So once it is pre-processed,',\n",
              "   'tokens': [293,\n",
              "    597,\n",
              "    307,\n",
              "    2902,\n",
              "    264,\n",
              "    6674,\n",
              "    2158,\n",
              "    597,\n",
              "    307,\n",
              "    1419,\n",
              "    6674,\n",
              "    2158,\n",
              "    13,\n",
              "    407,\n",
              "    1564,\n",
              "    309,\n",
              "    307,\n",
              "    659,\n",
              "    12,\n",
              "    41075,\n",
              "    292,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39028712681361605,\n",
              "   'compression_ratio': 1.630952380952381,\n",
              "   'no_speech_prob': 5.28540404047817e-05},\n",
              "  {'id': 86,\n",
              "   'seek': 74380,\n",
              "   'start': 752.92,\n",
              "   'end': 760.16,\n",
              "   'text': \" here I'm getting some data which is ready to pre-processing. And then feature selection\",\n",
              "   'tokens': [510,\n",
              "    286,\n",
              "    478,\n",
              "    1242,\n",
              "    512,\n",
              "    1412,\n",
              "    597,\n",
              "    307,\n",
              "    1919,\n",
              "    281,\n",
              "    659,\n",
              "    12,\n",
              "    41075,\n",
              "    278,\n",
              "    13,\n",
              "    400,\n",
              "    550,\n",
              "    4111,\n",
              "    9450],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39028712681361605,\n",
              "   'compression_ratio': 1.630952380952381,\n",
              "   'no_speech_prob': 5.28540404047817e-05},\n",
              "  {'id': 87,\n",
              "   'seek': 74380,\n",
              "   'start': 760.16,\n",
              "   'end': 767.68,\n",
              "   'text': ' algorithms. So we need to select the features. When you click on here, so it is going to',\n",
              "   'tokens': [14642,\n",
              "    13,\n",
              "    407,\n",
              "    321,\n",
              "    643,\n",
              "    281,\n",
              "    3048,\n",
              "    264,\n",
              "    4122,\n",
              "    13,\n",
              "    1133,\n",
              "    291,\n",
              "    2052,\n",
              "    322,\n",
              "    510,\n",
              "    11,\n",
              "    370,\n",
              "    309,\n",
              "    307,\n",
              "    516,\n",
              "    281],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39028712681361605,\n",
              "   'compression_ratio': 1.630952380952381,\n",
              "   'no_speech_prob': 5.28540404047817e-05},\n",
              "  {'id': 88,\n",
              "   'seek': 76768,\n",
              "   'start': 767.68,\n",
              "   'end': 777.4399999999999,\n",
              "   'text': ' give the information. This is a cross matrix. So we may have a number of features, 40 features',\n",
              "   'tokens': [976,\n",
              "    264,\n",
              "    1589,\n",
              "    13,\n",
              "    639,\n",
              "    307,\n",
              "    257,\n",
              "    3278,\n",
              "    8141,\n",
              "    13,\n",
              "    407,\n",
              "    321,\n",
              "    815,\n",
              "    362,\n",
              "    257,\n",
              "    1230,\n",
              "    295,\n",
              "    4122,\n",
              "    11,\n",
              "    3356,\n",
              "    4122],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4734386161521629,\n",
              "   'compression_ratio': 1.8708333333333333,\n",
              "   'no_speech_prob': 0.0002722706412896514},\n",
              "  {'id': 89,\n",
              "   'seek': 76768,\n",
              "   'start': 777.4399999999999,\n",
              "   'end': 782.04,\n",
              "   'text': \" are there. That's why that overlapping is happening. So, but here graphically, not only\",\n",
              "   'tokens': [366,\n",
              "    456,\n",
              "    13,\n",
              "    663,\n",
              "    311,\n",
              "    983,\n",
              "    300,\n",
              "    33535,\n",
              "    307,\n",
              "    2737,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    457,\n",
              "    510,\n",
              "    4295,\n",
              "    984,\n",
              "    11,\n",
              "    406,\n",
              "    787],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4734386161521629,\n",
              "   'compression_ratio': 1.8708333333333333,\n",
              "   'no_speech_prob': 0.0002722706412896514},\n",
              "  {'id': 90,\n",
              "   'seek': 76768,\n",
              "   'start': 782.04,\n",
              "   'end': 786.92,\n",
              "   'text': ' graphically textual in text wise, we can see here. So total features are found in the data',\n",
              "   'tokens': [4295,\n",
              "    984,\n",
              "    2487,\n",
              "    901,\n",
              "    294,\n",
              "    2487,\n",
              "    10829,\n",
              "    11,\n",
              "    321,\n",
              "    393,\n",
              "    536,\n",
              "    510,\n",
              "    13,\n",
              "    407,\n",
              "    3217,\n",
              "    4122,\n",
              "    366,\n",
              "    1352,\n",
              "    294,\n",
              "    264,\n",
              "    1412],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4734386161521629,\n",
              "   'compression_ratio': 1.8708333333333333,\n",
              "   'no_speech_prob': 0.0002722706412896514},\n",
              "  {'id': 91,\n",
              "   'seek': 76768,\n",
              "   'start': 786.92,\n",
              "   'end': 792.4,\n",
              "   'text': ' set before applying the feature selection. 39 is there. So total features found in the',\n",
              "   'tokens': [992,\n",
              "    949,\n",
              "    9275,\n",
              "    264,\n",
              "    4111,\n",
              "    9450,\n",
              "    13,\n",
              "    15238,\n",
              "    307,\n",
              "    456,\n",
              "    13,\n",
              "    407,\n",
              "    3217,\n",
              "    4122,\n",
              "    1352,\n",
              "    294,\n",
              "    264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4734386161521629,\n",
              "   'compression_ratio': 1.8708333333333333,\n",
              "   'no_speech_prob': 0.0002722706412896514},\n",
              "  {'id': 92,\n",
              "   'seek': 76768,\n",
              "   'start': 792.4,\n",
              "   'end': 797.4399999999999,\n",
              "   'text': ' data set after applying the feature selection algorithm. So among 39, we are choosing 30',\n",
              "   'tokens': [1412,\n",
              "    992,\n",
              "    934,\n",
              "    9275,\n",
              "    264,\n",
              "    4111,\n",
              "    9450,\n",
              "    9284,\n",
              "    13,\n",
              "    407,\n",
              "    3654,\n",
              "    15238,\n",
              "    11,\n",
              "    321,\n",
              "    366,\n",
              "    10875,\n",
              "    2217],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4734386161521629,\n",
              "   'compression_ratio': 1.8708333333333333,\n",
              "   'no_speech_prob': 0.0002722706412896514},\n",
              "  {'id': 93,\n",
              "   'seek': 79744,\n",
              "   'start': 797.44,\n",
              "   'end': 807.5200000000001,\n",
              "   'text': ' only. And the total records found is so 41067. But among these, some null data will be there.',\n",
              "   'tokens': [787,\n",
              "    13,\n",
              "    400,\n",
              "    264,\n",
              "    3217,\n",
              "    7724,\n",
              "    1352,\n",
              "    307,\n",
              "    370,\n",
              "    1017,\n",
              "    3279,\n",
              "    22452,\n",
              "    13,\n",
              "    583,\n",
              "    3654,\n",
              "    613,\n",
              "    11,\n",
              "    512,\n",
              "    18184,\n",
              "    1412,\n",
              "    486,\n",
              "    312,\n",
              "    456,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3834014243267952,\n",
              "   'compression_ratio': 1.8051282051282052,\n",
              "   'no_speech_prob': 0.00037865384365431964},\n",
              "  {'id': 94,\n",
              "   'seek': 79744,\n",
              "   'start': 807.5200000000001,\n",
              "   'end': 812.1600000000001,\n",
              "   'text': ' Some null data will be there. OK, that we can remove. The total records used for trying',\n",
              "   'tokens': [2188,\n",
              "    18184,\n",
              "    1412,\n",
              "    486,\n",
              "    312,\n",
              "    456,\n",
              "    13,\n",
              "    2264,\n",
              "    11,\n",
              "    300,\n",
              "    321,\n",
              "    393,\n",
              "    4159,\n",
              "    13,\n",
              "    440,\n",
              "    3217,\n",
              "    7724,\n",
              "    1143,\n",
              "    337,\n",
              "    1382],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3834014243267952,\n",
              "   'compression_ratio': 1.8051282051282052,\n",
              "   'no_speech_prob': 0.00037865384365431964},\n",
              "  {'id': 95,\n",
              "   'seek': 79744,\n",
              "   'start': 812.1600000000001,\n",
              "   'end': 818.48,\n",
              "   'text': ' the machine learning algorithm is 33,333. And the total records used to test machine',\n",
              "   'tokens': [264,\n",
              "    3479,\n",
              "    2539,\n",
              "    9284,\n",
              "    307,\n",
              "    11816,\n",
              "    11,\n",
              "    10191,\n",
              "    18,\n",
              "    13,\n",
              "    400,\n",
              "    264,\n",
              "    3217,\n",
              "    7724,\n",
              "    1143,\n",
              "    281,\n",
              "    1500,\n",
              "    3479],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3834014243267952,\n",
              "   'compression_ratio': 1.8051282051282052,\n",
              "   'no_speech_prob': 0.00037865384365431964},\n",
              "  {'id': 96,\n",
              "   'seek': 79744,\n",
              "   'start': 818.48,\n",
              "   'end': 825.9200000000001,\n",
              "   'text': ' learning algorithm is 8,334. So here, when you observe the data set, so we are having',\n",
              "   'tokens': [2539,\n",
              "    9284,\n",
              "    307,\n",
              "    1649,\n",
              "    11,\n",
              "    10191,\n",
              "    19,\n",
              "    13,\n",
              "    407,\n",
              "    510,\n",
              "    11,\n",
              "    562,\n",
              "    291,\n",
              "    11441,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    370,\n",
              "    321,\n",
              "    366,\n",
              "    1419],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3834014243267952,\n",
              "   'compression_ratio': 1.8051282051282052,\n",
              "   'no_speech_prob': 0.00037865384365431964},\n",
              "  {'id': 97,\n",
              "   'seek': 82592,\n",
              "   'start': 825.92,\n",
              "   'end': 835.12,\n",
              "   'text': ' single data set. When you people are applying any machine learning algorithm, so the data',\n",
              "   'tokens': [2167,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    1133,\n",
              "    291,\n",
              "    561,\n",
              "    366,\n",
              "    9275,\n",
              "    604,\n",
              "    3479,\n",
              "    2539,\n",
              "    9284,\n",
              "    11,\n",
              "    370,\n",
              "    264,\n",
              "    1412],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43525268917992,\n",
              "   'compression_ratio': 1.781725888324873,\n",
              "   'no_speech_prob': 0.0001746476482367143},\n",
              "  {'id': 98,\n",
              "   'seek': 82592,\n",
              "   'start': 835.12,\n",
              "   'end': 840.4799999999999,\n",
              "   'text': ' set is supposed to divide into two parts. One is called trying data set, another is',\n",
              "   'tokens': [992,\n",
              "    307,\n",
              "    3442,\n",
              "    281,\n",
              "    9845,\n",
              "    666,\n",
              "    732,\n",
              "    3166,\n",
              "    13,\n",
              "    1485,\n",
              "    307,\n",
              "    1219,\n",
              "    504,\n",
              "    1840,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    1071,\n",
              "    307],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43525268917992,\n",
              "   'compression_ratio': 1.781725888324873,\n",
              "   'no_speech_prob': 0.0001746476482367143},\n",
              "  {'id': 99,\n",
              "   'seek': 82592,\n",
              "   'start': 840.4799999999999,\n",
              "   'end': 847.92,\n",
              "   'text': ' called test data set. And some problems may find a different for training and testing',\n",
              "   'tokens': [1219,\n",
              "    1500,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    400,\n",
              "    512,\n",
              "    2740,\n",
              "    815,\n",
              "    915,\n",
              "    257,\n",
              "    819,\n",
              "    337,\n",
              "    3097,\n",
              "    293,\n",
              "    4997],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43525268917992,\n",
              "   'compression_ratio': 1.781725888324873,\n",
              "   'no_speech_prob': 0.0001746476482367143},\n",
              "  {'id': 100,\n",
              "   'seek': 82592,\n",
              "   'start': 847.92,\n",
              "   'end': 854.64,\n",
              "   'text': ' also. OK, so in some applications, you may find two data sets. One is for training, another',\n",
              "   'tokens': [611,\n",
              "    13,\n",
              "    2264,\n",
              "    11,\n",
              "    370,\n",
              "    294,\n",
              "    512,\n",
              "    5821,\n",
              "    11,\n",
              "    291,\n",
              "    815,\n",
              "    915,\n",
              "    732,\n",
              "    1412,\n",
              "    6352,\n",
              "    13,\n",
              "    1485,\n",
              "    307,\n",
              "    337,\n",
              "    3097,\n",
              "    11,\n",
              "    1071],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43525268917992,\n",
              "   'compression_ratio': 1.781725888324873,\n",
              "   'no_speech_prob': 0.0001746476482367143},\n",
              "  {'id': 101,\n",
              "   'seek': 85464,\n",
              "   'start': 854.64,\n",
              "   'end': 860.08,\n",
              "   'text': ' is for testing. In some applications, you may get only one data set. In that case, if',\n",
              "   'tokens': [307,\n",
              "    337,\n",
              "    4997,\n",
              "    13,\n",
              "    682,\n",
              "    512,\n",
              "    5821,\n",
              "    11,\n",
              "    291,\n",
              "    815,\n",
              "    483,\n",
              "    787,\n",
              "    472,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    682,\n",
              "    300,\n",
              "    1389,\n",
              "    11,\n",
              "    498],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3602618528216073,\n",
              "   'compression_ratio': 1.7309644670050761,\n",
              "   'no_speech_prob': 0.000846385839395225},\n",
              "  {'id': 102,\n",
              "   'seek': 85464,\n",
              "   'start': 860.08,\n",
              "   'end': 865.1999999999999,\n",
              "   'text': ' you are having only one data set, in that case, it is your responsibility to divide',\n",
              "   'tokens': [291,\n",
              "    366,\n",
              "    1419,\n",
              "    787,\n",
              "    472,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    294,\n",
              "    300,\n",
              "    1389,\n",
              "    11,\n",
              "    309,\n",
              "    307,\n",
              "    428,\n",
              "    6357,\n",
              "    281,\n",
              "    9845],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3602618528216073,\n",
              "   'compression_ratio': 1.7309644670050761,\n",
              "   'no_speech_prob': 0.000846385839395225},\n",
              "  {'id': 103,\n",
              "   'seek': 85464,\n",
              "   'start': 865.1999999999999,\n",
              "   'end': 870.96,\n",
              "   'text': ' the data set into two parts, training and test. So how we are going to divide in the',\n",
              "   'tokens': [264,\n",
              "    1412,\n",
              "    992,\n",
              "    666,\n",
              "    732,\n",
              "    3166,\n",
              "    11,\n",
              "    3097,\n",
              "    293,\n",
              "    1500,\n",
              "    13,\n",
              "    407,\n",
              "    577,\n",
              "    321,\n",
              "    366,\n",
              "    516,\n",
              "    281,\n",
              "    9845,\n",
              "    294,\n",
              "    264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3602618528216073,\n",
              "   'compression_ratio': 1.7309644670050761,\n",
              "   'no_speech_prob': 0.000846385839395225},\n",
              "  {'id': 104,\n",
              "   'seek': 85464,\n",
              "   'start': 870.96,\n",
              "   'end': 880.48,\n",
              "   'text': ' sense, so we may consider 70-30 percentages only. So some programs may consider 70% of',\n",
              "   'tokens': [2020,\n",
              "    11,\n",
              "    370,\n",
              "    321,\n",
              "    815,\n",
              "    1949,\n",
              "    5285,\n",
              "    12,\n",
              "    3446,\n",
              "    42270,\n",
              "    787,\n",
              "    13,\n",
              "    407,\n",
              "    512,\n",
              "    4268,\n",
              "    815,\n",
              "    1949,\n",
              "    5285,\n",
              "    4,\n",
              "    295],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3602618528216073,\n",
              "   'compression_ratio': 1.7309644670050761,\n",
              "   'no_speech_prob': 0.000846385839395225},\n",
              "  {'id': 105,\n",
              "   'seek': 88048,\n",
              "   'start': 880.48,\n",
              "   'end': 887.52,\n",
              "   'text': ' data set will be training and 30% will be testing. In some applications, they may go',\n",
              "   'tokens': [1412,\n",
              "    992,\n",
              "    486,\n",
              "    312,\n",
              "    3097,\n",
              "    293,\n",
              "    2217,\n",
              "    4,\n",
              "    486,\n",
              "    312,\n",
              "    4997,\n",
              "    13,\n",
              "    682,\n",
              "    512,\n",
              "    5821,\n",
              "    11,\n",
              "    436,\n",
              "    815,\n",
              "    352],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3314316177368164,\n",
              "   'compression_ratio': 1.5701754385964912,\n",
              "   'no_speech_prob': 0.0005847492138855159},\n",
              "  {'id': 106,\n",
              "   'seek': 88752,\n",
              "   'start': 887.52,\n",
              "   'end': 917.4399999999999,\n",
              "   'text': ' with 80-20 also. In some applications, they may go with 60-40 also. OK, so in our application.',\n",
              "   'tokens': [50364,\n",
              "    365,\n",
              "    4688,\n",
              "    12,\n",
              "    2009,\n",
              "    611,\n",
              "    13,\n",
              "    682,\n",
              "    512,\n",
              "    5821,\n",
              "    11,\n",
              "    436,\n",
              "    815,\n",
              "    352,\n",
              "    365,\n",
              "    4060,\n",
              "    12,\n",
              "    5254,\n",
              "    611,\n",
              "    13,\n",
              "    2264,\n",
              "    11,\n",
              "    370,\n",
              "    294,\n",
              "    527,\n",
              "    3861,\n",
              "    13,\n",
              "    51860],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.36229949161924163,\n",
              "   'compression_ratio': 1.1325301204819278,\n",
              "   'no_speech_prob': 0.00045013538328930736},\n",
              "  {'id': 107,\n",
              "   'seek': 97752,\n",
              "   'start': 977.52,\n",
              "   'end': 991.36,\n",
              "   'text': ' So here in our application, we are using 80-20 percent. Here, the test size is equal',\n",
              "   'tokens': [407,\n",
              "    510,\n",
              "    294,\n",
              "    527,\n",
              "    3861,\n",
              "    11,\n",
              "    321,\n",
              "    366,\n",
              "    1228,\n",
              "    4688,\n",
              "    12,\n",
              "    2009,\n",
              "    3043,\n",
              "    13,\n",
              "    1692,\n",
              "    11,\n",
              "    264,\n",
              "    1500,\n",
              "    2744,\n",
              "    307,\n",
              "    2681],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4017020358314997,\n",
              "   'compression_ratio': 1.4414893617021276,\n",
              "   'no_speech_prob': 0.01535060815513134},\n",
              "  {'id': 108,\n",
              "   'seek': 97752,\n",
              "   'start': 991.36,\n",
              "   'end': 999.76,\n",
              "   'text': ' to 0.2, means 20%. So 80% will be for training data and 20% is for testing data. How we are',\n",
              "   'tokens': [281,\n",
              "    1958,\n",
              "    13,\n",
              "    17,\n",
              "    11,\n",
              "    1355,\n",
              "    945,\n",
              "    6856,\n",
              "    407,\n",
              "    4688,\n",
              "    4,\n",
              "    486,\n",
              "    312,\n",
              "    337,\n",
              "    3097,\n",
              "    1412,\n",
              "    293,\n",
              "    945,\n",
              "    4,\n",
              "    307,\n",
              "    337,\n",
              "    4997,\n",
              "    1412,\n",
              "    13,\n",
              "    1012,\n",
              "    321,\n",
              "    366],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4017020358314997,\n",
              "   'compression_ratio': 1.4414893617021276,\n",
              "   'no_speech_prob': 0.01535060815513134},\n",
              "  {'id': 109,\n",
              "   'seek': 97752,\n",
              "   'start': 999.76,\n",
              "   'end': 1006.24,\n",
              "   'text': ' going to select like that means based on the data which we have in a week. OK, so for example,',\n",
              "   'tokens': [516,\n",
              "    281,\n",
              "    3048,\n",
              "    411,\n",
              "    300,\n",
              "    1355,\n",
              "    2361,\n",
              "    322,\n",
              "    264,\n",
              "    1412,\n",
              "    597,\n",
              "    321,\n",
              "    362,\n",
              "    294,\n",
              "    257,\n",
              "    1243,\n",
              "    13,\n",
              "    2264,\n",
              "    11,\n",
              "    370,\n",
              "    337,\n",
              "    1365,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4017020358314997,\n",
              "   'compression_ratio': 1.4414893617021276,\n",
              "   'no_speech_prob': 0.01535060815513134},\n",
              "  {'id': 110,\n",
              "   'seek': 100624,\n",
              "   'start': 1006.24,\n",
              "   'end': 1019.44,\n",
              "   'text': ' you can calculate. So total we are having 41,067 into 0.20. So 8334. So that is the',\n",
              "   'tokens': [291,\n",
              "    393,\n",
              "    8873,\n",
              "    13,\n",
              "    407,\n",
              "    3217,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    18173,\n",
              "    11,\n",
              "    12791,\n",
              "    22,\n",
              "    666,\n",
              "    1958,\n",
              "    13,\n",
              "    2009,\n",
              "    13,\n",
              "    407,\n",
              "    1649,\n",
              "    10191,\n",
              "    19,\n",
              "    13,\n",
              "    407,\n",
              "    300,\n",
              "    307,\n",
              "    264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40669468470982145,\n",
              "   'compression_ratio': 1.3255813953488371,\n",
              "   'no_speech_prob': 0.0004160896933171898},\n",
              "  {'id': 111,\n",
              "   'seek': 100624,\n",
              "   'start': 1019.44,\n",
              "   'end': 1027.28,\n",
              "   'text': ' value which we are having. OK, 8334 means 8334 it is taking and remaining the cost will',\n",
              "   'tokens': [2158,\n",
              "    597,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    13,\n",
              "    2264,\n",
              "    11,\n",
              "    1649,\n",
              "    10191,\n",
              "    19,\n",
              "    1355,\n",
              "    1649,\n",
              "    10191,\n",
              "    19,\n",
              "    309,\n",
              "    307,\n",
              "    1940,\n",
              "    293,\n",
              "    8877,\n",
              "    264,\n",
              "    2063,\n",
              "    486],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40669468470982145,\n",
              "   'compression_ratio': 1.3255813953488371,\n",
              "   'no_speech_prob': 0.0004160896933171898},\n",
              "  {'id': 112,\n",
              "   'seek': 102728,\n",
              "   'start': 1027.28,\n",
              "   'end': 1037.04,\n",
              "   'text': ' be training cost. So 70-30 means if you are having huge amount of data, thousands of records,',\n",
              "   'tokens': [312,\n",
              "    3097,\n",
              "    2063,\n",
              "    13,\n",
              "    407,\n",
              "    5285,\n",
              "    12,\n",
              "    3446,\n",
              "    1355,\n",
              "    498,\n",
              "    291,\n",
              "    366,\n",
              "    1419,\n",
              "    2603,\n",
              "    2372,\n",
              "    295,\n",
              "    1412,\n",
              "    11,\n",
              "    5383,\n",
              "    295,\n",
              "    7724,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3143580714358559,\n",
              "   'compression_ratio': 1.5813953488372092,\n",
              "   'no_speech_prob': 0.00035336462315171957},\n",
              "  {'id': 113,\n",
              "   'seek': 102728,\n",
              "   'start': 1037.04,\n",
              "   'end': 1044.32,\n",
              "   'text': ' then go with 80-20. If you are having some medium, means some 5000, 6000 like that,',\n",
              "   'tokens': [550,\n",
              "    352,\n",
              "    365,\n",
              "    4688,\n",
              "    12,\n",
              "    2009,\n",
              "    13,\n",
              "    759,\n",
              "    291,\n",
              "    366,\n",
              "    1419,\n",
              "    512,\n",
              "    6399,\n",
              "    11,\n",
              "    1355,\n",
              "    512,\n",
              "    23777,\n",
              "    11,\n",
              "    41789,\n",
              "    411,\n",
              "    300,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3143580714358559,\n",
              "   'compression_ratio': 1.5813953488372092,\n",
              "   'no_speech_prob': 0.00035336462315171957},\n",
              "  {'id': 114,\n",
              "   'seek': 102728,\n",
              "   'start': 1044.32,\n",
              "   'end': 1053.36,\n",
              "   'text': ' go with 70-30. So if you are having very less, like hundreds, then go with 60-40. Why? Because',\n",
              "   'tokens': [352,\n",
              "    365,\n",
              "    5285,\n",
              "    12,\n",
              "    3446,\n",
              "    13,\n",
              "    407,\n",
              "    498,\n",
              "    291,\n",
              "    366,\n",
              "    1419,\n",
              "    588,\n",
              "    1570,\n",
              "    11,\n",
              "    411,\n",
              "    6779,\n",
              "    11,\n",
              "    550,\n",
              "    352,\n",
              "    365,\n",
              "    4060,\n",
              "    12,\n",
              "    5254,\n",
              "    13,\n",
              "    1545,\n",
              "    30,\n",
              "    1436],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3143580714358559,\n",
              "   'compression_ratio': 1.5813953488372092,\n",
              "   'no_speech_prob': 0.00035336462315171957},\n",
              "  {'id': 115,\n",
              "   'seek': 105336,\n",
              "   'start': 1053.36,\n",
              "   'end': 1059.76,\n",
              "   'text': ' for training or testing, both should be having some meaningful of records. OK, if you are',\n",
              "   'tokens': [337,\n",
              "    3097,\n",
              "    420,\n",
              "    4997,\n",
              "    11,\n",
              "    1293,\n",
              "    820,\n",
              "    312,\n",
              "    1419,\n",
              "    512,\n",
              "    10995,\n",
              "    295,\n",
              "    7724,\n",
              "    13,\n",
              "    2264,\n",
              "    11,\n",
              "    498,\n",
              "    291,\n",
              "    366],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28533595095398606,\n",
              "   'compression_ratio': 1.6318181818181818,\n",
              "   'no_speech_prob': 0.00043424387695267797},\n",
              "  {'id': 116,\n",
              "   'seek': 105336,\n",
              "   'start': 1059.76,\n",
              "   'end': 1065.84,\n",
              "   'text': ' having very less records for testing, then in that case, so your machine learning algorithms',\n",
              "   'tokens': [1419,\n",
              "    588,\n",
              "    1570,\n",
              "    7724,\n",
              "    337,\n",
              "    4997,\n",
              "    11,\n",
              "    550,\n",
              "    294,\n",
              "    300,\n",
              "    1389,\n",
              "    11,\n",
              "    370,\n",
              "    428,\n",
              "    3479,\n",
              "    2539,\n",
              "    14642],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28533595095398606,\n",
              "   'compression_ratio': 1.6318181818181818,\n",
              "   'no_speech_prob': 0.00043424387695267797},\n",
              "  {'id': 117,\n",
              "   'seek': 105336,\n",
              "   'start': 1065.84,\n",
              "   'end': 1075.6,\n",
              "   'text': \" will not work properly. So here I'm having 41,667. That's why I choose 80-20%. So 20%\",\n",
              "   'tokens': [486,\n",
              "    406,\n",
              "    589,\n",
              "    6108,\n",
              "    13,\n",
              "    407,\n",
              "    510,\n",
              "    286,\n",
              "    478,\n",
              "    1419,\n",
              "    18173,\n",
              "    11,\n",
              "    15237,\n",
              "    22,\n",
              "    13,\n",
              "    663,\n",
              "    311,\n",
              "    983,\n",
              "    286,\n",
              "    2826,\n",
              "    4688,\n",
              "    12,\n",
              "    2009,\n",
              "    6856,\n",
              "    407,\n",
              "    945,\n",
              "    4],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28533595095398606,\n",
              "   'compression_ratio': 1.6318181818181818,\n",
              "   'no_speech_prob': 0.00043424387695267797},\n",
              "  {'id': 118,\n",
              "   'seek': 105336,\n",
              "   'start': 1075.6,\n",
              "   'end': 1081.6,\n",
              "   'text': ' of data will be for testing purpose and 80% of data will be for training purpose. So among',\n",
              "   'tokens': [295,\n",
              "    1412,\n",
              "    486,\n",
              "    312,\n",
              "    337,\n",
              "    4997,\n",
              "    4334,\n",
              "    293,\n",
              "    4688,\n",
              "    4,\n",
              "    295,\n",
              "    1412,\n",
              "    486,\n",
              "    312,\n",
              "    337,\n",
              "    3097,\n",
              "    4334,\n",
              "    13,\n",
              "    407,\n",
              "    3654],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28533595095398606,\n",
              "   'compression_ratio': 1.6318181818181818,\n",
              "   'no_speech_prob': 0.00043424387695267797},\n",
              "  {'id': 119,\n",
              "   'seek': 108160,\n",
              "   'start': 1081.6,\n",
              "   'end': 1087.76,\n",
              "   'text': ' these records, so it is taking randomly. Randomly it is going to divide into two parts. So that',\n",
              "   'tokens': [613,\n",
              "    7724,\n",
              "    11,\n",
              "    370,\n",
              "    309,\n",
              "    307,\n",
              "    1940,\n",
              "    16979,\n",
              "    13,\n",
              "    37603,\n",
              "    356,\n",
              "    309,\n",
              "    307,\n",
              "    516,\n",
              "    281,\n",
              "    9845,\n",
              "    666,\n",
              "    732,\n",
              "    3166,\n",
              "    13,\n",
              "    407,\n",
              "    300],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3669444613986545,\n",
              "   'compression_ratio': 1.4148148148148147,\n",
              "   'no_speech_prob': 0.0007100008660927415},\n",
              "  {'id': 120,\n",
              "   'seek': 108160,\n",
              "   'start': 1087.76,\n",
              "   'end': 1093.36,\n",
              "   'text': \" is feature selection algorithm. Then I'm running machine learning algorithms. Just I'm clicking\",\n",
              "   'tokens': [307,\n",
              "    4111,\n",
              "    9450,\n",
              "    9284,\n",
              "    13,\n",
              "    1396,\n",
              "    286,\n",
              "    478,\n",
              "    2614,\n",
              "    3479,\n",
              "    2539,\n",
              "    14642,\n",
              "    13,\n",
              "    1449,\n",
              "    286,\n",
              "    478,\n",
              "    9697],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3669444613986545,\n",
              "   'compression_ratio': 1.4148148148148147,\n",
              "   'no_speech_prob': 0.0007100008660927415},\n",
              "  {'id': 121,\n",
              "   'seek': 109336,\n",
              "   'start': 1093.36,\n",
              "   'end': 1113.6,\n",
              "   'text': ' machine learning algorithm. Run. So it will take some time. So for machine learning algorithms',\n",
              "   'tokens': [3479,\n",
              "    2539,\n",
              "    9284,\n",
              "    13,\n",
              "    8950,\n",
              "    13,\n",
              "    407,\n",
              "    309,\n",
              "    486,\n",
              "    747,\n",
              "    512,\n",
              "    565,\n",
              "    13,\n",
              "    407,\n",
              "    337,\n",
              "    3479,\n",
              "    2539,\n",
              "    14642],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43139439094357374,\n",
              "   'compression_ratio': 1.4953271028037383,\n",
              "   'no_speech_prob': 0.0005347465630620718},\n",
              "  {'id': 122,\n",
              "   'seek': 109336,\n",
              "   'start': 1113.6,\n",
              "   'end': 1120.32,\n",
              "   'text': ' execution, you take a lot of time. We need to wait for some time.',\n",
              "   'tokens': [15058,\n",
              "    11,\n",
              "    291,\n",
              "    747,\n",
              "    257,\n",
              "    688,\n",
              "    295,\n",
              "    565,\n",
              "    13,\n",
              "    492,\n",
              "    643,\n",
              "    281,\n",
              "    1699,\n",
              "    337,\n",
              "    512,\n",
              "    565,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43139439094357374,\n",
              "   'compression_ratio': 1.4953271028037383,\n",
              "   'no_speech_prob': 0.0005347465630620718},\n",
              "  {'id': 123,\n",
              "   'seek': 112032,\n",
              "   'start': 1120.32,\n",
              "   'end': 1125.6,\n",
              "   'text': ' So this 8334 records, it will pick randomly or it will pick sequentially?',\n",
              "   'tokens': [407,\n",
              "    341,\n",
              "    1649,\n",
              "    10191,\n",
              "    19,\n",
              "    7724,\n",
              "    11,\n",
              "    309,\n",
              "    486,\n",
              "    1888,\n",
              "    16979,\n",
              "    420,\n",
              "    309,\n",
              "    486,\n",
              "    1888,\n",
              "    5123,\n",
              "    3137,\n",
              "    30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41641326745351154,\n",
              "   'compression_ratio': 1.9269662921348314,\n",
              "   'no_speech_prob': 0.000532973266672343},\n",
              "  {'id': 124,\n",
              "   'seek': 112032,\n",
              "   'start': 1125.6,\n",
              "   'end': 1132.32,\n",
              "   'text': ' Randomly. Randomly machine itself is taking. OK, among these, so it is going to design',\n",
              "   'tokens': [37603,\n",
              "    356,\n",
              "    13,\n",
              "    37603,\n",
              "    356,\n",
              "    3479,\n",
              "    2564,\n",
              "    307,\n",
              "    1940,\n",
              "    13,\n",
              "    2264,\n",
              "    11,\n",
              "    3654,\n",
              "    613,\n",
              "    11,\n",
              "    370,\n",
              "    309,\n",
              "    307,\n",
              "    516,\n",
              "    281,\n",
              "    1715],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41641326745351154,\n",
              "   'compression_ratio': 1.9269662921348314,\n",
              "   'no_speech_prob': 0.000532973266672343},\n",
              "  {'id': 125,\n",
              "   'seek': 112032,\n",
              "   'start': 1132.32,\n",
              "   'end': 1138.24,\n",
              "   'text': ' data frames. So for 80% of records, it is going to design one data frame and 30% of',\n",
              "   'tokens': [1412,\n",
              "    12083,\n",
              "    13,\n",
              "    407,\n",
              "    337,\n",
              "    4688,\n",
              "    4,\n",
              "    295,\n",
              "    7724,\n",
              "    11,\n",
              "    309,\n",
              "    307,\n",
              "    516,\n",
              "    281,\n",
              "    1715,\n",
              "    472,\n",
              "    1412,\n",
              "    3920,\n",
              "    293,\n",
              "    2217,\n",
              "    4,\n",
              "    295],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41641326745351154,\n",
              "   'compression_ratio': 1.9269662921348314,\n",
              "   'no_speech_prob': 0.000532973266672343},\n",
              "  {'id': 126,\n",
              "   'seek': 112032,\n",
              "   'start': 1138.24,\n",
              "   'end': 1143.84,\n",
              "   'text': ' records, it is going to design one data frame and it is not sequence. So randomly, it will',\n",
              "   'tokens': [7724,\n",
              "    11,\n",
              "    309,\n",
              "    307,\n",
              "    516,\n",
              "    281,\n",
              "    1715,\n",
              "    472,\n",
              "    1412,\n",
              "    3920,\n",
              "    293,\n",
              "    309,\n",
              "    307,\n",
              "    406,\n",
              "    8310,\n",
              "    13,\n",
              "    407,\n",
              "    16979,\n",
              "    11,\n",
              "    309,\n",
              "    486],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41641326745351154,\n",
              "   'compression_ratio': 1.9269662921348314,\n",
              "   'no_speech_prob': 0.000532973266672343},\n",
              "  {'id': 127,\n",
              "   'seek': 112032,\n",
              "   'start': 1143.84,\n",
              "   'end': 1144.84,\n",
              "   'text': ' choose.',\n",
              "   'tokens': [2826, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41641326745351154,\n",
              "   'compression_ratio': 1.9269662921348314,\n",
              "   'no_speech_prob': 0.000532973266672343},\n",
              "  {'id': 128,\n",
              "   'seek': 114484,\n",
              "   'start': 1144.84,\n",
              "   'end': 1150.3999999999999,\n",
              "   'text': ' A single data set which we have pointed, it will split into two now?',\n",
              "   'tokens': [316,\n",
              "    2167,\n",
              "    1412,\n",
              "    992,\n",
              "    597,\n",
              "    321,\n",
              "    362,\n",
              "    10932,\n",
              "    11,\n",
              "    309,\n",
              "    486,\n",
              "    7472,\n",
              "    666,\n",
              "    732,\n",
              "    586,\n",
              "    30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40981221810365337,\n",
              "   'compression_ratio': 1.4941176470588236,\n",
              "   'no_speech_prob': 0.0005247032386250794},\n",
              "  {'id': 129,\n",
              "   'seek': 114484,\n",
              "   'start': 1150.3999999999999,\n",
              "   'end': 1151.3999999999999,\n",
              "   'text': ' Yeah.',\n",
              "   'tokens': [865, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40981221810365337,\n",
              "   'compression_ratio': 1.4941176470588236,\n",
              "   'no_speech_prob': 0.0005247032386250794},\n",
              "  {'id': 130,\n",
              "   'seek': 114484,\n",
              "   'start': 1151.3999999999999,\n",
              "   'end': 1152.3999999999999,\n",
              "   'text': ' OK.',\n",
              "   'tokens': [2264, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40981221810365337,\n",
              "   'compression_ratio': 1.4941176470588236,\n",
              "   'no_speech_prob': 0.0005247032386250794},\n",
              "  {'id': 131,\n",
              "   'seek': 114484,\n",
              "   'start': 1152.3999999999999,\n",
              "   'end': 1160.1599999999999,\n",
              "   'text': ' Whatever the data set you selected, so that will be split into two parts. 80-20%. Is it',\n",
              "   'tokens': [8541,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    291,\n",
              "    8209,\n",
              "    11,\n",
              "    370,\n",
              "    300,\n",
              "    486,\n",
              "    312,\n",
              "    7472,\n",
              "    666,\n",
              "    732,\n",
              "    3166,\n",
              "    13,\n",
              "    4688,\n",
              "    12,\n",
              "    2009,\n",
              "    6856,\n",
              "    1119,\n",
              "    309],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40981221810365337,\n",
              "   'compression_ratio': 1.4941176470588236,\n",
              "   'no_speech_prob': 0.0005247032386250794},\n",
              "  {'id': 132,\n",
              "   'seek': 114484,\n",
              "   'start': 1160.1599999999999,\n",
              "   'end': 1167.76,\n",
              "   'text': ' compulsory 80-20 means? No. Some people may go with 70-30 also. Some people may go with',\n",
              "   'tokens': [42773,\n",
              "    827,\n",
              "    4688,\n",
              "    12,\n",
              "    2009,\n",
              "    1355,\n",
              "    30,\n",
              "    883,\n",
              "    13,\n",
              "    2188,\n",
              "    561,\n",
              "    815,\n",
              "    352,\n",
              "    365,\n",
              "    5285,\n",
              "    12,\n",
              "    3446,\n",
              "    611,\n",
              "    13,\n",
              "    2188,\n",
              "    561,\n",
              "    815,\n",
              "    352,\n",
              "    365],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40981221810365337,\n",
              "   'compression_ratio': 1.4941176470588236,\n",
              "   'no_speech_prob': 0.0005247032386250794},\n",
              "  {'id': 133,\n",
              "   'seek': 116776,\n",
              "   'start': 1167.76,\n",
              "   'end': 1176.44,\n",
              "   'text': ' 60-40 also. Based on our requirement. But 70-30 is the average maximum people will use.',\n",
              "   'tokens': [4060,\n",
              "    12,\n",
              "    5254,\n",
              "    611,\n",
              "    13,\n",
              "    18785,\n",
              "    322,\n",
              "    527,\n",
              "    11695,\n",
              "    13,\n",
              "    583,\n",
              "    5285,\n",
              "    12,\n",
              "    3446,\n",
              "    307,\n",
              "    264,\n",
              "    4274,\n",
              "    6674,\n",
              "    561,\n",
              "    486,\n",
              "    764,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4238216594114142,\n",
              "   'compression_ratio': 1.33125,\n",
              "   'no_speech_prob': 0.00016207103908527642},\n",
              "  {'id': 134,\n",
              "   'seek': 116776,\n",
              "   'start': 1176.44,\n",
              "   'end': 1182.32,\n",
              "   'text': ' But here we are using 80-20 because we have plenty of records.',\n",
              "   'tokens': [583,\n",
              "    510,\n",
              "    321,\n",
              "    366,\n",
              "    1228,\n",
              "    4688,\n",
              "    12,\n",
              "    2009,\n",
              "    570,\n",
              "    321,\n",
              "    362,\n",
              "    7140,\n",
              "    295,\n",
              "    7724,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4238216594114142,\n",
              "   'compression_ratio': 1.33125,\n",
              "   'no_speech_prob': 0.00016207103908527642},\n",
              "  {'id': 135,\n",
              "   'seek': 116776,\n",
              "   'start': 1182.32,\n",
              "   'end': 1191.36,\n",
              "   'text': ' Why they opt to choose for this splitting? Is there any logic?',\n",
              "   'tokens': [1545,\n",
              "    436,\n",
              "    2427,\n",
              "    281,\n",
              "    2826,\n",
              "    337,\n",
              "    341,\n",
              "    30348,\n",
              "    30,\n",
              "    1119,\n",
              "    456,\n",
              "    604,\n",
              "    9952,\n",
              "    30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4238216594114142,\n",
              "   'compression_ratio': 1.33125,\n",
              "   'no_speech_prob': 0.00016207103908527642},\n",
              "  {'id': 136,\n",
              "   'seek': 119136,\n",
              "   'start': 1191.36,\n",
              "   'end': 1202.12,\n",
              "   'text': ' For example, if you say that I prepared for exam. I prepared for exam. So I prepared some',\n",
              "   'tokens': [1171,\n",
              "    1365,\n",
              "    11,\n",
              "    498,\n",
              "    291,\n",
              "    584,\n",
              "    300,\n",
              "    286,\n",
              "    4927,\n",
              "    337,\n",
              "    1139,\n",
              "    13,\n",
              "    286,\n",
              "    4927,\n",
              "    337,\n",
              "    1139,\n",
              "    13,\n",
              "    407,\n",
              "    286,\n",
              "    4927,\n",
              "    512],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48844752592198987,\n",
              "   'compression_ratio': 1.685897435897436,\n",
              "   'no_speech_prob': 0.0002505946031305939},\n",
              "  {'id': 137,\n",
              "   'seek': 119136,\n",
              "   'start': 1202.12,\n",
              "   'end': 1209.9599999999998,\n",
              "   'text': \" math exam. So in my notes, I'm having some problems. So I prepared very well. Can we\",\n",
              "   'tokens': [5221,\n",
              "    1139,\n",
              "    13,\n",
              "    407,\n",
              "    294,\n",
              "    452,\n",
              "    5570,\n",
              "    11,\n",
              "    286,\n",
              "    478,\n",
              "    1419,\n",
              "    512,\n",
              "    2740,\n",
              "    13,\n",
              "    407,\n",
              "    286,\n",
              "    4927,\n",
              "    588,\n",
              "    731,\n",
              "    13,\n",
              "    1664,\n",
              "    321],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48844752592198987,\n",
              "   'compression_ratio': 1.685897435897436,\n",
              "   'no_speech_prob': 0.0002505946031305939},\n",
              "  {'id': 138,\n",
              "   'seek': 119136,\n",
              "   'start': 1209.9599999999998,\n",
              "   'end': 1218.84,\n",
              "   'text': ' expect in exam the same 10 problems or same questions in examination? Can you expect the',\n",
              "   'tokens': [2066,\n",
              "    294,\n",
              "    1139,\n",
              "    264,\n",
              "    912,\n",
              "    1266,\n",
              "    2740,\n",
              "    420,\n",
              "    912,\n",
              "    1651,\n",
              "    294,\n",
              "    23874,\n",
              "    30,\n",
              "    1664,\n",
              "    291,\n",
              "    2066,\n",
              "    264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48844752592198987,\n",
              "   'compression_ratio': 1.685897435897436,\n",
              "   'no_speech_prob': 0.0002505946031305939},\n",
              "  {'id': 139,\n",
              "   'seek': 121884,\n",
              "   'start': 1218.84,\n",
              "   'end': 1221.48,\n",
              "   'text': ' same questions in external examination?',\n",
              "   'tokens': [912, 1651, 294, 8320, 23874, 30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5512261622160384,\n",
              "   'compression_ratio': 1.8076923076923077,\n",
              "   'no_speech_prob': 0.00018733891192823648},\n",
              "  {'id': 140,\n",
              "   'seek': 121884,\n",
              "   'start': 1221.48,\n",
              "   'end': 1224.1599999999999,\n",
              "   'text': ' No, we cannot expect.',\n",
              "   'tokens': [883, 11, 321, 2644, 2066, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5512261622160384,\n",
              "   'compression_ratio': 1.8076923076923077,\n",
              "   'no_speech_prob': 0.00018733891192823648},\n",
              "  {'id': 141,\n",
              "   'seek': 121884,\n",
              "   'start': 1224.1599999999999,\n",
              "   'end': 1231.08,\n",
              "   'text': \" But you should, when you said that I prepared for exam, then you're supposed to do same\",\n",
              "   'tokens': [583,\n",
              "    291,\n",
              "    820,\n",
              "    11,\n",
              "    562,\n",
              "    291,\n",
              "    848,\n",
              "    300,\n",
              "    286,\n",
              "    4927,\n",
              "    337,\n",
              "    1139,\n",
              "    11,\n",
              "    550,\n",
              "    291,\n",
              "    434,\n",
              "    3442,\n",
              "    281,\n",
              "    360,\n",
              "    912],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5512261622160384,\n",
              "   'compression_ratio': 1.8076923076923077,\n",
              "   'no_speech_prob': 0.00018733891192823648},\n",
              "  {'id': 142,\n",
              "   'seek': 121884,\n",
              "   'start': 1231.08,\n",
              "   'end': 1235.3999999999999,\n",
              "   'text': ' type of questions that may arise. Same, not same problem, same type of questions that',\n",
              "   'tokens': [2010,\n",
              "    295,\n",
              "    1651,\n",
              "    300,\n",
              "    815,\n",
              "    20288,\n",
              "    13,\n",
              "    10635,\n",
              "    11,\n",
              "    406,\n",
              "    912,\n",
              "    1154,\n",
              "    11,\n",
              "    912,\n",
              "    2010,\n",
              "    295,\n",
              "    1651,\n",
              "    300],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5512261622160384,\n",
              "   'compression_ratio': 1.8076923076923077,\n",
              "   'no_speech_prob': 0.00018733891192823648},\n",
              "  {'id': 143,\n",
              "   'seek': 121884,\n",
              "   'start': 1235.3999999999999,\n",
              "   'end': 1242.28,\n",
              "   'text': \" will arise. In that situation, you're supposed to write answer that questions also. For that\",\n",
              "   'tokens': [486,\n",
              "    20288,\n",
              "    13,\n",
              "    682,\n",
              "    300,\n",
              "    2590,\n",
              "    11,\n",
              "    291,\n",
              "    434,\n",
              "    3442,\n",
              "    281,\n",
              "    2464,\n",
              "    1867,\n",
              "    300,\n",
              "    1651,\n",
              "    611,\n",
              "    13,\n",
              "    1171,\n",
              "    300],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5512261622160384,\n",
              "   'compression_ratio': 1.8076923076923077,\n",
              "   'no_speech_prob': 0.00018733891192823648},\n",
              "  {'id': 144,\n",
              "   'seek': 121884,\n",
              "   'start': 1242.28,\n",
              "   'end': 1248.1999999999998,\n",
              "   'text': ' here we are using training and testing. Training in the data set. So mission is going to train',\n",
              "   'tokens': [510,\n",
              "    321,\n",
              "    366,\n",
              "    1228,\n",
              "    3097,\n",
              "    293,\n",
              "    4997,\n",
              "    13,\n",
              "    20620,\n",
              "    294,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    407,\n",
              "    4447,\n",
              "    307,\n",
              "    516,\n",
              "    281,\n",
              "    3847],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5512261622160384,\n",
              "   'compression_ratio': 1.8076923076923077,\n",
              "   'no_speech_prob': 0.00018733891192823648},\n",
              "  {'id': 145,\n",
              "   'seek': 124820,\n",
              "   'start': 1248.2,\n",
              "   'end': 1256.44,\n",
              "   'text': ' the algorithm with the help of these 33,333 records. Randomly they choose them. And then',\n",
              "   'tokens': [264,\n",
              "    9284,\n",
              "    365,\n",
              "    264,\n",
              "    854,\n",
              "    295,\n",
              "    613,\n",
              "    11816,\n",
              "    11,\n",
              "    10191,\n",
              "    18,\n",
              "    7724,\n",
              "    13,\n",
              "    37603,\n",
              "    356,\n",
              "    436,\n",
              "    2826,\n",
              "    552,\n",
              "    13,\n",
              "    400,\n",
              "    550],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.38304758646402015,\n",
              "   'compression_ratio': 1.7684729064039408,\n",
              "   'no_speech_prob': 0.0007196454098448157},\n",
              "  {'id': 146,\n",
              "   'seek': 124820,\n",
              "   'start': 1256.44,\n",
              "   'end': 1260.92,\n",
              "   'text': ' to check whether the mission is working properly or not, whether the algorithm is working properly',\n",
              "   'tokens': [281,\n",
              "    1520,\n",
              "    1968,\n",
              "    264,\n",
              "    4447,\n",
              "    307,\n",
              "    1364,\n",
              "    6108,\n",
              "    420,\n",
              "    406,\n",
              "    11,\n",
              "    1968,\n",
              "    264,\n",
              "    9284,\n",
              "    307,\n",
              "    1364,\n",
              "    6108],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.38304758646402015,\n",
              "   'compression_ratio': 1.7684729064039408,\n",
              "   'no_speech_prob': 0.0007196454098448157},\n",
              "  {'id': 147,\n",
              "   'seek': 124820,\n",
              "   'start': 1260.92,\n",
              "   'end': 1266.96,\n",
              "   'text': ' or not, we are using testing data set. So for testing data set also supposed to take',\n",
              "   'tokens': [420,\n",
              "    406,\n",
              "    11,\n",
              "    321,\n",
              "    366,\n",
              "    1228,\n",
              "    4997,\n",
              "    1412,\n",
              "    992,\n",
              "    13,\n",
              "    407,\n",
              "    337,\n",
              "    4997,\n",
              "    1412,\n",
              "    992,\n",
              "    611,\n",
              "    3442,\n",
              "    281,\n",
              "    747],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.38304758646402015,\n",
              "   'compression_ratio': 1.7684729064039408,\n",
              "   'no_speech_prob': 0.0007196454098448157},\n",
              "  {'id': 148,\n",
              "   'seek': 124820,\n",
              "   'start': 1266.96,\n",
              "   'end': 1273.0,\n",
              "   'text': ' same performance. For that we are dividing training and testing. Training in the sense',\n",
              "   'tokens': [912,\n",
              "    3389,\n",
              "    13,\n",
              "    1171,\n",
              "    300,\n",
              "    321,\n",
              "    366,\n",
              "    26764,\n",
              "    3097,\n",
              "    293,\n",
              "    4997,\n",
              "    13,\n",
              "    20620,\n",
              "    294,\n",
              "    264,\n",
              "    2020],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.38304758646402015,\n",
              "   'compression_ratio': 1.7684729064039408,\n",
              "   'no_speech_prob': 0.0007196454098448157},\n",
              "  {'id': 149,\n",
              "   'seek': 127300,\n",
              "   'start': 1273.0,\n",
              "   'end': 1279.76,\n",
              "   'text': ' that training, we are giving training to algorithm and to test whether it is working properly',\n",
              "   'tokens': [300,\n",
              "    3097,\n",
              "    11,\n",
              "    321,\n",
              "    366,\n",
              "    2902,\n",
              "    3097,\n",
              "    281,\n",
              "    9284,\n",
              "    293,\n",
              "    281,\n",
              "    1500,\n",
              "    1968,\n",
              "    309,\n",
              "    307,\n",
              "    1364,\n",
              "    6108],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4911014628860186,\n",
              "   'compression_ratio': 1.5474452554744527,\n",
              "   'no_speech_prob': 0.0003748866729438305},\n",
              "  {'id': 150,\n",
              "   'seek': 127300,\n",
              "   'start': 1279.76,\n",
              "   'end': 1288.2,\n",
              "   'text': ' or not, we are using testing data set.',\n",
              "   'tokens': [420, 406, 11, 321, 366, 1228, 4997, 1412, 992, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4911014628860186,\n",
              "   'compression_ratio': 1.5474452554744527,\n",
              "   'no_speech_prob': 0.0003748866729438305},\n",
              "  {'id': 151,\n",
              "   'seek': 127300,\n",
              "   'start': 1288.2,\n",
              "   'end': 1293.6,\n",
              "   'text': ' All the fields in the data set, how we are capturing like there are 30 columns.',\n",
              "   'tokens': [1057,\n",
              "    264,\n",
              "    7909,\n",
              "    294,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    577,\n",
              "    321,\n",
              "    366,\n",
              "    23384,\n",
              "    411,\n",
              "    456,\n",
              "    366,\n",
              "    2217,\n",
              "    13766,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4911014628860186,\n",
              "   'compression_ratio': 1.5474452554744527,\n",
              "   'no_speech_prob': 0.0003748866729438305},\n",
              "  {'id': 152,\n",
              "   'seek': 129360,\n",
              "   'start': 1293.6,\n",
              "   'end': 1303.04,\n",
              "   'text': ' 40 fields are there. So in programming part we are thinking just a minute I will show',\n",
              "   'tokens': [3356,\n",
              "    7909,\n",
              "    366,\n",
              "    456,\n",
              "    13,\n",
              "    407,\n",
              "    294,\n",
              "    9410,\n",
              "    644,\n",
              "    321,\n",
              "    366,\n",
              "    1953,\n",
              "    445,\n",
              "    257,\n",
              "    3456,\n",
              "    286,\n",
              "    486,\n",
              "    855],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5263814169263082,\n",
              "   'compression_ratio': 1.6331360946745561,\n",
              "   'no_speech_prob': 0.0006111898692324758},\n",
              "  {'id': 153,\n",
              "   'seek': 129360,\n",
              "   'start': 1303.04,\n",
              "   'end': 1305.04,\n",
              "   'text': ' that program.',\n",
              "   'tokens': [300, 1461, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5263814169263082,\n",
              "   'compression_ratio': 1.6331360946745561,\n",
              "   'no_speech_prob': 0.0006111898692324758},\n",
              "  {'id': 154,\n",
              "   'seek': 129360,\n",
              "   'start': 1305.04,\n",
              "   'end': 1315.1599999999999,\n",
              "   'text': ' The fields which is recorded by application, some application is there so that we are not',\n",
              "   'tokens': [440,\n",
              "    7909,\n",
              "    597,\n",
              "    307,\n",
              "    8287,\n",
              "    538,\n",
              "    3861,\n",
              "    11,\n",
              "    512,\n",
              "    3861,\n",
              "    307,\n",
              "    456,\n",
              "    370,\n",
              "    300,\n",
              "    321,\n",
              "    366,\n",
              "    406],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5263814169263082,\n",
              "   'compression_ratio': 1.6331360946745561,\n",
              "   'no_speech_prob': 0.0006111898692324758},\n",
              "  {'id': 155,\n",
              "   'seek': 129360,\n",
              "   'start': 1315.1599999999999,\n",
              "   'end': 1322.32,\n",
              "   'text': ' discussing. So every fields will be gathered through application. So someone is giving',\n",
              "   'tokens': [10850,\n",
              "    13,\n",
              "    407,\n",
              "    633,\n",
              "    7909,\n",
              "    486,\n",
              "    312,\n",
              "    13032,\n",
              "    807,\n",
              "    3861,\n",
              "    13,\n",
              "    407,\n",
              "    1580,\n",
              "    307,\n",
              "    2902],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5263814169263082,\n",
              "   'compression_ratio': 1.6331360946745561,\n",
              "   'no_speech_prob': 0.0006111898692324758},\n",
              "  {'id': 156,\n",
              "   'seek': 132232,\n",
              "   'start': 1322.32,\n",
              "   'end': 1328.2,\n",
              "   'text': ' that data set to us to go with the software quality prediction. How much, how quality',\n",
              "   'tokens': [300,\n",
              "    1412,\n",
              "    992,\n",
              "    281,\n",
              "    505,\n",
              "    281,\n",
              "    352,\n",
              "    365,\n",
              "    264,\n",
              "    4722,\n",
              "    3125,\n",
              "    17630,\n",
              "    13,\n",
              "    1012,\n",
              "    709,\n",
              "    11,\n",
              "    577,\n",
              "    3125],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.44200048714040596,\n",
              "   'compression_ratio': 1.8744186046511628,\n",
              "   'no_speech_prob': 0.0006528178346343338},\n",
              "  {'id': 157,\n",
              "   'seek': 132232,\n",
              "   'start': 1328.2,\n",
              "   'end': 1335.4399999999998,\n",
              "   'text': \" is there if I'm using Hadoop. So whether the accuracy, how much accuracy is there, whether\",\n",
              "   'tokens': [307,\n",
              "    456,\n",
              "    498,\n",
              "    286,\n",
              "    478,\n",
              "    1228,\n",
              "    389,\n",
              "    1573,\n",
              "    404,\n",
              "    13,\n",
              "    407,\n",
              "    1968,\n",
              "    264,\n",
              "    14170,\n",
              "    11,\n",
              "    577,\n",
              "    709,\n",
              "    14170,\n",
              "    307,\n",
              "    456,\n",
              "    11,\n",
              "    1968],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.44200048714040596,\n",
              "   'compression_ratio': 1.8744186046511628,\n",
              "   'no_speech_prob': 0.0006528178346343338},\n",
              "  {'id': 158,\n",
              "   'seek': 132232,\n",
              "   'start': 1335.4399999999998,\n",
              "   'end': 1342.0,\n",
              "   'text': ' can we proceed with Hadoop or not. If I give some net bills, how much accuracy is there.',\n",
              "   'tokens': [393,\n",
              "    321,\n",
              "    8991,\n",
              "    365,\n",
              "    389,\n",
              "    1573,\n",
              "    404,\n",
              "    420,\n",
              "    406,\n",
              "    13,\n",
              "    759,\n",
              "    286,\n",
              "    976,\n",
              "    512,\n",
              "    2533,\n",
              "    12433,\n",
              "    11,\n",
              "    577,\n",
              "    709,\n",
              "    14170,\n",
              "    307,\n",
              "    456,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.44200048714040596,\n",
              "   'compression_ratio': 1.8744186046511628,\n",
              "   'no_speech_prob': 0.0006528178346343338},\n",
              "  {'id': 159,\n",
              "   'seek': 132232,\n",
              "   'start': 1342.0,\n",
              "   'end': 1346.0,\n",
              "   'text': ' So Java, how much accuracy is there, like that. They will give the fields and every',\n",
              "   'tokens': [407,\n",
              "    10745,\n",
              "    11,\n",
              "    577,\n",
              "    709,\n",
              "    14170,\n",
              "    307,\n",
              "    456,\n",
              "    11,\n",
              "    411,\n",
              "    300,\n",
              "    13,\n",
              "    814,\n",
              "    486,\n",
              "    976,\n",
              "    264,\n",
              "    7909,\n",
              "    293,\n",
              "    633],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.44200048714040596,\n",
              "   'compression_ratio': 1.8744186046511628,\n",
              "   'no_speech_prob': 0.0006528178346343338},\n",
              "  {'id': 160,\n",
              "   'seek': 132232,\n",
              "   'start': 1346.0,\n",
              "   'end': 1349.9199999999998,\n",
              "   'text': ' data set. For that we are going to process the thing.',\n",
              "   'tokens': [1412,\n",
              "    992,\n",
              "    13,\n",
              "    1171,\n",
              "    300,\n",
              "    321,\n",
              "    366,\n",
              "    516,\n",
              "    281,\n",
              "    1399,\n",
              "    264,\n",
              "    551,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.44200048714040596,\n",
              "   'compression_ratio': 1.8744186046511628,\n",
              "   'no_speech_prob': 0.0006528178346343338},\n",
              "  {'id': 161,\n",
              "   'seek': 134992,\n",
              "   'start': 1349.92,\n",
              "   'end': 1355.64,\n",
              "   'text': ' So here feature selection will be there. So some columns may be having non-values in that',\n",
              "   'tokens': [407,\n",
              "    510,\n",
              "    4111,\n",
              "    9450,\n",
              "    486,\n",
              "    312,\n",
              "    456,\n",
              "    13,\n",
              "    407,\n",
              "    512,\n",
              "    13766,\n",
              "    815,\n",
              "    312,\n",
              "    1419,\n",
              "    2107,\n",
              "    12,\n",
              "    46033,\n",
              "    294,\n",
              "    300],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4172467478999385,\n",
              "   'compression_ratio': 2.097674418604651,\n",
              "   'no_speech_prob': 4.1848445107461885e-05},\n",
              "  {'id': 162,\n",
              "   'seek': 134992,\n",
              "   'start': 1355.64,\n",
              "   'end': 1360.68,\n",
              "   'text': \" case, we'll remove that one. Some rows will be having non-values in that case, we'll remove\",\n",
              "   'tokens': [1389,\n",
              "    11,\n",
              "    321,\n",
              "    603,\n",
              "    4159,\n",
              "    300,\n",
              "    472,\n",
              "    13,\n",
              "    2188,\n",
              "    13241,\n",
              "    486,\n",
              "    312,\n",
              "    1419,\n",
              "    2107,\n",
              "    12,\n",
              "    46033,\n",
              "    294,\n",
              "    300,\n",
              "    1389,\n",
              "    11,\n",
              "    321,\n",
              "    603,\n",
              "    4159],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4172467478999385,\n",
              "   'compression_ratio': 2.097674418604651,\n",
              "   'no_speech_prob': 4.1848445107461885e-05},\n",
              "  {'id': 163,\n",
              "   'seek': 134992,\n",
              "   'start': 1360.68,\n",
              "   'end': 1367.68,\n",
              "   'text': \" that row also, like that. And if we're having less non-values, then we go with standard\",\n",
              "   'tokens': [300,\n",
              "    5386,\n",
              "    611,\n",
              "    11,\n",
              "    411,\n",
              "    300,\n",
              "    13,\n",
              "    400,\n",
              "    498,\n",
              "    321,\n",
              "    434,\n",
              "    1419,\n",
              "    1570,\n",
              "    2107,\n",
              "    12,\n",
              "    46033,\n",
              "    11,\n",
              "    550,\n",
              "    321,\n",
              "    352,\n",
              "    365,\n",
              "    3832],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4172467478999385,\n",
              "   'compression_ratio': 2.097674418604651,\n",
              "   'no_speech_prob': 4.1848445107461885e-05},\n",
              "  {'id': 164,\n",
              "   'seek': 134992,\n",
              "   'start': 1367.68,\n",
              "   'end': 1373.72,\n",
              "   'text': \" deviation. But for that particular column, we're going to calculate standard deviation\",\n",
              "   'tokens': [25163,\n",
              "    13,\n",
              "    583,\n",
              "    337,\n",
              "    300,\n",
              "    1729,\n",
              "    7738,\n",
              "    11,\n",
              "    321,\n",
              "    434,\n",
              "    516,\n",
              "    281,\n",
              "    8873,\n",
              "    3832,\n",
              "    25163],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4172467478999385,\n",
              "   'compression_ratio': 2.097674418604651,\n",
              "   'no_speech_prob': 4.1848445107461885e-05},\n",
              "  {'id': 165,\n",
              "   'seek': 134992,\n",
              "   'start': 1373.72,\n",
              "   'end': 1377.92,\n",
              "   'text': ' and the value will be represented with standard deviation value. Non-value will be represented',\n",
              "   'tokens': [293,\n",
              "    264,\n",
              "    2158,\n",
              "    486,\n",
              "    312,\n",
              "    10379,\n",
              "    365,\n",
              "    3832,\n",
              "    25163,\n",
              "    2158,\n",
              "    13,\n",
              "    8774,\n",
              "    12,\n",
              "    29155,\n",
              "    486,\n",
              "    312,\n",
              "    10379],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4172467478999385,\n",
              "   'compression_ratio': 2.097674418604651,\n",
              "   'no_speech_prob': 4.1848445107461885e-05},\n",
              "  {'id': 166,\n",
              "   'seek': 137792,\n",
              "   'start': 1377.92,\n",
              "   'end': 1392.96,\n",
              "   'text': ' with standard deviation value. For example, I will show you. Some empty values are there',\n",
              "   'tokens': [365,\n",
              "    3832,\n",
              "    25163,\n",
              "    2158,\n",
              "    13,\n",
              "    1171,\n",
              "    1365,\n",
              "    11,\n",
              "    286,\n",
              "    486,\n",
              "    855,\n",
              "    291,\n",
              "    13,\n",
              "    2188,\n",
              "    6707,\n",
              "    4190,\n",
              "    366,\n",
              "    456],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3484404427664621,\n",
              "   'compression_ratio': 1.603658536585366,\n",
              "   'no_speech_prob': 0.00013562718231696635},\n",
              "  {'id': 167,\n",
              "   'seek': 137792,\n",
              "   'start': 1392.96,\n",
              "   'end': 1398.52,\n",
              "   'text': ' here, just of the empty values are there. In that case, if like that, if it is having',\n",
              "   'tokens': [510,\n",
              "    11,\n",
              "    445,\n",
              "    295,\n",
              "    264,\n",
              "    6707,\n",
              "    4190,\n",
              "    366,\n",
              "    456,\n",
              "    13,\n",
              "    682,\n",
              "    300,\n",
              "    1389,\n",
              "    11,\n",
              "    498,\n",
              "    411,\n",
              "    300,\n",
              "    11,\n",
              "    498,\n",
              "    309,\n",
              "    307,\n",
              "    1419],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3484404427664621,\n",
              "   'compression_ratio': 1.603658536585366,\n",
              "   'no_speech_prob': 0.00013562718231696635},\n",
              "  {'id': 168,\n",
              "   'seek': 137792,\n",
              "   'start': 1398.52,\n",
              "   'end': 1404.92,\n",
              "   'text': ' more number of records, then they will try to remove. So, but if it is having very less,',\n",
              "   'tokens': [544,\n",
              "    1230,\n",
              "    295,\n",
              "    7724,\n",
              "    11,\n",
              "    550,\n",
              "    436,\n",
              "    486,\n",
              "    853,\n",
              "    281,\n",
              "    4159,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    457,\n",
              "    498,\n",
              "    309,\n",
              "    307,\n",
              "    1419,\n",
              "    588,\n",
              "    1570,\n",
              "    11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3484404427664621,\n",
              "   'compression_ratio': 1.603658536585366,\n",
              "   'no_speech_prob': 0.00013562718231696635},\n",
              "  {'id': 169,\n",
              "   'seek': 140492,\n",
              "   'start': 1404.92,\n",
              "   'end': 1411.04,\n",
              "   'text': ' then these values will be replaced with standard deviation. So RFC, standard deviation of RFC',\n",
              "   'tokens': [550,\n",
              "    613,\n",
              "    4190,\n",
              "    486,\n",
              "    312,\n",
              "    10772,\n",
              "    365,\n",
              "    3832,\n",
              "    25163,\n",
              "    13,\n",
              "    407,\n",
              "    497,\n",
              "    18671,\n",
              "    11,\n",
              "    3832,\n",
              "    25163,\n",
              "    295,\n",
              "    497,\n",
              "    18671],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4455023593589908,\n",
              "   'compression_ratio': 1.8206896551724139,\n",
              "   'no_speech_prob': 0.0002583382010925561},\n",
              "  {'id': 170,\n",
              "   'seek': 140492,\n",
              "   'start': 1411.04,\n",
              "   'end': 1416.76,\n",
              "   'text': ' they will find and these values will be replaced. So standard deviation of SRFC will find, processing',\n",
              "   'tokens': [436,\n",
              "    486,\n",
              "    915,\n",
              "    293,\n",
              "    613,\n",
              "    4190,\n",
              "    486,\n",
              "    312,\n",
              "    10772,\n",
              "    13,\n",
              "    407,\n",
              "    3832,\n",
              "    25163,\n",
              "    295,\n",
              "    20840,\n",
              "    18671,\n",
              "    486,\n",
              "    915,\n",
              "    11,\n",
              "    9007],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4455023593589908,\n",
              "   'compression_ratio': 1.8206896551724139,\n",
              "   'no_speech_prob': 0.0002583382010925561},\n",
              "  {'id': 171,\n",
              "   'seek': 140492,\n",
              "   'start': 1416.76,\n",
              "   'end': 1422.0800000000002,\n",
              "   'text': ' will take care. So that is taken care by machine learning algorithm.',\n",
              "   'tokens': [486,\n",
              "    747,\n",
              "    1127,\n",
              "    13,\n",
              "    407,\n",
              "    300,\n",
              "    307,\n",
              "    2726,\n",
              "    1127,\n",
              "    538,\n",
              "    3479,\n",
              "    2539,\n",
              "    9284,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4455023593589908,\n",
              "   'compression_ratio': 1.8206896551724139,\n",
              "   'no_speech_prob': 0.0002583382010925561},\n",
              "  {'id': 172,\n",
              "   'seek': 142208,\n",
              "   'start': 1422.08,\n",
              "   'end': 1441.1599999999999,\n",
              "   'text': ' One second, can you open that? So data set you are required to open. So these are the',\n",
              "   'tokens': [1485,\n",
              "    1150,\n",
              "    11,\n",
              "    393,\n",
              "    291,\n",
              "    1269,\n",
              "    300,\n",
              "    30,\n",
              "    407,\n",
              "    1412,\n",
              "    992,\n",
              "    291,\n",
              "    366,\n",
              "    4739,\n",
              "    281,\n",
              "    1269,\n",
              "    13,\n",
              "    407,\n",
              "    613,\n",
              "    366,\n",
              "    264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5066147232055664,\n",
              "   'compression_ratio': 1.5043478260869565,\n",
              "   'no_speech_prob': 0.0006657611229456961},\n",
              "  {'id': 173,\n",
              "   'seek': 142208,\n",
              "   'start': 1441.1599999999999,\n",
              "   'end': 1448.6799999999998,\n",
              "   'text': \" non-values and it doesn't have any value. So it is also having, doesn't have any value.\",\n",
              "   'tokens': [2107,\n",
              "    12,\n",
              "    46033,\n",
              "    293,\n",
              "    309,\n",
              "    1177,\n",
              "    380,\n",
              "    362,\n",
              "    604,\n",
              "    2158,\n",
              "    13,\n",
              "    407,\n",
              "    309,\n",
              "    307,\n",
              "    611,\n",
              "    1419,\n",
              "    11,\n",
              "    1177,\n",
              "    380,\n",
              "    362,\n",
              "    604,\n",
              "    2158,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5066147232055664,\n",
              "   'compression_ratio': 1.5043478260869565,\n",
              "   'no_speech_prob': 0.0006657611229456961},\n",
              "  {'id': 174,\n",
              "   'seek': 144868,\n",
              "   'start': 1448.68,\n",
              "   'end': 1454.68,\n",
              "   'text': ' Some values are there, some values are empty. So these empty values.',\n",
              "   'tokens': [2188,\n",
              "    4190,\n",
              "    366,\n",
              "    456,\n",
              "    11,\n",
              "    512,\n",
              "    4190,\n",
              "    366,\n",
              "    6707,\n",
              "    13,\n",
              "    407,\n",
              "    613,\n",
              "    6707,\n",
              "    4190,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5174133401168021,\n",
              "   'compression_ratio': 1.6341463414634145,\n",
              "   'no_speech_prob': 0.00024080347793642431},\n",
              "  {'id': 175,\n",
              "   'seek': 144868,\n",
              "   'start': 1454.68,\n",
              "   'end': 1461.0800000000002,\n",
              "   'text': ' All the columns, is it given by some third party members?',\n",
              "   'tokens': [1057,\n",
              "    264,\n",
              "    13766,\n",
              "    11,\n",
              "    307,\n",
              "    309,\n",
              "    2212,\n",
              "    538,\n",
              "    512,\n",
              "    2636,\n",
              "    3595,\n",
              "    2679,\n",
              "    30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5174133401168021,\n",
              "   'compression_ratio': 1.6341463414634145,\n",
              "   'no_speech_prob': 0.00024080347793642431},\n",
              "  {'id': 176,\n",
              "   'seek': 144868,\n",
              "   'start': 1461.0800000000002,\n",
              "   'end': 1467.6000000000001,\n",
              "   'text': ' Third party, third party, third party. So the person who gave the problem to us, they',\n",
              "   'tokens': [12548,\n",
              "    3595,\n",
              "    11,\n",
              "    2636,\n",
              "    3595,\n",
              "    11,\n",
              "    2636,\n",
              "    3595,\n",
              "    13,\n",
              "    407,\n",
              "    264,\n",
              "    954,\n",
              "    567,\n",
              "    2729,\n",
              "    264,\n",
              "    1154,\n",
              "    281,\n",
              "    505,\n",
              "    11,\n",
              "    436],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5174133401168021,\n",
              "   'compression_ratio': 1.6341463414634145,\n",
              "   'no_speech_prob': 0.00024080347793642431},\n",
              "  {'id': 177,\n",
              "   'seek': 144868,\n",
              "   'start': 1467.6000000000001,\n",
              "   'end': 1469.6000000000001,\n",
              "   'text': ' will provide. Okay. So.',\n",
              "   'tokens': [486, 2893, 13, 1033, 13, 407, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5174133401168021,\n",
              "   'compression_ratio': 1.6341463414634145,\n",
              "   'no_speech_prob': 0.00024080347793642431},\n",
              "  {'id': 178,\n",
              "   'seek': 144868,\n",
              "   'start': 1469.6000000000001,\n",
              "   'end': 1472.6000000000001,\n",
              "   'text': ' Is there any definitions?',\n",
              "   'tokens': [1119, 456, 604, 21988, 30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5174133401168021,\n",
              "   'compression_ratio': 1.6341463414634145,\n",
              "   'no_speech_prob': 0.00024080347793642431},\n",
              "  {'id': 179,\n",
              "   'seek': 144868,\n",
              "   'start': 1472.6000000000001,\n",
              "   'end': 1473.6000000000001,\n",
              "   'text': ' Yeah.',\n",
              "   'tokens': [865, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5174133401168021,\n",
              "   'compression_ratio': 1.6341463414634145,\n",
              "   'no_speech_prob': 0.00024080347793642431},\n",
              "  {'id': 180,\n",
              "   'seek': 147360,\n",
              "   'start': 1473.6,\n",
              "   'end': 1480.6,\n",
              "   'text': ' Definitions available for all these columns because it is listed in short form.',\n",
              "   'tokens': [46245,\n",
              "    2451,\n",
              "    2435,\n",
              "    337,\n",
              "    439,\n",
              "    613,\n",
              "    13766,\n",
              "    570,\n",
              "    309,\n",
              "    307,\n",
              "    10052,\n",
              "    294,\n",
              "    2099,\n",
              "    1254,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4265826375860917,\n",
              "   'compression_ratio': 1.3533834586466165,\n",
              "   'no_speech_prob': 8.091708150459453e-05},\n",
              "  {'id': 181,\n",
              "   'seek': 147360,\n",
              "   'start': 1480.6,\n",
              "   'end': 1481.6,\n",
              "   'text': ' Yeah.',\n",
              "   'tokens': [865, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4265826375860917,\n",
              "   'compression_ratio': 1.3533834586466165,\n",
              "   'no_speech_prob': 8.091708150459453e-05},\n",
              "  {'id': 182,\n",
              "   'seek': 147360,\n",
              "   'start': 1481.6,\n",
              "   'end': 1482.6,\n",
              "   'text': ' RFC, SRFC, DAT.',\n",
              "   'tokens': [497, 18671, 11, 20840, 18671, 11, 413, 2218, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4265826375860917,\n",
              "   'compression_ratio': 1.3533834586466165,\n",
              "   'no_speech_prob': 8.091708150459453e-05},\n",
              "  {'id': 183,\n",
              "   'seek': 147360,\n",
              "   'start': 1482.6,\n",
              "   'end': 1493.6,\n",
              "   'text': ' Yeah. I will check it. I will check it and if possible, I will share with you.',\n",
              "   'tokens': [865,\n",
              "    13,\n",
              "    286,\n",
              "    486,\n",
              "    1520,\n",
              "    309,\n",
              "    13,\n",
              "    286,\n",
              "    486,\n",
              "    1520,\n",
              "    309,\n",
              "    293,\n",
              "    498,\n",
              "    1944,\n",
              "    11,\n",
              "    286,\n",
              "    486,\n",
              "    2073,\n",
              "    365,\n",
              "    291,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4265826375860917,\n",
              "   'compression_ratio': 1.3533834586466165,\n",
              "   'no_speech_prob': 8.091708150459453e-05},\n",
              "  {'id': 184,\n",
              "   'seek': 149360,\n",
              "   'start': 1493.6,\n",
              "   'end': 1503.6,\n",
              "   'text': \" Okay. Supposed to be given that. So we don't have.\",\n",
              "   'tokens': [1033,\n",
              "    13,\n",
              "    9391,\n",
              "    1744,\n",
              "    281,\n",
              "    312,\n",
              "    2212,\n",
              "    300,\n",
              "    13,\n",
              "    407,\n",
              "    321,\n",
              "    500,\n",
              "    380,\n",
              "    362,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5345492959022522,\n",
              "   'compression_ratio': 1.3724137931034484,\n",
              "   'no_speech_prob': 0.00036894402001053095},\n",
              "  {'id': 185,\n",
              "   'seek': 149360,\n",
              "   'start': 1503.6,\n",
              "   'end': 1504.6,\n",
              "   'text': ' Can I check in online for this?',\n",
              "   'tokens': [1664, 286, 1520, 294, 2950, 337, 341, 30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5345492959022522,\n",
              "   'compression_ratio': 1.3724137931034484,\n",
              "   'no_speech_prob': 0.00036894402001053095},\n",
              "  {'id': 186,\n",
              "   'seek': 149360,\n",
              "   'start': 1504.6,\n",
              "   'end': 1510.6,\n",
              "   'text': ' Yeah, you can find it online. You can find it online. Okay. Anyhow, if possible, myself',\n",
              "   'tokens': [865,\n",
              "    11,\n",
              "    291,\n",
              "    393,\n",
              "    915,\n",
              "    309,\n",
              "    2950,\n",
              "    13,\n",
              "    509,\n",
              "    393,\n",
              "    915,\n",
              "    309,\n",
              "    2950,\n",
              "    13,\n",
              "    1033,\n",
              "    13,\n",
              "    2639,\n",
              "    4286,\n",
              "    11,\n",
              "    498,\n",
              "    1944,\n",
              "    11,\n",
              "    2059],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5345492959022522,\n",
              "   'compression_ratio': 1.3724137931034484,\n",
              "   'no_speech_prob': 0.00036894402001053095},\n",
              "  {'id': 187,\n",
              "   'seek': 149360,\n",
              "   'start': 1510.6,\n",
              "   'end': 1513.6,\n",
              "   'text': ' also, I will share with you.',\n",
              "   'tokens': [611, 11, 286, 486, 2073, 365, 291, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5345492959022522,\n",
              "   'compression_ratio': 1.3724137931034484,\n",
              "   'no_speech_prob': 0.00036894402001053095},\n",
              "  {'id': 188,\n",
              "   'seek': 151360,\n",
              "   'start': 1513.6,\n",
              "   'end': 1535.6,\n",
              "   'text': ' Okay, here we have. So, matrix is there. Just we need to close this one.',\n",
              "   'tokens': [1033,\n",
              "    11,\n",
              "    510,\n",
              "    321,\n",
              "    362,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    8141,\n",
              "    307,\n",
              "    456,\n",
              "    13,\n",
              "    1449,\n",
              "    321,\n",
              "    643,\n",
              "    281,\n",
              "    1998,\n",
              "    341,\n",
              "    472,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48595575491587323,\n",
              "   'compression_ratio': 0.9863013698630136,\n",
              "   'no_speech_prob': 0.00017907684377860278},\n",
              "  {'id': 189,\n",
              "   'seek': 153560,\n",
              "   'start': 1535.6,\n",
              "   'end': 1544.6,\n",
              "   'text': ' Okay.',\n",
              "   'tokens': [50364, 1033, 13, 50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.8775615692138672,\n",
              "   'compression_ratio': 0.38461538461538464,\n",
              "   'no_speech_prob': 0.0005587367340922356},\n",
              "  {'id': 190,\n",
              "   'seek': 156560,\n",
              "   'start': 1566.6,\n",
              "   'end': 1582.6,\n",
              "   'text': \" So, first you're supposed to upload the data set.\",\n",
              "   'tokens': [407, 11, 700, 291, 434, 3442, 281, 6580, 264, 1412, 992, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5939821243286133,\n",
              "   'compression_ratio': 1.0972222222222223,\n",
              "   'no_speech_prob': 0.839436411857605},\n",
              "  {'id': 191,\n",
              "   'seek': 156560,\n",
              "   'start': 1582.6,\n",
              "   'end': 1594.6,\n",
              "   'text': ' Then we process the data set.',\n",
              "   'tokens': [1396, 321, 1399, 264, 1412, 992, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5939821243286133,\n",
              "   'compression_ratio': 1.0972222222222223,\n",
              "   'no_speech_prob': 0.839436411857605},\n",
              "  {'id': 192,\n",
              "   'seek': 159460,\n",
              "   'start': 1594.6,\n",
              "   'end': 1604.6,\n",
              "   'text': ' And then we select the algorithm.',\n",
              "   'tokens': [400, 550, 321, 3048, 264, 9284, 13],\n",
              "   'temperature': 0.4,\n",
              "   'avg_logprob': -0.7271190007527669,\n",
              "   'compression_ratio': 1.0,\n",
              "   'no_speech_prob': 0.0008606516057625413},\n",
              "  {'id': 193,\n",
              "   'seek': 159460,\n",
              "   'start': 1604.6,\n",
              "   'end': 1611.6,\n",
              "   'text': ' So here we are having 36,000, 928. Same 20, 80%.',\n",
              "   'tokens': [407,\n",
              "    510,\n",
              "    321,\n",
              "    366,\n",
              "    1419,\n",
              "    8652,\n",
              "    11,\n",
              "    1360,\n",
              "    11,\n",
              "    1722,\n",
              "    11205,\n",
              "    13,\n",
              "    10635,\n",
              "    945,\n",
              "    11,\n",
              "    4688,\n",
              "    6856],\n",
              "   'temperature': 0.4,\n",
              "   'avg_logprob': -0.7271190007527669,\n",
              "   'compression_ratio': 1.0,\n",
              "   'no_speech_prob': 0.0008606516057625413},\n",
              "  {'id': 194,\n",
              "   'seek': 161160,\n",
              "   'start': 1611.6,\n",
              "   'end': 1625.6,\n",
              "   'text': ' And machine learning algorithm.',\n",
              "   'tokens': [400, 3479, 2539, 9284, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6146620548132694,\n",
              "   'compression_ratio': 1.196078431372549,\n",
              "   'no_speech_prob': 0.00023586118186358362},\n",
              "  {'id': 195,\n",
              "   'seek': 161160,\n",
              "   'start': 1625.6,\n",
              "   'end': 1626.6,\n",
              "   'text': ' So,',\n",
              "   'tokens': [407, 11],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6146620548132694,\n",
              "   'compression_ratio': 1.196078431372549,\n",
              "   'no_speech_prob': 0.00023586118186358362},\n",
              "  {'id': 196,\n",
              "   'seek': 161160,\n",
              "   'start': 1626.6,\n",
              "   'end': 1634.6,\n",
              "   'text': ' yeah, it executed different algorithms. So, the rolling average accuracy 90% is there.',\n",
              "   'tokens': [1338,\n",
              "    11,\n",
              "    309,\n",
              "    17577,\n",
              "    819,\n",
              "    14642,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    264,\n",
              "    9439,\n",
              "    4274,\n",
              "    14170,\n",
              "    4289,\n",
              "    4,\n",
              "    307,\n",
              "    456,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6146620548132694,\n",
              "   'compression_ratio': 1.196078431372549,\n",
              "   'no_speech_prob': 0.00023586118186358362},\n",
              "  {'id': 197,\n",
              "   'seek': 163460,\n",
              "   'start': 1634.6,\n",
              "   'end': 1641.6,\n",
              "   'text': ' We supposed to take accuracy and they should be accuracy 97% 4.8. Random forest 97.83.',\n",
              "   'tokens': [492,\n",
              "    3442,\n",
              "    281,\n",
              "    747,\n",
              "    14170,\n",
              "    293,\n",
              "    436,\n",
              "    820,\n",
              "    312,\n",
              "    14170,\n",
              "    23399,\n",
              "    4,\n",
              "    1017,\n",
              "    13,\n",
              "    23,\n",
              "    13,\n",
              "    37603,\n",
              "    6719,\n",
              "    23399,\n",
              "    13,\n",
              "    31849,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43597153086721163,\n",
              "   'compression_ratio': 1.5980392156862746,\n",
              "   'no_speech_prob': 0.00026216800324618816},\n",
              "  {'id': 198,\n",
              "   'seek': 163460,\n",
              "   'start': 1641.6,\n",
              "   'end': 1648.6,\n",
              "   'text': ' Logistic regression is 85. Among these, which algorithm is providing more accuracy that',\n",
              "   'tokens': [10824,\n",
              "    3142,\n",
              "    24590,\n",
              "    307,\n",
              "    14695,\n",
              "    13,\n",
              "    16119,\n",
              "    613,\n",
              "    11,\n",
              "    597,\n",
              "    9284,\n",
              "    307,\n",
              "    6530,\n",
              "    544,\n",
              "    14170,\n",
              "    300],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43597153086721163,\n",
              "   'compression_ratio': 1.5980392156862746,\n",
              "   'no_speech_prob': 0.00026216800324618816},\n",
              "  {'id': 199,\n",
              "   'seek': 163460,\n",
              "   'start': 1648.6,\n",
              "   'end': 1655.6,\n",
              "   'text': ' algorithm will prefer. So here, random forest is having 97.83. They can choose either random',\n",
              "   'tokens': [9284,\n",
              "    486,\n",
              "    4382,\n",
              "    13,\n",
              "    407,\n",
              "    510,\n",
              "    11,\n",
              "    4974,\n",
              "    6719,\n",
              "    307,\n",
              "    1419,\n",
              "    23399,\n",
              "    13,\n",
              "    31849,\n",
              "    13,\n",
              "    814,\n",
              "    393,\n",
              "    2826,\n",
              "    2139,\n",
              "    4974],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43597153086721163,\n",
              "   'compression_ratio': 1.5980392156862746,\n",
              "   'no_speech_prob': 0.00026216800324618816},\n",
              "  {'id': 200,\n",
              "   'seek': 163460,\n",
              "   'start': 1655.6,\n",
              "   'end': 1659.6,\n",
              "   'text': ' forest or Dation tree. These two algorithms they can find.',\n",
              "   'tokens': [6719,\n",
              "    420,\n",
              "    413,\n",
              "    399,\n",
              "    4230,\n",
              "    13,\n",
              "    1981,\n",
              "    732,\n",
              "    14642,\n",
              "    436,\n",
              "    393,\n",
              "    915,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43597153086721163,\n",
              "   'compression_ratio': 1.5980392156862746,\n",
              "   'no_speech_prob': 0.00026216800324618816},\n",
              "  {'id': 201,\n",
              "   'seek': 165960,\n",
              "   'start': 1659.6,\n",
              "   'end': 1666.6,\n",
              "   'text': \" Okay, why because it's having high accuracy value. And then next we will go with Bernoulli\",\n",
              "   'tokens': [1033,\n",
              "    11,\n",
              "    983,\n",
              "    570,\n",
              "    309,\n",
              "    311,\n",
              "    1419,\n",
              "    1090,\n",
              "    14170,\n",
              "    2158,\n",
              "    13,\n",
              "    400,\n",
              "    550,\n",
              "    958,\n",
              "    321,\n",
              "    486,\n",
              "    352,\n",
              "    365,\n",
              "    10781,\n",
              "    263,\n",
              "    16320],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3999075954907561,\n",
              "   'compression_ratio': 1.593939393939394,\n",
              "   'no_speech_prob': 0.000731578329578042},\n",
              "  {'id': 202,\n",
              "   'seek': 165960,\n",
              "   'start': 1666.6,\n",
              "   'end': 1671.6,\n",
              "   'text': ' Naive Bayes. And last we will go with logistic regression.',\n",
              "   'tokens': [6056,\n",
              "    488,\n",
              "    7840,\n",
              "    279,\n",
              "    13,\n",
              "    400,\n",
              "    1036,\n",
              "    321,\n",
              "    486,\n",
              "    352,\n",
              "    365,\n",
              "    3565,\n",
              "    3142,\n",
              "    24590,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3999075954907561,\n",
              "   'compression_ratio': 1.593939393939394,\n",
              "   'no_speech_prob': 0.000731578329578042},\n",
              "  {'id': 203,\n",
              "   'seek': 165960,\n",
              "   'start': 1671.6,\n",
              "   'end': 1675.6,\n",
              "   'text': ' So, they will consider. So accuracy.',\n",
              "   'tokens': [407, 11, 436, 486, 1949, 13, 407, 14170, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3999075954907561,\n",
              "   'compression_ratio': 1.593939393939394,\n",
              "   'no_speech_prob': 0.000731578329578042},\n",
              "  {'id': 204,\n",
              "   'seek': 165960,\n",
              "   'start': 1675.6,\n",
              "   'end': 1681.6,\n",
              "   'text': ' Okay, so precision, they call FMF measure, but accuracy, they will consider.',\n",
              "   'tokens': [1033,\n",
              "    11,\n",
              "    370,\n",
              "    18356,\n",
              "    11,\n",
              "    436,\n",
              "    818,\n",
              "    29614,\n",
              "    37,\n",
              "    3481,\n",
              "    11,\n",
              "    457,\n",
              "    14170,\n",
              "    11,\n",
              "    436,\n",
              "    486,\n",
              "    1949,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3999075954907561,\n",
              "   'compression_ratio': 1.593939393939394,\n",
              "   'no_speech_prob': 0.000731578329578042},\n",
              "  {'id': 205,\n",
              "   'seek': 168160,\n",
              "   'start': 1681.6,\n",
              "   'end': 1689.6,\n",
              "   'text': ' So, when you executed for this data set, these two algorithms can prefer. Okay, so 97.48 is',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    562,\n",
              "    291,\n",
              "    17577,\n",
              "    337,\n",
              "    341,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    613,\n",
              "    732,\n",
              "    14642,\n",
              "    393,\n",
              "    4382,\n",
              "    13,\n",
              "    1033,\n",
              "    11,\n",
              "    370,\n",
              "    23399,\n",
              "    13,\n",
              "    13318,\n",
              "    307],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2962864935398102,\n",
              "   'compression_ratio': 1.4324324324324325,\n",
              "   'no_speech_prob': 0.0003031188971363008},\n",
              "  {'id': 206,\n",
              "   'seek': 168160,\n",
              "   'start': 1689.6,\n",
              "   'end': 1692.6,\n",
              "   'text': ' there, 97.83 is there.',\n",
              "   'tokens': [456, 11, 23399, 13, 31849, 307, 456, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2962864935398102,\n",
              "   'compression_ratio': 1.4324324324324325,\n",
              "   'no_speech_prob': 0.0003031188971363008},\n",
              "  {'id': 207,\n",
              "   'seek': 168160,\n",
              "   'start': 1692.6,\n",
              "   'end': 1697.6,\n",
              "   'text': ' Okay, and then run CNN algorithm.',\n",
              "   'tokens': [1033, 11, 293, 550, 1190, 24859, 9284, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2962864935398102,\n",
              "   'compression_ratio': 1.4324324324324325,\n",
              "   'no_speech_prob': 0.0003031188971363008},\n",
              "  {'id': 208,\n",
              "   'seek': 168160,\n",
              "   'start': 1697.6,\n",
              "   'end': 1702.6,\n",
              "   'text': \" We're executing CNN algorithm also. So, it is taking some time.\",\n",
              "   'tokens': [492,\n",
              "    434,\n",
              "    32368,\n",
              "    24859,\n",
              "    9284,\n",
              "    611,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    309,\n",
              "    307,\n",
              "    1940,\n",
              "    512,\n",
              "    565,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2962864935398102,\n",
              "   'compression_ratio': 1.4324324324324325,\n",
              "   'no_speech_prob': 0.0003031188971363008},\n",
              "  {'id': 209,\n",
              "   'seek': 170260,\n",
              "   'start': 1702.6,\n",
              "   'end': 1712.6,\n",
              "   'text': \" So, background, it is running. Final result we'll get. It is running. It is taking some time.\",\n",
              "   'tokens': [50364,\n",
              "    407,\n",
              "    11,\n",
              "    3678,\n",
              "    11,\n",
              "    309,\n",
              "    307,\n",
              "    2614,\n",
              "    13,\n",
              "    13443,\n",
              "    1874,\n",
              "    321,\n",
              "    603,\n",
              "    483,\n",
              "    13,\n",
              "    467,\n",
              "    307,\n",
              "    2614,\n",
              "    13,\n",
              "    467,\n",
              "    307,\n",
              "    1940,\n",
              "    512,\n",
              "    565,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.43314478132459855,\n",
              "   'compression_ratio': 1.1481481481481481,\n",
              "   'no_speech_prob': 0.0015171925770118833},\n",
              "  {'id': 210,\n",
              "   'seek': 173260,\n",
              "   'start': 1733.6,\n",
              "   'end': 1753.6,\n",
              "   'text': ' So, total output will be come here itself.',\n",
              "   'tokens': [407, 11, 3217, 5598, 486, 312, 808, 510, 2564, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.7044281959533691,\n",
              "   'compression_ratio': 0.84,\n",
              "   'no_speech_prob': 0.7876339554786682},\n",
              "  {'id': 211,\n",
              "   'seek': 175360,\n",
              "   'start': 1753.6,\n",
              "   'end': 1764.6,\n",
              "   'text': ' Model sequential, layer depth dense one, look output shape, params, how much params it is taking, everything is there.',\n",
              "   'tokens': [17105,\n",
              "    42881,\n",
              "    11,\n",
              "    4583,\n",
              "    7161,\n",
              "    18011,\n",
              "    472,\n",
              "    11,\n",
              "    574,\n",
              "    5598,\n",
              "    3909,\n",
              "    11,\n",
              "    971,\n",
              "    4070,\n",
              "    11,\n",
              "    577,\n",
              "    709,\n",
              "    971,\n",
              "    4070,\n",
              "    309,\n",
              "    307,\n",
              "    1940,\n",
              "    11,\n",
              "    1203,\n",
              "    307,\n",
              "    456,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.46903443009886026,\n",
              "   'compression_ratio': 1.5365853658536586,\n",
              "   'no_speech_prob': 0.0003245829720981419},\n",
              "  {'id': 212,\n",
              "   'seek': 175360,\n",
              "   'start': 1764.6,\n",
              "   'end': 1775.6,\n",
              "   'text': ' So, just we are executing CNN algorithm. So, total params it is having 281606, paranormal params 281606, non-paranormal params are 0.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    445,\n",
              "    321,\n",
              "    366,\n",
              "    32368,\n",
              "    24859,\n",
              "    9284,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    3217,\n",
              "    971,\n",
              "    4070,\n",
              "    309,\n",
              "    307,\n",
              "    1419,\n",
              "    7562,\n",
              "    44158,\n",
              "    21,\n",
              "    11,\n",
              "    280,\n",
              "    17142,\n",
              "    24440,\n",
              "    971,\n",
              "    4070,\n",
              "    7562,\n",
              "    44158,\n",
              "    21,\n",
              "    11,\n",
              "    2107,\n",
              "    12,\n",
              "    2181,\n",
              "    282,\n",
              "    24440,\n",
              "    971,\n",
              "    4070,\n",
              "    366,\n",
              "    1958,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.46903443009886026,\n",
              "   'compression_ratio': 1.5365853658536586,\n",
              "   'no_speech_prob': 0.0003245829720981419},\n",
              "  {'id': 213,\n",
              "   'seek': 177560,\n",
              "   'start': 1775.6,\n",
              "   'end': 1785.6,\n",
              "   'text': ' Just executing like this. And then we can compare the graph. So, which is having highest. Already in text only we can find it.',\n",
              "   'tokens': [1449,\n",
              "    32368,\n",
              "    411,\n",
              "    341,\n",
              "    13,\n",
              "    400,\n",
              "    550,\n",
              "    321,\n",
              "    393,\n",
              "    6794,\n",
              "    264,\n",
              "    4295,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    597,\n",
              "    307,\n",
              "    1419,\n",
              "    6343,\n",
              "    13,\n",
              "    23741,\n",
              "    294,\n",
              "    2487,\n",
              "    787,\n",
              "    321,\n",
              "    393,\n",
              "    915,\n",
              "    309,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42548591015385645,\n",
              "   'compression_ratio': 1.381679389312977,\n",
              "   'no_speech_prob': 0.0003283294790890068},\n",
              "  {'id': 214,\n",
              "   'seek': 177560,\n",
              "   'start': 1785.6,\n",
              "   'end': 1789.6,\n",
              "   'text': ' But in graph, we are executing only.',\n",
              "   'tokens': [583, 294, 4295, 11, 321, 366, 32368, 787, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42548591015385645,\n",
              "   'compression_ratio': 1.381679389312977,\n",
              "   'no_speech_prob': 0.0003283294790890068},\n",
              "  {'id': 215,\n",
              "   'seek': 177560,\n",
              "   'start': 1789.6,\n",
              "   'end': 1798.6,\n",
              "   'text': ' So, patient tree.',\n",
              "   'tokens': [407, 11, 4537, 4230, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42548591015385645,\n",
              "   'compression_ratio': 1.381679389312977,\n",
              "   'no_speech_prob': 0.0003283294790890068},\n",
              "  {'id': 216,\n",
              "   'seek': 179860,\n",
              "   'start': 1798.6,\n",
              "   'end': 1805.6,\n",
              "   'text': ' So, among these, we can find this color blue is having accuracy, reference score, precision, recall.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    3654,\n",
              "    613,\n",
              "    11,\n",
              "    321,\n",
              "    393,\n",
              "    915,\n",
              "    341,\n",
              "    2017,\n",
              "    3344,\n",
              "    307,\n",
              "    1419,\n",
              "    14170,\n",
              "    11,\n",
              "    6408,\n",
              "    6175,\n",
              "    11,\n",
              "    18356,\n",
              "    11,\n",
              "    9901,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3550599621188256,\n",
              "   'compression_ratio': 1.625,\n",
              "   'no_speech_prob': 0.0003181595238856971},\n",
              "  {'id': 217,\n",
              "   'seek': 179860,\n",
              "   'start': 1805.6,\n",
              "   'end': 1813.6,\n",
              "   'text': ' So, here we are suggesting. So, patient tree is one and random forest is another one.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    510,\n",
              "    321,\n",
              "    366,\n",
              "    18094,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    4537,\n",
              "    4230,\n",
              "    307,\n",
              "    472,\n",
              "    293,\n",
              "    4974,\n",
              "    6719,\n",
              "    307,\n",
              "    1071,\n",
              "    472,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3550599621188256,\n",
              "   'compression_ratio': 1.625,\n",
              "   'no_speech_prob': 0.0003181595238856971},\n",
              "  {'id': 218,\n",
              "   'seek': 179860,\n",
              "   'start': 1813.6,\n",
              "   'end': 1821.6,\n",
              "   'text': ' So, this is about the project execution. And the values will be changed based on the data set which we choose.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    341,\n",
              "    307,\n",
              "    466,\n",
              "    264,\n",
              "    1716,\n",
              "    15058,\n",
              "    13,\n",
              "    400,\n",
              "    264,\n",
              "    4190,\n",
              "    486,\n",
              "    312,\n",
              "    3105,\n",
              "    2361,\n",
              "    322,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    597,\n",
              "    321,\n",
              "    2826,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3550599621188256,\n",
              "   'compression_ratio': 1.625,\n",
              "   'no_speech_prob': 0.0003181595238856971},\n",
              "  {'id': 219,\n",
              "   'seek': 179860,\n",
              "   'start': 1821.6,\n",
              "   'end': 1824.6,\n",
              "   'text': ' So, for this we can prefer this.',\n",
              "   'tokens': [407, 11, 337, 341, 321, 393, 4382, 341, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3550599621188256,\n",
              "   'compression_ratio': 1.625,\n",
              "   'no_speech_prob': 0.0003181595238856971},\n",
              "  {'id': 220,\n",
              "   'seek': 179860,\n",
              "   'start': 1824.6,\n",
              "   'end': 1826.6,\n",
              "   'text': ' So, have any doubts?',\n",
              "   'tokens': [407, 11, 362, 604, 22618, 30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3550599621188256,\n",
              "   'compression_ratio': 1.625,\n",
              "   'no_speech_prob': 0.0003181595238856971},\n",
              "  {'id': 221,\n",
              "   'seek': 182660,\n",
              "   'start': 1826.6,\n",
              "   'end': 1831.6,\n",
              "   'text': \" If you run CNN algorithm, it won't be displayed in this window. It will be displayed in command window only.\",\n",
              "   'tokens': [759,\n",
              "    291,\n",
              "    1190,\n",
              "    24859,\n",
              "    9284,\n",
              "    11,\n",
              "    309,\n",
              "    1582,\n",
              "    380,\n",
              "    312,\n",
              "    16372,\n",
              "    294,\n",
              "    341,\n",
              "    4910,\n",
              "    13,\n",
              "    467,\n",
              "    486,\n",
              "    312,\n",
              "    16372,\n",
              "    294,\n",
              "    5622,\n",
              "    4910,\n",
              "    787,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.34712625057139296,\n",
              "   'compression_ratio': 1.7427184466019416,\n",
              "   'no_speech_prob': 0.0014330255798995495},\n",
              "  {'id': 222,\n",
              "   'seek': 182660,\n",
              "   'start': 1831.6,\n",
              "   'end': 1838.6,\n",
              "   'text': \" Yeah, it doesn't work. Why? Because actually it will work in background process only.\",\n",
              "   'tokens': [865,\n",
              "    11,\n",
              "    309,\n",
              "    1177,\n",
              "    380,\n",
              "    589,\n",
              "    13,\n",
              "    1545,\n",
              "    30,\n",
              "    1436,\n",
              "    767,\n",
              "    309,\n",
              "    486,\n",
              "    589,\n",
              "    294,\n",
              "    3678,\n",
              "    1399,\n",
              "    787,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.34712625057139296,\n",
              "   'compression_ratio': 1.7427184466019416,\n",
              "   'no_speech_prob': 0.0014330255798995495},\n",
              "  {'id': 223,\n",
              "   'seek': 182660,\n",
              "   'start': 1838.6,\n",
              "   'end': 1841.6,\n",
              "   'text': ' It will work background only.',\n",
              "   'tokens': [467, 486, 589, 3678, 787, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.34712625057139296,\n",
              "   'compression_ratio': 1.7427184466019416,\n",
              "   'no_speech_prob': 0.0014330255798995495},\n",
              "  {'id': 224,\n",
              "   'seek': 182660,\n",
              "   'start': 1841.6,\n",
              "   'end': 1848.6,\n",
              "   'text': ' And up to, this CNN is in the future selection only. So, up to this one only is the final.',\n",
              "   'tokens': [400,\n",
              "    493,\n",
              "    281,\n",
              "    11,\n",
              "    341,\n",
              "    24859,\n",
              "    307,\n",
              "    294,\n",
              "    264,\n",
              "    2027,\n",
              "    9450,\n",
              "    787,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    493,\n",
              "    281,\n",
              "    341,\n",
              "    472,\n",
              "    787,\n",
              "    307,\n",
              "    264,\n",
              "    2572,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.34712625057139296,\n",
              "   'compression_ratio': 1.7427184466019416,\n",
              "   'no_speech_prob': 0.0014330255798995495},\n",
              "  {'id': 225,\n",
              "   'seek': 182660,\n",
              "   'start': 1848.6,\n",
              "   'end': 1853.6,\n",
              "   'text': ' Okay, this is the future selection process.',\n",
              "   'tokens': [1033, 11, 341, 307, 264, 2027, 9450, 1399, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.34712625057139296,\n",
              "   'compression_ratio': 1.7427184466019416,\n",
              "   'no_speech_prob': 0.0014330255798995495},\n",
              "  {'id': 226,\n",
              "   'seek': 185360,\n",
              "   'start': 1853.6,\n",
              "   'end': 1860.6,\n",
              "   'text': \" And CNN algorithms will work background only. It doesn't work in front, we can't show you.\",\n",
              "   'tokens': [400,\n",
              "    24859,\n",
              "    14642,\n",
              "    486,\n",
              "    589,\n",
              "    3678,\n",
              "    787,\n",
              "    13,\n",
              "    467,\n",
              "    1177,\n",
              "    380,\n",
              "    589,\n",
              "    294,\n",
              "    1868,\n",
              "    11,\n",
              "    321,\n",
              "    393,\n",
              "    380,\n",
              "    855,\n",
              "    291,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2570719770205918,\n",
              "   'compression_ratio': 1.5344827586206897,\n",
              "   'no_speech_prob': 0.0007505640387535095},\n",
              "  {'id': 227,\n",
              "   'seek': 185360,\n",
              "   'start': 1860.6,\n",
              "   'end': 1862.6,\n",
              "   'text': ' Okay.',\n",
              "   'tokens': [1033, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2570719770205918,\n",
              "   'compression_ratio': 1.5344827586206897,\n",
              "   'no_speech_prob': 0.0007505640387535095},\n",
              "  {'id': 228,\n",
              "   'seek': 185360,\n",
              "   'start': 1862.6,\n",
              "   'end': 1874.6,\n",
              "   'text': \" So, first you're supposed to upload the data set, then pre-process it, then future selection process, and then machine learning execution process.\",\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    700,\n",
              "    291,\n",
              "    434,\n",
              "    3442,\n",
              "    281,\n",
              "    6580,\n",
              "    264,\n",
              "    1412,\n",
              "    992,\n",
              "    11,\n",
              "    550,\n",
              "    659,\n",
              "    12,\n",
              "    41075,\n",
              "    309,\n",
              "    11,\n",
              "    550,\n",
              "    2027,\n",
              "    9450,\n",
              "    1399,\n",
              "    11,\n",
              "    293,\n",
              "    550,\n",
              "    3479,\n",
              "    2539,\n",
              "    15058,\n",
              "    1399,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2570719770205918,\n",
              "   'compression_ratio': 1.5344827586206897,\n",
              "   'no_speech_prob': 0.0007505640387535095},\n",
              "  {'id': 229,\n",
              "   'seek': 185360,\n",
              "   'start': 1874.6,\n",
              "   'end': 1879.6,\n",
              "   'text': ' So, in this comparison graph, is there any option available like how to check that?',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    294,\n",
              "    341,\n",
              "    9660,\n",
              "    4295,\n",
              "    11,\n",
              "    307,\n",
              "    456,\n",
              "    604,\n",
              "    3614,\n",
              "    2435,\n",
              "    411,\n",
              "    577,\n",
              "    281,\n",
              "    1520,\n",
              "    300,\n",
              "    30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2570719770205918,\n",
              "   'compression_ratio': 1.5344827586206897,\n",
              "   'no_speech_prob': 0.0007505640387535095},\n",
              "  {'id': 230,\n",
              "   'seek': 185360,\n",
              "   'start': 1879.6,\n",
              "   'end': 1880.6,\n",
              "   'text': ' Which one?',\n",
              "   'tokens': [3013, 472, 30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2570719770205918,\n",
              "   'compression_ratio': 1.5344827586206897,\n",
              "   'no_speech_prob': 0.0007505640387535095},\n",
              "  {'id': 231,\n",
              "   'seek': 185360,\n",
              "   'start': 1880.6,\n",
              "   'end': 1882.6,\n",
              "   'text': ' Comparison graph.',\n",
              "   'tokens': [2432, 2181, 2770, 4295, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2570719770205918,\n",
              "   'compression_ratio': 1.5344827586206897,\n",
              "   'no_speech_prob': 0.0007505640387535095},\n",
              "  {'id': 232,\n",
              "   'seek': 188260,\n",
              "   'start': 1882.6,\n",
              "   'end': 1888.6,\n",
              "   'text': ' Comparison graph, just whatever the data which we received here, whatever the data which we received here.',\n",
              "   'tokens': [2432,\n",
              "    2181,\n",
              "    2770,\n",
              "    4295,\n",
              "    11,\n",
              "    445,\n",
              "    2035,\n",
              "    264,\n",
              "    1412,\n",
              "    597,\n",
              "    321,\n",
              "    4613,\n",
              "    510,\n",
              "    11,\n",
              "    2035,\n",
              "    264,\n",
              "    1412,\n",
              "    597,\n",
              "    321,\n",
              "    4613,\n",
              "    510,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.313844937956735,\n",
              "   'compression_ratio': 1.7428571428571429,\n",
              "   'no_speech_prob': 0.0004938232596032321},\n",
              "  {'id': 233,\n",
              "   'seek': 188260,\n",
              "   'start': 1888.6,\n",
              "   'end': 1892.6,\n",
              "   'text': ' So, yeah, CNN accuracy also it came here.',\n",
              "   'tokens': [407, 11, 1338, 11, 24859, 14170, 611, 309, 1361, 510, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.313844937956735,\n",
              "   'compression_ratio': 1.7428571428571429,\n",
              "   'no_speech_prob': 0.0004938232596032321},\n",
              "  {'id': 234,\n",
              "   'seek': 188260,\n",
              "   'start': 1892.6,\n",
              "   'end': 1895.6,\n",
              "   'text': ' CNN accuracy 86.5150.',\n",
              "   'tokens': [24859, 14170, 26687, 13, 20, 5211, 15, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.313844937956735,\n",
              "   'compression_ratio': 1.7428571428571429,\n",
              "   'no_speech_prob': 0.0004938232596032321},\n",
              "  {'id': 235,\n",
              "   'seek': 188260,\n",
              "   'start': 1895.6,\n",
              "   'end': 1899.6,\n",
              "   'text': ' Okay, CNN precision, CNN recall and CNN reference.',\n",
              "   'tokens': [1033, 11, 24859, 18356, 11, 24859, 9901, 293, 24859, 6408, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.313844937956735,\n",
              "   'compression_ratio': 1.7428571428571429,\n",
              "   'no_speech_prob': 0.0004938232596032321},\n",
              "  {'id': 236,\n",
              "   'seek': 188260,\n",
              "   'start': 1899.6,\n",
              "   'end': 1902.6,\n",
              "   'text': ' It will be received here also.',\n",
              "   'tokens': [467, 486, 312, 4613, 510, 611, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.313844937956735,\n",
              "   'compression_ratio': 1.7428571428571429,\n",
              "   'no_speech_prob': 0.0004938232596032321},\n",
              "  {'id': 237,\n",
              "   'seek': 188260,\n",
              "   'start': 1902.6,\n",
              "   'end': 1911.6,\n",
              "   'text': ' So, CNN algorithm is also having very less, 86.5151.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    24859,\n",
              "    9284,\n",
              "    307,\n",
              "    611,\n",
              "    1419,\n",
              "    588,\n",
              "    1570,\n",
              "    11,\n",
              "    26687,\n",
              "    13,\n",
              "    20,\n",
              "    5211,\n",
              "    16,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.313844937956735,\n",
              "   'compression_ratio': 1.7428571428571429,\n",
              "   'no_speech_prob': 0.0004938232596032321},\n",
              "  {'id': 238,\n",
              "   'seek': 191160,\n",
              "   'start': 1911.6,\n",
              "   'end': 1922.6,\n",
              "   'text': ' So, just we are giving comparison graph means the text what we received here, the text what we received here, just we are showing graphical monad, nothing is there.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    445,\n",
              "    321,\n",
              "    366,\n",
              "    2902,\n",
              "    9660,\n",
              "    4295,\n",
              "    1355,\n",
              "    264,\n",
              "    2487,\n",
              "    437,\n",
              "    321,\n",
              "    4613,\n",
              "    510,\n",
              "    11,\n",
              "    264,\n",
              "    2487,\n",
              "    437,\n",
              "    321,\n",
              "    4613,\n",
              "    510,\n",
              "    11,\n",
              "    445,\n",
              "    321,\n",
              "    366,\n",
              "    4099,\n",
              "    35942,\n",
              "    1108,\n",
              "    345,\n",
              "    11,\n",
              "    1825,\n",
              "    307,\n",
              "    456,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41520905226803895,\n",
              "   'compression_ratio': 1.8144329896907216,\n",
              "   'no_speech_prob': 0.0010973638854920864},\n",
              "  {'id': 239,\n",
              "   'seek': 191160,\n",
              "   'start': 1922.6,\n",
              "   'end': 1923.6,\n",
              "   'text': ' Okay.',\n",
              "   'tokens': [1033, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41520905226803895,\n",
              "   'compression_ratio': 1.8144329896907216,\n",
              "   'no_speech_prob': 0.0010973638854920864},\n",
              "  {'id': 240,\n",
              "   'seek': 191160,\n",
              "   'start': 1923.6,\n",
              "   'end': 1926.6,\n",
              "   'text': ' All the data we have, same thing we are representing here.',\n",
              "   'tokens': [1057,\n",
              "    264,\n",
              "    1412,\n",
              "    321,\n",
              "    362,\n",
              "    11,\n",
              "    912,\n",
              "    551,\n",
              "    321,\n",
              "    366,\n",
              "    13460,\n",
              "    510,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41520905226803895,\n",
              "   'compression_ratio': 1.8144329896907216,\n",
              "   'no_speech_prob': 0.0010973638854920864},\n",
              "  {'id': 241,\n",
              "   'seek': 191160,\n",
              "   'start': 1926.6,\n",
              "   'end': 1930.6,\n",
              "   'text': ' This different algorithms, values?',\n",
              "   'tokens': [639, 819, 14642, 11, 4190, 30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41520905226803895,\n",
              "   'compression_ratio': 1.8144329896907216,\n",
              "   'no_speech_prob': 0.0010973638854920864},\n",
              "  {'id': 242,\n",
              "   'seek': 191160,\n",
              "   'start': 1930.6,\n",
              "   'end': 1933.6,\n",
              "   'text': ' Yeah, values.',\n",
              "   'tokens': [865, 11, 4190, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41520905226803895,\n",
              "   'compression_ratio': 1.8144329896907216,\n",
              "   'no_speech_prob': 0.0010973638854920864},\n",
              "  {'id': 243,\n",
              "   'seek': 191160,\n",
              "   'start': 1933.6,\n",
              "   'end': 1940.6,\n",
              "   'text': ' Just different algorithm values only there. So, what we received in here.',\n",
              "   'tokens': [1449,\n",
              "    819,\n",
              "    9284,\n",
              "    4190,\n",
              "    787,\n",
              "    456,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    437,\n",
              "    321,\n",
              "    4613,\n",
              "    294,\n",
              "    510,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.41520905226803895,\n",
              "   'compression_ratio': 1.8144329896907216,\n",
              "   'no_speech_prob': 0.0010973638854920864},\n",
              "  {'id': 244,\n",
              "   'seek': 194060,\n",
              "   'start': 1940.6,\n",
              "   'end': 1945.6,\n",
              "   'text': ' Okay, so for checking purpose only we are using graph.',\n",
              "   'tokens': [1033, 11, 370, 337, 8568, 4334, 787, 321, 366, 1228, 4295, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2621839387076242,\n",
              "   'compression_ratio': 1.6514285714285715,\n",
              "   'no_speech_prob': 0.0002815107291098684},\n",
              "  {'id': 245,\n",
              "   'seek': 194060,\n",
              "   'start': 1945.6,\n",
              "   'end': 1947.6,\n",
              "   'text': ' But here only we can say that.',\n",
              "   'tokens': [583, 510, 787, 321, 393, 584, 300, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2621839387076242,\n",
              "   'compression_ratio': 1.6514285714285715,\n",
              "   'no_speech_prob': 0.0002815107291098684},\n",
              "  {'id': 246,\n",
              "   'seek': 194060,\n",
              "   'start': 1947.6,\n",
              "   'end': 1953.6,\n",
              "   'text': ' When you compare accuracy, here only we can say that.',\n",
              "   'tokens': [1133, 291, 6794, 14170, 11, 510, 787, 321, 393, 584, 300, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2621839387076242,\n",
              "   'compression_ratio': 1.6514285714285715,\n",
              "   'no_speech_prob': 0.0002815107291098684},\n",
              "  {'id': 247,\n",
              "   'seek': 194060,\n",
              "   'start': 1953.6,\n",
              "   'end': 1955.6,\n",
              "   'text': ' And CNN is also.',\n",
              "   'tokens': [400, 24859, 307, 611, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2621839387076242,\n",
              "   'compression_ratio': 1.6514285714285715,\n",
              "   'no_speech_prob': 0.0002815107291098684},\n",
              "  {'id': 248,\n",
              "   'seek': 194060,\n",
              "   'start': 1955.6,\n",
              "   'end': 1962.6,\n",
              "   'text': ' So, bagging glass for accuracy 85 is there. So, gradient boosting accuracy 99.71 is there, sorry.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    3411,\n",
              "    3249,\n",
              "    4276,\n",
              "    337,\n",
              "    14170,\n",
              "    14695,\n",
              "    307,\n",
              "    456,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    16235,\n",
              "    43117,\n",
              "    14170,\n",
              "    11803,\n",
              "    13,\n",
              "    29985,\n",
              "    307,\n",
              "    456,\n",
              "    11,\n",
              "    2597,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2621839387076242,\n",
              "   'compression_ratio': 1.6514285714285715,\n",
              "   'no_speech_prob': 0.0002815107291098684},\n",
              "  {'id': 249,\n",
              "   'seek': 194060,\n",
              "   'start': 1962.6,\n",
              "   'end': 1966.6,\n",
              "   'text': ' Gradient boosting is having 99.71.',\n",
              "   'tokens': [16710, 1196, 43117, 307, 1419, 11803, 13, 29985, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2621839387076242,\n",
              "   'compression_ratio': 1.6514285714285715,\n",
              "   'no_speech_prob': 0.0002815107291098684},\n",
              "  {'id': 250,\n",
              "   'seek': 196660,\n",
              "   'start': 1966.6,\n",
              "   'end': 1971.6,\n",
              "   'text': ' And CNN accuracy is 86. So, this is having best one.',\n",
              "   'tokens': [400,\n",
              "    24859,\n",
              "    14170,\n",
              "    307,\n",
              "    26687,\n",
              "    13,\n",
              "    407,\n",
              "    11,\n",
              "    341,\n",
              "    307,\n",
              "    1419,\n",
              "    1151,\n",
              "    472,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4065467465308405,\n",
              "   'compression_ratio': 1.4563758389261745,\n",
              "   'no_speech_prob': 0.0013938435586169362},\n",
              "  {'id': 251,\n",
              "   'seek': 196660,\n",
              "   'start': 1971.6,\n",
              "   'end': 1975.6,\n",
              "   'text': ' Scroll the text.',\n",
              "   'tokens': [35395, 264, 2487, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4065467465308405,\n",
              "   'compression_ratio': 1.4563758389261745,\n",
              "   'no_speech_prob': 0.0013938435586169362},\n",
              "  {'id': 252,\n",
              "   'seek': 196660,\n",
              "   'start': 1975.6,\n",
              "   'end': 1981.6,\n",
              "   'text': ' So, 97 decision tree and 7.48 and random forest 97.83.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    23399,\n",
              "    3537,\n",
              "    4230,\n",
              "    293,\n",
              "    1614,\n",
              "    13,\n",
              "    13318,\n",
              "    293,\n",
              "    4974,\n",
              "    6719,\n",
              "    23399,\n",
              "    13,\n",
              "    31849,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4065467465308405,\n",
              "   'compression_ratio': 1.4563758389261745,\n",
              "   'no_speech_prob': 0.0013938435586169362},\n",
              "  {'id': 253,\n",
              "   'seek': 196660,\n",
              "   'start': 1981.6,\n",
              "   'end': 1989.6,\n",
              "   'text': ' So, when it comes to gradient boosting accuracy algorithm, gradient boosting accuracy 99.71.',\n",
              "   'tokens': [407,\n",
              "    11,\n",
              "    562,\n",
              "    309,\n",
              "    1487,\n",
              "    281,\n",
              "    16235,\n",
              "    43117,\n",
              "    14170,\n",
              "    9284,\n",
              "    11,\n",
              "    16235,\n",
              "    43117,\n",
              "    14170,\n",
              "    11803,\n",
              "    13,\n",
              "    29985,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4065467465308405,\n",
              "   'compression_ratio': 1.4563758389261745,\n",
              "   'no_speech_prob': 0.0013938435586169362},\n",
              "  {'id': 254,\n",
              "   'seek': 198960,\n",
              "   'start': 1989.6,\n",
              "   'end': 1999.6,\n",
              "   'text': ' So, only CNN algorithm has been extended.',\n",
              "   'tokens': [407, 11, 787, 24859, 9284, 575, 668, 10913, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6222546895345052,\n",
              "   'compression_ratio': 1.5401459854014599,\n",
              "   'no_speech_prob': 0.0014260014286264777},\n",
              "  {'id': 255,\n",
              "   'seek': 198960,\n",
              "   'start': 1999.6,\n",
              "   'end': 2006.6,\n",
              "   'text': ' CNN algorithm is extended. CNN, LSTM, and other extension algorithms are not there.',\n",
              "   'tokens': [24859,\n",
              "    9284,\n",
              "    307,\n",
              "    10913,\n",
              "    13,\n",
              "    24859,\n",
              "    11,\n",
              "    441,\n",
              "    6840,\n",
              "    44,\n",
              "    11,\n",
              "    293,\n",
              "    661,\n",
              "    10320,\n",
              "    14642,\n",
              "    366,\n",
              "    406,\n",
              "    456,\n",
              "    13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6222546895345052,\n",
              "   'compression_ratio': 1.5401459854014599,\n",
              "   'no_speech_prob': 0.0014260014286264777},\n",
              "  {'id': 256,\n",
              "   'seek': 198960,\n",
              "   'start': 2006.6,\n",
              "   'end': 2008.6,\n",
              "   'text': \" That's why we executed it separately.\",\n",
              "   'tokens': [663, 311, 983, 321, 17577, 309, 14759, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6222546895345052,\n",
              "   'compression_ratio': 1.5401459854014599,\n",
              "   'no_speech_prob': 0.0014260014286264777},\n",
              "  {'id': 257,\n",
              "   'seek': 198960,\n",
              "   'start': 2008.6,\n",
              "   'end': 2012.6,\n",
              "   'text': ' So, it came out finally, it extended algorithm.',\n",
              "   'tokens': [407, 11, 309, 1361, 484, 2721, 11, 309, 10913, 9284, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6222546895345052,\n",
              "   'compression_ratio': 1.5401459854014599,\n",
              "   'no_speech_prob': 0.0014260014286264777},\n",
              "  {'id': 258,\n",
              "   'seek': 201260,\n",
              "   'start': 2012.6,\n",
              "   'end': 2022.6,\n",
              "   'text': ' We also have CNN and Joplin.',\n",
              "   'tokens': [492, 611, 362, 24859, 293, 508, 404, 5045, 13],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.637126332237607,\n",
              "   'compression_ratio': 0.8461538461538461,\n",
              "   'no_speech_prob': 0.0004015174927189946},\n",
              "  {'id': 259,\n",
              "   'seek': 201260,\n",
              "   'start': 2022.6,\n",
              "   'end': 2024.6,\n",
              "   'text': ' Any doubts?',\n",
              "   'tokens': [2639, 22618, 30],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.637126332237607,\n",
              "   'compression_ratio': 0.8461538461538461,\n",
              "   'no_speech_prob': 0.0004015174927189946},\n",
              "  {'id': 260,\n",
              "   'seek': 202460,\n",
              "   'start': 2024.6,\n",
              "   'end': 2044.6,\n",
              "   'text': ' No.',\n",
              "   'tokens': [50364, 883, 13, 51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6539354801177979,\n",
              "   'compression_ratio': 0.2727272727272727,\n",
              "   'no_speech_prob': 0.00015899971185717732}],\n",
              " 'language': 'en'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the resulting transcription\n",
        "print(results[\"text\"])"
      ],
      "metadata": {
        "id": "jEvwnN3dEJGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9930fab2-c029-44b9-bb04-92a17abfa202"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " So here, the intention of this application is me to predict the software quality. So here we are going to consider one data set, which is having related to the software and everything. So here we are having 10 data sets, one is related to Spring Framework, another one is related to JUnit, another one is related to Kafka trunk, another one is related to Blue Sea and Drop Wizard, Textile, Hadoop, Selenium, Skywalking and Signal Android Mast. So these are the data sets which we are working. So among these data sets, we can choose any one data set. So when you observe any data set, it is having the information related to the software. So for example, here we are using qualified name. So what are the things they are observing and then the name. So here we are having qualified name and the name, then complexity, then coupling, size, lack of cohesion, CBO, RFC. These are all the different parameters that are considering in software quality and everything. So every quality is having its own values. So based on the thing, it may have between 1 to 100 or 0 to 1 like that or 1 or 0. So like that, we are having different data sets. Regarding JUnit also we are having. So any data set we can use it. So it's also having the same parameters. So and like that, we are having totally 10 data sets. Among these 10 data sets, we can choose anything. So whichever data set you want, you can test it. So here, when you are going to discuss regarding the abstract, they are saying that the software quality estimation is an activity needed at various stages of software development. So when people are going to develop any software, so mainly they will concentrate on quality and everything. So already we know that one problem can be solved with the help of different things. For example, when you consider one example like to find out whether the number is a right number or not, or else whether you want to find out whether the number is a strong number or not, or want to reverse the number, or there's some exergence. So if you assume some problem, for that problem, you can find different solutions. So everything is correct. When you execute n number of programs, for example, n users are there, and n users, they will give n programs. All n programs will get the same output, but they will consider some applications only. They will not consider all n programs to implement it. Why? Because they may need some time complexity and space complexity also. So the program should execute as early as possible in a good time manner and should use very less memory. These are the main constraints. So when you consider these constraints, then some programs will be assured and some programs only will work. So that will decide based on the situation. Next slide, please. Sorry. So here the thing is, when we people are working with programming styles, so all programmers write their own program, but we don't consider all the programs. The programming which is giving best performance, then only we'll consider. So when you're planning some performance, they may have different factors. So among these factors, they will check it. But here in the part of machine learning, so what we are going to discuss is, so which one is best, which one is better. So for that, we are using SVM and neural network algorithms. So they will find the accuracy, which is having high accuracy, which is having low accuracy, and everything will be mentioned in machine learning algorithm. So these are the total documentation which we are having. So when it comes to execution part, so in the folder, software quality folder is there, there just click on run. When you click on run, automatically your application will start execution. So it is having PPT also. And generally, the machine learning algorithms will process these things. So whatever the data set we are having, first they will apply cleaning and pre-processing, then they will find the data set and they will select the future. So futures in the sense here in machine learning, so table fields, we call it as a future setting. So if you consider any table, it may have a number of fields, columns are there. So that columns will be mentioned as a future. So they will select the futures and then they will do the input and they will apply the machine learning algorithms. But then they will get the predictions. So for execution it will take some time. We need to wait. So this is the table. So first you're supposed to upload the data set. So in data set, we're having different types of data sets. Among these things, whichever data set you want, you can choose it. You need to consider one data set. These are different software's data which we have collected. Yeah, which is already recorded. And if you have your own data set, you can also add here. So whatever it may be. So here they gave some data sets which is related to different different software's. And they recorded yearly wise. So just you need to choose upload data set. So we are having different different data sets. So I'm using some Hadoop trunk. So it is having only 2020. We can choose that one. So once you uploaded the data set, then pre-processing is going to work. So we're having the data sets information. Some are there. Totally 4,000, sorry, 41,667 records are there and 40 features are there. So 41,667 rows and 40 columns. Here columns in the sense we call it as features. And we are giving some graphical representation also. Of different different columns, SRFC, DIT, all the columns are there. So it is giving information. And if you want to save this image, you can save it, but not required. Just I'm closing this one. So this is data which I uploaded. Once you uploaded the data set, then you're supposed to pre-process the given data set. Pre-processing in the sense it is going to check any null values are there or else any difficulties is there. Everything will think. And if any null values or anything is there, then they will remove the data set. They will remove the rows and which contains the null values. Just we're supposed to be pre-processed data set. It is having the qualified name, resolve things and which is giving the maximum value which is having maximum value. So once it is pre-processed, here I'm getting some data which is ready to pre-processing. And then feature selection algorithms. So we need to select the features. When you click on here, so it is going to give the information. This is a cross matrix. So we may have a number of features, 40 features are there. That's why that overlapping is happening. So, but here graphically, not only graphically textual in text wise, we can see here. So total features are found in the data set before applying the feature selection. 39 is there. So total features found in the data set after applying the feature selection algorithm. So among 39, we are choosing 30 only. And the total records found is so 41067. But among these, some null data will be there. Some null data will be there. OK, that we can remove. The total records used for trying the machine learning algorithm is 33,333. And the total records used to test machine learning algorithm is 8,334. So here, when you observe the data set, so we are having single data set. When you people are applying any machine learning algorithm, so the data set is supposed to divide into two parts. One is called trying data set, another is called test data set. And some problems may find a different for training and testing also. OK, so in some applications, you may find two data sets. One is for training, another is for testing. In some applications, you may get only one data set. In that case, if you are having only one data set, in that case, it is your responsibility to divide the data set into two parts, training and test. So how we are going to divide in the sense, so we may consider 70-30 percentages only. So some programs may consider 70% of data set will be training and 30% will be testing. In some applications, they may go with 80-20 also. In some applications, they may go with 60-40 also. OK, so in our application. So here in our application, we are using 80-20 percent. Here, the test size is equal to 0.2, means 20%. So 80% will be for training data and 20% is for testing data. How we are going to select like that means based on the data which we have in a week. OK, so for example, you can calculate. So total we are having 41,067 into 0.20. So 8334. So that is the value which we are having. OK, 8334 means 8334 it is taking and remaining the cost will be training cost. So 70-30 means if you are having huge amount of data, thousands of records, then go with 80-20. If you are having some medium, means some 5000, 6000 like that, go with 70-30. So if you are having very less, like hundreds, then go with 60-40. Why? Because for training or testing, both should be having some meaningful of records. OK, if you are having very less records for testing, then in that case, so your machine learning algorithms will not work properly. So here I'm having 41,667. That's why I choose 80-20%. So 20% of data will be for testing purpose and 80% of data will be for training purpose. So among these records, so it is taking randomly. Randomly it is going to divide into two parts. So that is feature selection algorithm. Then I'm running machine learning algorithms. Just I'm clicking machine learning algorithm. Run. So it will take some time. So for machine learning algorithms execution, you take a lot of time. We need to wait for some time. So this 8334 records, it will pick randomly or it will pick sequentially? Randomly. Randomly machine itself is taking. OK, among these, so it is going to design data frames. So for 80% of records, it is going to design one data frame and 30% of records, it is going to design one data frame and it is not sequence. So randomly, it will choose. A single data set which we have pointed, it will split into two now? Yeah. OK. Whatever the data set you selected, so that will be split into two parts. 80-20%. Is it compulsory 80-20 means? No. Some people may go with 70-30 also. Some people may go with 60-40 also. Based on our requirement. But 70-30 is the average maximum people will use. But here we are using 80-20 because we have plenty of records. Why they opt to choose for this splitting? Is there any logic? For example, if you say that I prepared for exam. I prepared for exam. So I prepared some math exam. So in my notes, I'm having some problems. So I prepared very well. Can we expect in exam the same 10 problems or same questions in examination? Can you expect the same questions in external examination? No, we cannot expect. But you should, when you said that I prepared for exam, then you're supposed to do same type of questions that may arise. Same, not same problem, same type of questions that will arise. In that situation, you're supposed to write answer that questions also. For that here we are using training and testing. Training in the data set. So mission is going to train the algorithm with the help of these 33,333 records. Randomly they choose them. And then to check whether the mission is working properly or not, whether the algorithm is working properly or not, we are using testing data set. So for testing data set also supposed to take same performance. For that we are dividing training and testing. Training in the sense that training, we are giving training to algorithm and to test whether it is working properly or not, we are using testing data set. All the fields in the data set, how we are capturing like there are 30 columns. 40 fields are there. So in programming part we are thinking just a minute I will show that program. The fields which is recorded by application, some application is there so that we are not discussing. So every fields will be gathered through application. So someone is giving that data set to us to go with the software quality prediction. How much, how quality is there if I'm using Hadoop. So whether the accuracy, how much accuracy is there, whether can we proceed with Hadoop or not. If I give some net bills, how much accuracy is there. So Java, how much accuracy is there, like that. They will give the fields and every data set. For that we are going to process the thing. So here feature selection will be there. So some columns may be having non-values in that case, we'll remove that one. Some rows will be having non-values in that case, we'll remove that row also, like that. And if we're having less non-values, then we go with standard deviation. But for that particular column, we're going to calculate standard deviation and the value will be represented with standard deviation value. Non-value will be represented with standard deviation value. For example, I will show you. Some empty values are there here, just of the empty values are there. In that case, if like that, if it is having more number of records, then they will try to remove. So, but if it is having very less, then these values will be replaced with standard deviation. So RFC, standard deviation of RFC they will find and these values will be replaced. So standard deviation of SRFC will find, processing will take care. So that is taken care by machine learning algorithm. One second, can you open that? So data set you are required to open. So these are the non-values and it doesn't have any value. So it is also having, doesn't have any value. Some values are there, some values are empty. So these empty values. All the columns, is it given by some third party members? Third party, third party, third party. So the person who gave the problem to us, they will provide. Okay. So. Is there any definitions? Yeah. Definitions available for all these columns because it is listed in short form. Yeah. RFC, SRFC, DAT. Yeah. I will check it. I will check it and if possible, I will share with you. Okay. Supposed to be given that. So we don't have. Can I check in online for this? Yeah, you can find it online. You can find it online. Okay. Anyhow, if possible, myself also, I will share with you. Okay, here we have. So, matrix is there. Just we need to close this one. Okay. So, first you're supposed to upload the data set. Then we process the data set. And then we select the algorithm. So here we are having 36,000, 928. Same 20, 80%. And machine learning algorithm. So, yeah, it executed different algorithms. So, the rolling average accuracy 90% is there. We supposed to take accuracy and they should be accuracy 97% 4.8. Random forest 97.83. Logistic regression is 85. Among these, which algorithm is providing more accuracy that algorithm will prefer. So here, random forest is having 97.83. They can choose either random forest or Dation tree. These two algorithms they can find. Okay, why because it's having high accuracy value. And then next we will go with Bernoulli Naive Bayes. And last we will go with logistic regression. So, they will consider. So accuracy. Okay, so precision, they call FMF measure, but accuracy, they will consider. So, when you executed for this data set, these two algorithms can prefer. Okay, so 97.48 is there, 97.83 is there. Okay, and then run CNN algorithm. We're executing CNN algorithm also. So, it is taking some time. So, background, it is running. Final result we'll get. It is running. It is taking some time. So, total output will be come here itself. Model sequential, layer depth dense one, look output shape, params, how much params it is taking, everything is there. So, just we are executing CNN algorithm. So, total params it is having 281606, paranormal params 281606, non-paranormal params are 0. Just executing like this. And then we can compare the graph. So, which is having highest. Already in text only we can find it. But in graph, we are executing only. So, patient tree. So, among these, we can find this color blue is having accuracy, reference score, precision, recall. So, here we are suggesting. So, patient tree is one and random forest is another one. So, this is about the project execution. And the values will be changed based on the data set which we choose. So, for this we can prefer this. So, have any doubts? If you run CNN algorithm, it won't be displayed in this window. It will be displayed in command window only. Yeah, it doesn't work. Why? Because actually it will work in background process only. It will work background only. And up to, this CNN is in the future selection only. So, up to this one only is the final. Okay, this is the future selection process. And CNN algorithms will work background only. It doesn't work in front, we can't show you. Okay. So, first you're supposed to upload the data set, then pre-process it, then future selection process, and then machine learning execution process. So, in this comparison graph, is there any option available like how to check that? Which one? Comparison graph. Comparison graph, just whatever the data which we received here, whatever the data which we received here. So, yeah, CNN accuracy also it came here. CNN accuracy 86.5150. Okay, CNN precision, CNN recall and CNN reference. It will be received here also. So, CNN algorithm is also having very less, 86.5151. So, just we are giving comparison graph means the text what we received here, the text what we received here, just we are showing graphical monad, nothing is there. Okay. All the data we have, same thing we are representing here. This different algorithms, values? Yeah, values. Just different algorithm values only there. So, what we received in here. Okay, so for checking purpose only we are using graph. But here only we can say that. When you compare accuracy, here only we can say that. And CNN is also. So, bagging glass for accuracy 85 is there. So, gradient boosting accuracy 99.71 is there, sorry. Gradient boosting is having 99.71. And CNN accuracy is 86. So, this is having best one. Scroll the text. So, 97 decision tree and 7.48 and random forest 97.83. So, when it comes to gradient boosting accuracy algorithm, gradient boosting accuracy 99.71. So, only CNN algorithm has been extended. CNN algorithm is extended. CNN, LSTM, and other extension algorithms are not there. That's why we executed it separately. So, it came out finally, it extended algorithm. We also have CNN and Joplin. Any doubts? No.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## write the transcribed text into a text file"
      ],
      "metadata": {
        "id": "1v9WRL7fEDQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('transcription.txt','w+') as f:\n",
        "  # write the resulting transcription\n",
        "  f.write(results[\"text\"])"
      ],
      "metadata": {
        "id": "opYBmP4BD2Oq"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}